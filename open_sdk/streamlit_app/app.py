"""
BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤
Langchain + Gemini ë²„ì „ (OpenAI Agents SDK ì œê±°)
"""
import streamlit as st
from pathlib import Path
import json
import asyncio
import os
import sys
import time
from datetime import datetime
import platform
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# matplotlib import ë° ì„¤ì • (ì™„ì „ ì•ˆì „ ëª¨ë“œ)
MATPLOTLIB_AVAILABLE = False
plt = None
matplotlib = None

# matplotlibì„ ì™„ì „íˆ ì„ íƒì ìœ¼ë¡œ ë¡œë“œ
def safe_import_matplotlib():
    global MATPLOTLIB_AVAILABLE, plt, matplotlib
    try:
        import matplotlib
        import matplotlib.pyplot as plt
        
        # í•œê¸€ í°íŠ¸ ì„¤ì •
        system = platform.system()
        if system == "Windows":
            plt.rcParams['font.family'] = 'Malgun Gothic'
        elif system == "Darwin":
            plt.rcParams['font.family'] = 'AppleGothic'
        else:
            plt.rcParams['font.family'] = 'NanumGothic'
        matplotlib.rcParams['axes.unicode_minus'] = False
        
        MATPLOTLIB_AVAILABLE = True
        print("[OK] Matplotlib loaded successfully")
        return True
    except ImportError as e:
        print(f"[WARN] Matplotlib not available: {e}")
        return False
    except Exception as e:
        print(f"[WARN] Matplotlib configuration error: {e}")
        return False

# matplotlib ë¡œë“œ ì‹œë„ (ì‹¤ì œ ì‚¬ìš© ì‹œì ì— ë¡œë“œ)
# safe_import_matplotlib()

# run_analysis.py ì§ì ‘ import
sys.path.insert(0, str(Path(__file__).parent.parent))  # open_sdk ë””ë ‰í† ë¦¬ ì¶”ê°€
from run_analysis import run_full_analysis_pipeline

# Langchain AI Agents import
AGENTS_AVAILABLE = False
try:
    from ai_agents import (
        classify_query_sync,
        create_consultation_chain,
        chat_with_consultant,
        load_merged_analysis
    )
    AGENTS_AVAILABLE = True
    print("[OK] Langchain AI Agents loaded successfully")
except ImportError as e:
    print(f"[WARN] AI Agents import failed: {e}")
except Exception as e:
    print(f"[ERROR] AI Agents error: {e}")
    import traceback
    traceback.print_exc()

# Gemini í´ë¼ì´ì–¸íŠ¸ import
try:
    import importlib.util
    gemini_path = Path(__file__).parent.parent.parent / "agents_new" / "utils" / "gemini_client.py"
    spec = importlib.util.spec_from_file_location("gemini_client", gemini_path)
    gemini_module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(gemini_module)
    GeminiClient = gemini_module.GeminiClient
    GEMINI_AVAILABLE = True
except Exception as e:
    GEMINI_AVAILABLE = False
    print(f"Gemini client not available: {e}")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤",
    page_icon="ğŸª",
    layout="wide"
)

# ì»¤ìŠ¤í…€ CSS (í•œê¸€ í°íŠ¸ ì ìš©)
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap');
        
        * {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stMarkdown, .stText, .stSelectbox, .stTextInput, .stButton, .stMetric, .stExpander {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stMarkdown h1, .stMarkdown h2, .stMarkdown h3, .stMarkdown h4, .stMarkdown h5, .stMarkdown h6 {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stTabs [data-baseweb="tab-list"] {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stTabs [data-baseweb="tab"] {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stSelectbox label, .stTextInput label {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stButton > button {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stMetric [data-testid="metric-container"] {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stExpander [data-testid="stExpander"] {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
    </style>
    """, unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'store_code' not in st.session_state:
    st.session_state.store_code = None
if 'is_analyzing' not in st.session_state:
    st.session_state.is_analyzing = False
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'consultation_mode' not in st.session_state:
    st.session_state.consultation_mode = False
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'analysis_data' not in st.session_state:
    st.session_state.analysis_data = None
if 'final_report_generated' not in st.session_state:
    st.session_state.final_report_generated = False
if 'consultation_chain' not in st.session_state:
    st.session_state.consultation_chain = None
if 'consultation_memory' not in st.session_state:
    st.session_state.consultation_memory = None
if 'merged_data' not in st.session_state:
    st.session_state.merged_data = None
if 'merged_md' not in st.session_state:
    st.session_state.merged_md = None

def generate_final_report_with_gemini(analysis_data):
    """Geminië¥¼ ì‚¬ìš©í•´ì„œ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±"""
    if not GEMINI_AVAILABLE:
        return None, None
    
    try:
        client = GeminiClient()
        
        # ë¶„ì„ ë°ì´í„°ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        analysis_json = json.dumps(analysis_data, ensure_ascii=False, indent=2)
        
        prompt = f"""
ë‹¤ìŒì€ ë§¤ì¥ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë¶„ì„ ë°ì´í„°:
{analysis_json}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

# ë§¤ì¥ ë¶„ì„ ìµœì¢… ë¦¬í¬íŠ¸

## 1. ì‹¤í–‰ ìš”ì•½
- í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ê°€ì§€
- ì£¼ìš” ë¬¸ì œì  2ê°€ì§€  
- ì¶”ì²œ ì „ëµ 3ê°€ì§€

## 2. ë§¤ì¥ í˜„í™© ë¶„ì„
- ë§¤ì¥ ê¸°ë³¸ ì •ë³´
- ë§¤ì¶œ ë° ê³ ê° ë¶„ì„
- ìƒê¶Œ í™˜ê²½ ë¶„ì„

## 3. ë§ˆì¼€íŒ… ì „ëµ
- íƒ€ê²Ÿ ê³ ê° ë¶„ì„
- ì¶”ì²œ ë§ˆì¼€íŒ… ì „ëµ
- ì‹¤í–‰ ê³„íš

## 4. ê°œì„  ë°©ì•ˆ
- ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­
- ì¤‘ì¥ê¸° ë°œì „ ë°©í–¥
- ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘ ë°©ì•ˆ

## 5. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­
- ì¢…í•© í‰ê°€
- ìµœìš°ì„  ì‹¤í–‰ ê³¼ì œ
- ì„±ê³µ ì§€í‘œ ì„¤ì •

JSON í˜•ì‹ìœ¼ë¡œë„ ìš”ì•½í•´ì£¼ì„¸ìš”:
{{
  "executive_summary": {{
    "key_insights": ["ì¸ì‚¬ì´íŠ¸1", "ì¸ì‚¬ì´íŠ¸2", "ì¸ì‚¬ì´íŠ¸3"],
    "main_issues": ["ë¬¸ì œ1", "ë¬¸ì œ2"],
    "recommended_strategies": ["ì „ëµ1", "ì „ëµ2", "ì „ëµ3"]
  }},
  "store_analysis": {{
    "performance_score": 85,
    "strengths": ["ê°•ì 1", "ê°•ì 2"],
    "weaknesses": ["ì•½ì 1", "ì•½ì 2"]
  }},
  "marketing_recommendations": {{
    "target_customers": "íƒ€ê²Ÿ ê³ ê° ì„¤ëª…",
    "primary_strategy": "ì£¼ìš” ì „ëµ",
    "implementation_priority": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ"
  }},
  "action_plan": {{
    "immediate_actions": ["ì¦‰ì‹œ ì‹¤í–‰1", "ì¦‰ì‹œ ì‹¤í–‰2"],
    "short_term_goals": ["ë‹¨ê¸° ëª©í‘œ1", "ë‹¨ê¸° ëª©í‘œ2"],
    "long_term_vision": "ì¥ê¸° ë¹„ì „"
  }}
}}
"""
        
        response = client.chat_completion([{"role": "user", "content": prompt}])
        
        # MDì™€ JSON ë¶„ë¦¬
        md_content = response
        json_content = None
        
        # JSON ë¶€ë¶„ ì¶”ì¶œ
        if "```json" in response:
            json_start = response.find("```json") + 7
            json_end = response.find("```", json_start)
            if json_end > json_start:
                json_str = response[json_start:json_end].strip()
                try:
                    json_content = json.loads(json_str)
                except:
                    json_content = None
        
        return md_content, json_content
        
    except Exception as e:
        print(f"Gemini ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None, None

def convert_absolute_to_relative_path(absolute_path: str) -> str:
    """ì ˆëŒ€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
    if not absolute_path:
        return absolute_path
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
    project_root = Path(__file__).parent.parent.parent
    
    try:
        abs_path = Path(absolute_path)
        if abs_path.is_absolute():
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
            relative_path = abs_path.relative_to(project_root)
            return str(relative_path).replace('\\', '/')  # Windows ê²½ë¡œ êµ¬ë¶„ì í†µì¼
        else:
            return absolute_path
    except ValueError:
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë°–ì˜ ê²½ë¡œì¸ ê²½ìš° ì›ë³¸ ë°˜í™˜
        return absolute_path


def load_analysis_data_from_output(store_code):
    """output í´ë”ì—ì„œ ì‹¤ì œ ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œ"""
    try:
        output_dir = Path(__file__).parent.parent / "output"
        print(f"[DEBUG] output_dir: {output_dir}")
        print(f"[DEBUG] output_dir exists: {output_dir.exists()}")
        
        # ê°€ì¥ ìµœì‹  ë¶„ì„ í´ë” ì°¾ê¸° (analysis_{store_code}_{timestamp} í˜•ì‹)
        analysis_dirs = list(output_dir.glob(f"analysis_{store_code}_*"))
        print(f"[DEBUG] ì°¾ì€ ë¶„ì„ í´ë”: {analysis_dirs}")
        
        if not analysis_dirs:
            print(f"[ERROR] {store_code}ì— ëŒ€í•œ ë¶„ì„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ê°€ì¥ ìµœì‹  í´ë” ì„ íƒ
        latest_dir = max(analysis_dirs, key=os.path.getctime)
        print(f"[INFO] ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ë¡œë“œ: {latest_dir.name}")
        
        # ê° ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        data = {
            "store_code": store_code,
            "analysis_dir": str(latest_dir),
            "is_existing_analysis": True,  # ê¸°ì¡´ ë¶„ì„ì„ì„ í‘œì‹œ
            "timestamp": latest_dir.name.split("_")[-1]
        }
        
        # 1. í†µí•© ë¶„ì„ ê²°ê³¼ (analysis_result.json)
        analysis_file = latest_dir / "analysis_result.json"
        if analysis_file.exists():
            try:
                with open(analysis_file, 'r', encoding='utf-8') as f:
                    data["analysis_result"] = json.load(f)
                print(f"[OK] analysis_result.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] analysis_result.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] analysis_result.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 2. ì¢…í•© ë¶„ì„ ê²°ê³¼ (comprehensive_analysis.json) - ì„ íƒì 
        comprehensive_file = latest_dir / "comprehensive_analysis.json"
        if comprehensive_file.exists():
            try:
                with open(comprehensive_file, 'r', encoding='utf-8') as f:
                    data["comprehensive_analysis"] = json.load(f)
                print(f"[OK] comprehensive_analysis.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] comprehensive_analysis.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] comprehensive_analysis.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 3. Store ë¶„ì„ ê²°ê³¼ - ì„ íƒì 
        store_file = latest_dir / "store_analysis_report.json"
        if store_file.exists():
            try:
                with open(store_file, 'r', encoding='utf-8') as f:
                    data["store_analysis"] = json.load(f)
                print(f"[OK] store_analysis_report.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] store_analysis_report.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] store_analysis_report.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 4. Marketing ë¶„ì„ ê²°ê³¼ - ì„ íƒì 
        marketing_file = latest_dir / "marketing_strategy.json"
        if marketing_file.exists():
            try:
                with open(marketing_file, 'r', encoding='utf-8') as f:
                    data["marketing_analysis"] = json.load(f)
                print(f"[OK] marketing_strategy.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] marketing_strategy.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] marketing_strategy.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 5. Marketplace ë¶„ì„ ê²°ê³¼
        marketplace_file = latest_dir / "marketplace" / "marketplace_data.json"
        if marketplace_file.exists():
            try:
                with open(marketplace_file, 'r', encoding='utf-8') as f:
                    data["marketplace_analysis"] = json.load(f)
                print(f"[OK] marketplace_data.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] marketplace_data.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] marketplace_data.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 6. Panorama ë¶„ì„ ê²°ê³¼
        panorama_file = latest_dir / "panorama" / "analysis_result.json"
        if panorama_file.exists():
            try:
                with open(panorama_file, 'r', encoding='utf-8') as f:
                    data["panorama_analysis"] = json.load(f)
                print(f"[OK] panorama analysis_result.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] panorama analysis_result.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] panorama analysis_result.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 7. Mobility ë¶„ì„ ê²°ê³¼ - ì„ íƒì 
        mobility_file = latest_dir / "mobility_charts" / "mobility_data.json"
        if mobility_file.exists():
            try:
                with open(mobility_file, 'r', encoding='utf-8') as f:
                    data["mobility_analysis"] = json.load(f)
                print(f"[OK] mobility_data.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] mobility_data.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] mobility_data.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 8. ì‹œê°í™” íŒŒì¼ë“¤ ë¡œë“œ
        data["visualizations"] = load_visualization_files(latest_dir)
        
        # ìµœì†Œí•œ í•˜ë‚˜ì˜ ë¶„ì„ ë°ì´í„°ë¼ë„ ìˆìœ¼ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
        loaded_sections = [k for k, v in data.items() if k not in ["store_code", "analysis_dir", "is_existing_analysis", "timestamp"] and v is not None]
        
        if loaded_sections:
            print(f"[OK] ë¶„ì„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(loaded_sections)}ê°œ ì„¹ì…˜ ({', '.join(loaded_sections)})")
            return data
        else:
            print(f"[ERROR] ë¡œë“œëœ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
    except Exception as e:
        print(f"[ERROR] ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def load_visualization_files(analysis_dir):
    """ì‹œê°í™” íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    viz_data = {
        "store_charts": [],
        "mobility_charts": [],
        "panorama_images": [],
        "spatial_files": []
    }
    
    try:
        # Store ì°¨íŠ¸ë“¤
        store_charts_dir = analysis_dir / "store_charts"
        if store_charts_dir.exists():
            for chart_file in store_charts_dir.glob("*.png"):
                viz_data["store_charts"].append({
                    "name": chart_file.stem,
                    "path": convert_absolute_to_relative_path(str(chart_file)),
                    "absolute_path": str(chart_file),
                    "type": "store_chart"
                })
        
        # Mobility ì°¨íŠ¸ë“¤
        mobility_charts_dir = analysis_dir / "mobility_charts"
        if mobility_charts_dir.exists():
            for chart_file in mobility_charts_dir.glob("*.png"):
                viz_data["mobility_charts"].append({
                    "name": chart_file.stem,
                    "path": convert_absolute_to_relative_path(str(chart_file)),
                    "absolute_path": str(chart_file),
                    "type": "mobility_chart"
                })
        
        # Panorama ì´ë¯¸ì§€ë“¤
        panorama_images_dir = analysis_dir / "panorama" / "images"
        if panorama_images_dir.exists():
            for img_file in panorama_images_dir.glob("*.jpg"):
                viz_data["panorama_images"].append({
                    "name": img_file.stem,
                    "path": convert_absolute_to_relative_path(str(img_file)),
                    "absolute_path": str(img_file),
                    "type": "panorama_image"
                })
        
        # Spatial ì‹œê°í™” íŒŒì¼ë“¤
        spatial_map = analysis_dir / "spatial_map.html"
        spatial_chart = analysis_dir / "spatial_analysis.png"
        
        if spatial_map.exists():
            viz_data["spatial_files"].append({
                "name": "ê³µê°„ ë¶„ì„ ì§€ë„",
                "path": convert_absolute_to_relative_path(str(spatial_map)),
                "absolute_path": str(spatial_map),
                "type": "spatial_map"
            })
        
        if spatial_chart.exists():
            viz_data["spatial_files"].append({
                "name": "ê³µê°„ ë¶„ì„ ì°¨íŠ¸",
                "path": convert_absolute_to_relative_path(str(spatial_chart)),
                "absolute_path": str(spatial_chart),
                "type": "spatial_chart"
            })
        
        # Panorama ì§€ë„
        panorama_map = analysis_dir / "panorama" / "analysis_map.html"
        if panorama_map.exists():
            viz_data["spatial_files"].append({
                "name": "íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì§€ë„",
                "path": convert_absolute_to_relative_path(str(panorama_map)),
                "absolute_path": str(panorama_map),
                "type": "panorama_map"
            })
        
        print(f"[OK] ì‹œê°í™” íŒŒì¼ ë¡œë“œ: Store({len(viz_data['store_charts'])}), Mobility({len(viz_data['mobility_charts'])}), Panorama({len(viz_data['panorama_images'])}), Spatial({len(viz_data['spatial_files'])})")
        
    except Exception as e:
        print(f"[ERROR] ì‹œê°í™” íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return viz_data

def load_analysis_files_from_actual_locations(store_code):
    """ì‹¤ì œ ì €ì¥ëœ ë¶„ì„ íŒŒì¼ë“¤ì„ ë¡œë“œ (legacy í•¨ìˆ˜ - í˜¸í™˜ì„± ìœ ì§€)"""
    return load_analysis_data_from_output(store_code)

# ê° íƒ­ë³„ í‘œì‹œ í•¨ìˆ˜ë“¤
def display_basic_info(analysis_data):
    """ê¸°ë³¸ ì •ë³´ í‘œì‹œ"""
    st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    
    # Store ë¶„ì„ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    store_data = analysis_data.get("store_analysis", {})
    if store_data and "store_overview" in store_data:
        store_info = store_data["store_overview"]
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ë§¤ì¥ëª…", store_info.get("name", "N/A"))
        with col2:
            st.metric("ì—…ì¢…", store_info.get("industry", "N/A"))
        with col3:
            st.metric("ìƒê¶Œ", store_info.get("commercial_area", "N/A"))
    
    # Spatial ë¶„ì„ì—ì„œ ì£¼ì†Œ ì •ë³´
    comprehensive = analysis_data.get("comprehensive_analysis", {})
    if comprehensive and "spatial_analysis" in comprehensive:
        spatial = comprehensive["spatial_analysis"]
        st.write(f"**ì£¼ì†Œ:** {spatial.get('address', 'N/A')}")
        st.write(f"**í–‰ì •ë™:** {spatial.get('administrative_dong', 'N/A')}")

def display_final_report_button(store_code, analysis_data):
    """ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ í‘œì‹œ"""
    if not st.session_state.final_report_generated:
        if st.button("ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (Gemini)", type="primary"):
            with st.spinner("Geminië¡œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„± ì¤‘..."):
                md_content, json_content = generate_final_report_with_gemini(analysis_data)
                if md_content:
                    report_dir = save_final_reports(store_code, md_content, json_content)
                    if report_dir:
                        st.success(f"ìµœì¢… ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_dir}")
                        st.session_state.final_report_generated = True
                        st.rerun()
                else:
                    st.error("ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    else:
        st.info("âœ… ìµœì¢… ë¦¬í¬íŠ¸ê°€ ì´ë¯¸ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

def display_store_overview(analysis_data):
    """ë§¤ì¥ ê°œìš” íƒ­"""
    st.markdown("### ğŸª ë§¤ì¥ ê°œìš”")
    
    store_data = analysis_data.get("store_analysis", {})
    if not store_data:
        st.info("ë§¤ì¥ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    store_info = store_data.get("store_overview", {})
    sales_data = store_data.get("sales_analysis", {})
    
    # ê¸°ë³¸ ì •ë³´
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"**ë§¤ì¥ëª…:** {store_info.get('name', 'N/A')}")
        st.write(f"**ì—…ì¢…:** {store_info.get('industry', 'N/A')}")
        st.write(f"**ë¸Œëœë“œ:** {store_info.get('brand', 'N/A')}")
    with col2:
        st.write(f"**ìƒê¶Œ:** {store_info.get('commercial_area', 'N/A')}")
        st.write(f"**ìš´ì˜ ê°œì›”:** {store_info.get('operating_months', 'N/A')}ê°œì›”")
        st.write(f"**ë§¤ì¥ ì—°ë ¹:** {store_info.get('store_age', 'N/A')}")
    
    # ë§¤ì¶œ ë¶„ì„
    if sales_data:
        st.markdown("#### ğŸ“ˆ ë§¤ì¶œ ë¶„ì„")
        trends = sales_data.get("trends", {})
        
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ë§¤ì¶œì•¡", trends.get("sales_amount", {}).get("trend", "N/A"))
        with col2:
            st.metric("ë§¤ì¶œ ê±´ìˆ˜", trends.get("sales_count", {}).get("trend", "N/A"))
        with col3:
            st.metric("ê³ ìœ  ê³ ê°", trends.get("unique_customers", {}).get("trend", "N/A"))
        with col4:
            st.metric("ê°ë‹¨ê°€", trends.get("avg_transaction", {}).get("trend", "N/A"))
        
        # ë°°ë‹¬ ë¶„ì„
        delivery = sales_data.get("delivery_analysis", {})
        if delivery:
            st.write(f"**ë°°ë‹¬ ë¹„ìœ¨:** {delivery.get('average', 'N/A')}% ({delivery.get('trend', 'N/A')})")
        
        # ì·¨ì†Œìœ¨ ë¶„ì„
        cancellation = sales_data.get("cancellation_analysis", {})
        if cancellation:
            st.write(f"**í‰ê·  ì·¨ì†Œ ë“±ê¸‰:** {cancellation.get('average_grade', 'N/A')}")
            st.write(f"**ê¶Œì¥ì‚¬í•­:** {cancellation.get('recommendation', 'N/A')}")

def display_customer_analysis(analysis_data):
    """ê³ ê° ë¶„ì„ íƒ­ + ì‹œê°í™”"""
    st.markdown("### ğŸ‘¥ ê³ ê° ë¶„ì„")
    
    store_data = analysis_data.get("store_analysis", {})
    if not store_data:
        st.info("ë§¤ì¥ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    customer_data = store_data.get("customer_analysis", {})
    if not customer_data:
        st.info("ê³ ê° ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì„±ë³„ ë¶„í¬
    gender_data = customer_data.get("gender_distribution", {})
    if gender_data:
        st.markdown("#### ì„±ë³„ ë¶„í¬")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ë‚¨ì„±", f"{gender_data.get('male_ratio', 0)}%")
        with col2:
            st.metric("ì—¬ì„±", f"{gender_data.get('female_ratio', 0)}%")
    
    # ì—°ë ¹ëŒ€ ë¶„í¬
    age_data = customer_data.get("age_group_distribution", {})
    if age_data:
        st.markdown("#### ì—°ë ¹ëŒ€ë³„ ê³ ê° ë¶„í¬")
        for age_group, ratio in age_data.items():
            st.write(f"- **{age_group}:** {ratio}%")
    
    # ê³ ê° ìœ í˜• ë¶„ì„
    customer_type = customer_data.get("customer_type_analysis", {})
    if customer_type:
        st.markdown("#### ê³ ê° ìœ í˜• ë¶„ì„")
        
        new_customers = customer_type.get("new_customers", {})
        returning_customers = customer_type.get("returning_customers", {})
        
        col1, col2 = st.columns(2)
        with col1:
            st.metric("ì‹ ê·œ ê³ ê°", f"{new_customers.get('ratio', 0)}%", delta=new_customers.get('trend', ''))
        with col2:
            st.metric("ì¬ë°©ë¬¸ ê³ ê°", f"{returning_customers.get('ratio', 0)}%", delta=returning_customers.get('trend', ''))
        
        # ê³ ê° ë¶„í¬
        distribution = customer_type.get("customer_distribution", {})
        if distribution:
            st.markdown("#### ê³ ê° ë¶„í¬")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ì£¼ê±°í˜•", f"{distribution.get('residential', 0)}%")
            with col2:
                st.metric("ì§ì¥í˜•", f"{distribution.get('workplace', 0)}%")
            with col3:
                st.metric("ìœ ë™í˜•", f"{distribution.get('floating', 0)}%")
    
    # ===== ì‹œê°í™” ì¶”ê°€ =====
    visualizations = analysis_data.get("visualizations", {})
    store_charts = visualizations.get("store_charts", [])
    
    if store_charts:
        st.markdown("---")
        st.markdown("#### ğŸ“Š ê³ ê° ë¶„ì„ ì°¨íŠ¸")
        
        # ê³ ê° ê´€ë ¨ ì°¨íŠ¸ í•„í„°ë§
        customer_charts = [c for c in store_charts if any(keyword in c.get("name", "").lower() 
                          for keyword in ["age", "gender", "customer", "ì—°ë ¹", "ì„±ë³„", "ê³ ê°"])]
        
        if customer_charts:
            cols = st.columns(2)
            for idx, chart_info in enumerate(customer_charts[:6]):  # ìµœëŒ€ 6ê°œ
                col_idx = idx % 2
                with cols[col_idx]:
                    chart_path = chart_info.get("path")
                    chart_name = chart_info.get("name", f"Chart {idx+1}")
                    
                    if chart_path and Path(chart_path).exists():
                        try:
                            st.image(chart_path, caption=chart_name, use_column_width=True)
                        except Exception as e:
                            st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name}")
        else:
            st.info("ê³ ê° ê´€ë ¨ ì°¨íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

def display_mobility_analysis(analysis_data):
    """ì´ë™ íŒ¨í„´ ë¶„ì„ íƒ­ + ì‹œê°í™”"""
    st.markdown("### ğŸš¶ ì´ë™ íŒ¨í„´ ë¶„ì„")
    
    mobility_data = analysis_data.get("mobility_analysis", {})
    if not mobility_data:
        st.info("ì´ë™ íŒ¨í„´ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    analysis = mobility_data.get("analysis", {})
    if not analysis:
        st.info("ì´ë™ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì´ë™ ìœ í˜•
    move_types = analysis.get("part1_move_types", {})
    if move_types:
        st.markdown("#### ì´ë™ ìœ í˜•")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ìœ ì…", f"{move_types.get('ìœ ì…', 0):,}ëª…")
        with col2:
            st.metric("ìœ ì¶œ", f"{move_types.get('ìœ ì¶œ', 0):,}ëª…")
        with col3:
            st.metric("ë‚´ë¶€ì´ë™", f"{move_types.get('ë‚´ë¶€ì´ë™', 0):,}ëª…")
    
    # ì‹œê°„ëŒ€ë³„ íŒ¨í„´
    time_pattern = analysis.get("part2_time_pattern", {})
    if time_pattern:
        st.markdown("#### ì‹œê°„ëŒ€ë³„ ì´ë™ íŒ¨í„´")
        peak_hour = max(time_pattern.items(), key=lambda x: x[1])
        st.write(f"**ìµœëŒ€ ì´ë™ ì‹œê°„:** {peak_hour[0]}ì‹œ ({peak_hour[1]:,}ëª…)")
    
    # ===== ì‹œê°í™” ì¶”ê°€ =====
    visualizations = analysis_data.get("visualizations", {})
    mobility_charts = visualizations.get("mobility_charts", [])
    
    if mobility_charts:
        st.markdown("---")
        st.markdown("#### ğŸ“Š ì´ë™ íŒ¨í„´ ì°¨íŠ¸")
        st.write(f"ì´ {len(mobility_charts)}ê°œ ì°¨íŠ¸")
        
        cols = st.columns(2)
        for idx, chart_info in enumerate(mobility_charts):
            col_idx = idx % 2
            with cols[col_idx]:
                chart_path = chart_info.get("path")
                chart_name = chart_info.get("name", f"Chart {idx+1}")
                
                if chart_path and Path(chart_path).exists():
                    try:
                        st.image(chart_path, caption=chart_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name}")
    else:
        st.info("ì´ë™ íŒ¨í„´ ì°¨íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        # ìƒìœ„ 5ê°œ ì‹œê°„ëŒ€
        top_hours = sorted(time_pattern.items(), key=lambda x: x[1], reverse=True)[:5]
        st.write("**ìƒìœ„ ì´ë™ ì‹œê°„ëŒ€:**")
        for hour, count in top_hours:
            st.write(f"- {hour}ì‹œ: {count:,}ëª…")
    
    # ëª©ì ë³„ ë¶„ì„
    purpose_data = analysis.get("part3_purpose", {})
    if purpose_data:
        st.markdown("#### ëª©ì ë³„ ì´ë™")
        top_purposes = sorted(purpose_data.items(), key=lambda x: x[1], reverse=True)[:5]
        for purpose, count in top_purposes:
            st.write(f"- **{purpose}:** {count:,}ëª…")
    
    # êµí†µìˆ˜ë‹¨
    transport_data = analysis.get("part4_transport", {})
    if transport_data:
        st.markdown("#### êµí†µìˆ˜ë‹¨ë³„ ì´ìš©")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ì°¨ëŸ‰:** {transport_data.get('ì°¨ëŸ‰', 0):,}ëª…")
            st.write(f"**ì§€í•˜ì² :** {transport_data.get('ì§€í•˜ì² ', 0):,}ëª…")
        with col2:
            st.write(f"**ë„ë³´:** {transport_data.get('ë„ë³´', 0):,}ëª…")
            st.write(f"**ë²„ìŠ¤:** {transport_data.get('ì¼ë°˜ë²„ìŠ¤', 0) + transport_data.get('ê´‘ì—­ë²„ìŠ¤', 0):,}ëª…")

def display_panorama_analysis(analysis_data):
    """ì§€ì—­ ë¶„ì„ íƒ­"""
    st.markdown("### ğŸ˜ï¸ ì§€ì—­ ë¶„ì„ (íŒŒë…¸ë¼ë§ˆ)")
    
    panorama_data = analysis_data.get("panorama_analysis", {})
    if not panorama_data:
        st.info("íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    metadata = panorama_data.get("metadata", {})
    if metadata:
        st.write(f"**ë¶„ì„ ì£¼ì†Œ:** {metadata.get('input_address', 'N/A')}")
        st.write(f"**ë¶„ì„ ë°˜ê²½:** {metadata.get('buffer_meters', 'N/A')}m")
        st.write(f"**ë¶„ì„ ì´ë¯¸ì§€:** {metadata.get('images_analyzed', 0)}ê°œ")
    
    # ì¢…í•© ë¶„ì„ ê²°ê³¼
    synthesis = panorama_data.get("synthesis", {})
    if synthesis:
        st.markdown("#### ì¢…í•© ë¶„ì„ ê²°ê³¼")
        
        area_summary = synthesis.get("area_summary", {})
        if area_summary:
            st.write(f"**ì§€ì—­ íŠ¹ì„±:** {area_summary.get('overall_character', 'N/A')}")
            st.write(f"**ìƒê¶Œ ìœ í˜•:** {area_summary.get('primary_commercial_type', 'N/A')}")
        
        scores = synthesis.get("comprehensive_scores", {})
        if scores:
            st.markdown("#### ì§€ì—­ ì ìˆ˜")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ìƒê¶Œ í™œë ¥", f"{scores.get('commercial_atmosphere', 0)}/10")
                st.metric("ê±°ë¦¬ ë¶„ìœ„ê¸°", f"{scores.get('street_atmosphere', 0)}/10")
            with col2:
                st.metric("ì²­ê²°ë„", f"{scores.get('cleanliness', 0)}/10")
                st.metric("ìœ ì§€ë³´ìˆ˜", f"{scores.get('maintenance', 0)}/10")
            with col3:
                st.metric("ë³´í–‰ì„±", f"{scores.get('walkability', 0)}/10")
                st.metric("ì•ˆì „ê°", f"{scores.get('safety_perception', 0)}/10")
        
        detailed_assessment = synthesis.get("detailed_assessment", {})
        if detailed_assessment:
            strengths = detailed_assessment.get("strengths", [])
            weaknesses = detailed_assessment.get("weaknesses", [])
            
            if strengths:
                st.markdown("#### ê°•ì ")
                for strength in strengths:
                    st.write(f"âœ… {strength}")
            
            if weaknesses:
                st.markdown("#### ì•½ì ")
                for weakness in weaknesses:
                    st.write(f"âŒ {weakness}")
            
            expert_opinion = detailed_assessment.get("expert_opinion")
            if expert_opinion:
                st.markdown("#### ì „ë¬¸ê°€ ì˜ê²¬")
                st.write(expert_opinion)
    
    # ===== ì‹œê°í™” ì¶”ê°€ =====
    visualizations = analysis_data.get("visualizations", {})
    panorama_images = visualizations.get("panorama_images", [])
    
    if panorama_images:
        st.markdown("---")
        st.markdown("#### ğŸ“· íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€")
        cols = st.columns(2)
        for idx, img_info in enumerate(panorama_images[:6]):  # ìµœëŒ€ 6ê°œ
            col_idx = idx % 2
            with cols[col_idx]:
                img_path = img_info.get("path")
                img_name = img_info.get("name", f"Image {idx+1}")
                
                if img_path and Path(img_path).exists():
                    try:
                        st.image(img_path, caption=img_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {img_name}")
    
    # ê³µê°„ ë¶„ì„ ì§€ë„
    spatial_files = visualizations.get("spatial_files", [])
    if spatial_files:
        st.markdown("---")
        st.markdown("#### ğŸ—ºï¸ ê³µê°„ ë¶„ì„")
        for file_info in spatial_files:
            file_path = file_info.get("path")
            file_name = file_info.get("name", "Unknown")
            
            if file_path and Path(file_path).exists():
                if ".png" in str(file_path):
                    try:
                        st.image(file_path, caption=file_name, use_column_width=True)
                    except:
                        pass
                elif ".html" in str(file_path):
                    st.markdown(f"**{file_name}:**")
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            html_content = f.read()
                        st.components.v1.html(html_content, height=600)
                    except Exception as e:
                        st.error(f"ì§€ë„ ë¡œë”© ì‹¤íŒ¨: {e}")
                        st.markdown(f"[ì§€ë„ ë³´ê¸°]({file_path})")

def display_marketplace_analysis(analysis_data):
    """ìƒê¶Œ ë¶„ì„ íƒ­ - Geminië¡œ ë¶„ì„ ê²°ê³¼ ìƒì„±"""
    st.markdown("### ğŸ¬ ìƒê¶Œ ë¶„ì„")
    
    marketplace_data = analysis_data.get("marketplace_analysis", {})
    if not marketplace_data:
        st.info("ìƒê¶Œ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Geminië¡œ ìƒê¶Œ ë¶„ì„ ê²°ê³¼ ìƒì„±
    try:
        if not GEMINI_AVAILABLE:
            st.warning("Gemini í´ë¼ì´ì–¸íŠ¸ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        client = GeminiClient()
        
        # ìƒê¶Œ ë°ì´í„°ë¥¼ Geminiì—ê²Œ ì „ë‹¬í•˜ì—¬ ë¶„ì„
        prompt = f"""
ë‹¤ìŒ ìƒê¶Œ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ìƒì„¸í•œ ìƒê¶Œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ìƒê¶Œ ë°ì´í„°:
{json.dumps(marketplace_data, ensure_ascii=False, indent=2)}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

## ğŸ¬ ìƒê¶Œ ê°œìš”
- ìƒê¶Œëª…ê³¼ ìœ„ì¹˜ ì •ë³´
- ë¶„ì„ ì‹œì ê³¼ ì£¼ìš” íŠ¹ì§•

## ğŸ“Š í•µì‹¬ ì§€í‘œ ë¶„ì„
- ì í¬ìˆ˜ ë³€í™” ì¶”ì´ì™€ ì˜ë¯¸
- ë§¤ì¶œì•¡ ë³€í™”ì™€ ìƒê¶Œ í™œë ¥ë„
- ë©´ì  ëŒ€ë¹„ ì í¬ ë°€ë„ ë¶„ì„

## ğŸ“ˆ ìƒê¶Œ ë™í–¥ ë¶„ì„
- ì „ë¶„ê¸°/ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„ ë³€í™” í•´ì„
- ìƒê¶Œ ì„±ì¥ì„±ê³¼ ì•ˆì •ì„± í‰ê°€
- ê²½ìŸ í™˜ê²½ê³¼ ì‹œì¥ í¬í™”ë„

## ğŸ’¡ ìƒê¶Œ ì „ë§ ë° ì‹œì‚¬ì 
- í–¥í›„ ì „ë§ê³¼ ê¸°íšŒ ìš”ì†Œ
- ì£¼ì˜í•´ì•¼ í•  ë¦¬ìŠ¤í¬ ìš”ì¸
- ìƒê¶Œ ë‚´ ì…ì§€ ì„ íƒ ê°€ì´ë“œ

ê° ì„¹ì…˜ì„ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        response = client.chat_completion([{"role": "user", "content": prompt}])
        
        # Gemini ì‘ë‹µì„ í‘œì‹œ
        st.markdown(response)
        
    except Exception as e:
        st.error(f"ìƒê¶Œ ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}")
        
        # ë°±ì—…: ê¸°ë³¸ ë°ì´í„° í‘œì‹œ
        st.write(f"**ìƒê¶Œëª…:** {marketplace_data.get('ìƒê¶Œëª…', 'N/A')}")
        st.write(f"**ë¶„ì„ì¼ì‹œ:** {marketplace_data.get('ë¶„ì„ì¼ì‹œ', 'N/A')}")
        
        # ë°ì´í„° ì„¹ì…˜
        data_section = marketplace_data.get("ë°ì´í„°", [])
        if data_section:
            # ì¢…í•©ì˜ê²¬ ì°¾ê¸°
            for item in data_section:
                if item.get("ìœ í˜•") == "ì¢…í•©ì˜ê²¬":
                    st.markdown("#### ì¢…í•©ì˜ê²¬")
                    
                    # ë©´ì  ì •ë³´
                    area_info = item.get("ë©´ì ", {})
                    if area_info:
                        st.write(f"**ë¶„ì„ ë©´ì :** {area_info.get('ë¶„ì„', 'N/A')}ã¡")
                    
                    # ì í¬ìˆ˜ ì •ë³´
                    store_count = item.get("ì í¬ìˆ˜", {})
                    if store_count:
                        current = store_count.get("í˜„ì¬", {})
                        st.write(f"**í˜„ì¬ ì í¬ìˆ˜:** {current.get('ê°’', 'N/A')}ê°œ ({current.get('ê¸°ì¤€', 'N/A')})")
                        
                        # ë³€í™”ëŸ‰
                        quarter_change = store_count.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                        year_change = store_count.get("ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„", {})
                        if quarter_change:
                            st.write(f"**ì „ë¶„ê¸° ëŒ€ë¹„:** {quarter_change.get('ë³€í™”', 'N/A')}ê°œ")
                        if year_change:
                            st.write(f"**ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„:** {year_change.get('ë³€í™”', 'N/A')}ê°œ")
                    
                    # ë§¤ì¶œì•¡ ì •ë³´
                    sales_info = item.get("ë§¤ì¶œì•¡", {})
                    if sales_info:
                        current_sales = sales_info.get("í˜„ì¬", {})
                        st.write(f"**í˜„ì¬ ë§¤ì¶œì•¡:** {current_sales.get('ê°’', 'N/A')}ë§Œì› ({current_sales.get('ê¸°ì¤€', 'N/A')})")
                        
                        # ë³€í™”ëŸ‰
                        quarter_sales = sales_info.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                        if quarter_sales:
                            st.write(f"**ì „ë¶„ê¸° ëŒ€ë¹„:** {quarter_sales.get('ë³€í™”', 'N/A')}ë§Œì›")
                
                break

def display_marketing_analysis(analysis_data):
    """ë§ˆì¼€íŒ… ë¶„ì„ íƒ­"""
    st.markdown("### ğŸ“ˆ ë§ˆì¼€íŒ… ë¶„ì„")
    
    marketing_data = analysis_data.get("marketing_analysis", {})
    if not marketing_data:
        st.info("ë§ˆì¼€íŒ… ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í˜ë¥´ì†Œë‚˜ ë¶„ì„
    persona_analysis = marketing_data.get("persona_analysis", {})
    if persona_analysis:
        st.markdown("#### í˜ë¥´ì†Œë‚˜ ë¶„ì„")
        st.write(f"**í˜ë¥´ì†Œë‚˜ ìœ í˜•:** {persona_analysis.get('persona_type', 'N/A')}")
        st.write(f"**í˜ë¥´ì†Œë‚˜ ì„¤ëª…:** {persona_analysis.get('persona_description', 'N/A')}")
        
        # ë§ˆì¼€íŒ… í†¤
        marketing_tone = persona_analysis.get("marketing_tone", "")
        if marketing_tone:
            st.write(f"**ë§ˆì¼€íŒ… í†¤:** {marketing_tone}")
        
        # í•µì‹¬ ì±„ë„
        key_channels = persona_analysis.get("key_channels", [])
        if key_channels:
            st.markdown("#### í•µì‹¬ ë§ˆì¼€íŒ… ì±„ë„")
            for i, channel in enumerate(key_channels[:5], 1):
                st.write(f"{i}. {channel}")
    
    # ìœ„í—˜ ë¶„ì„
    risk_analysis = marketing_data.get("risk_analysis", {})
    if risk_analysis:
        st.markdown("#### ìœ„í—˜ ë¶„ì„")
        st.write(f"**ì „ì²´ ìœ„í—˜ë„:** {risk_analysis.get('overall_risk_level', 'N/A')}")
        
        detected_risks = risk_analysis.get("detected_risks", [])
        if detected_risks:
            st.write("**ê°ì§€ëœ ìœ„í—˜ ìš”ì†Œ:**")
            for risk in detected_risks[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                st.write(f"- **{risk.get('name', 'N/A')}:** {risk.get('description', 'N/A')} (ìš°ì„ ìˆœìœ„: {risk.get('priority', 'N/A')})")
    
    # ë§ˆì¼€íŒ… ì „ëµ
    strategies = marketing_data.get("marketing_strategies", [])
    if strategies:
        st.markdown("#### ğŸ“ˆ ë§ˆì¼€íŒ… ì „ëµ")
        for i, strategy in enumerate(strategies[:6], 1):  # ìƒìœ„ 6ê°œ í‘œì‹œ
            with st.expander(f"**{i}. {strategy.get('name', 'N/A')}**", expanded=(i==1)):
                st.markdown(f"**ğŸ“‹ ì „ëµ ì„¤ëª…:**")
                st.write(strategy.get('description', 'N/A'))
                
                st.markdown(f"**ğŸ¯ ì˜ˆìƒ íš¨ê³¼:** {strategy.get('expected_impact', 'N/A')}")
                
                # ì „ìˆ  ìƒì„¸ í‘œì‹œ
                tactics = strategy.get("tactics", [])
                if tactics:
                    st.markdown("**âš¡ ì£¼ìš” ì „ìˆ :**")
                    for tactic in tactics:
                        st.write(f"  â€¢ {tactic}")
                
                # ì±„ë„ ì •ë³´
                channel = strategy.get("channel", "N/A")
                if channel != "N/A":
                    st.markdown(f"**ğŸ“± ë§ˆì¼€íŒ… ì±„ë„:** {channel}")
                
                # êµ¬í˜„ ì •ë³´
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("â±ï¸ êµ¬í˜„ ê¸°ê°„", strategy.get('implementation_time', 'N/A'))
                with col2:
                    st.metric("ğŸ’° ì˜ˆì‚°", strategy.get('budget_estimate', 'N/A'))
                with col3:
                    st.metric("â­ ìš°ì„ ìˆœìœ„", f"{strategy.get('priority', 'N/A')}")
                
                # ì„±ê³µ ì§€í‘œ
                success_metrics = strategy.get("success_metrics", [])
                if success_metrics:
                    st.markdown("**ğŸ“Š ì„±ê³µ ì§€í‘œ:**")
                    for metric in success_metrics:
                        st.write(f"  âœ“ {metric}")
                
                st.markdown("---")
    
    # ìº í˜ì¸ ê³„íš
    campaign_plan = marketing_data.get("campaign_plan", {})
    if campaign_plan:
        st.markdown("#### ìº í˜ì¸ ê³„íš")
        st.write(f"**ìº í˜ì¸ëª…:** {campaign_plan.get('name', 'N/A')}")
        st.write(f"**ê¸°ê°„:** {campaign_plan.get('duration', 'N/A')}")
        
        expected_kpis = campaign_plan.get("expected_kpis", {})
        if expected_kpis:
            st.write("**ì˜ˆìƒ KPI:**")
            for kpi, value in expected_kpis.items():
                st.write(f"- {kpi}: {value}")

def display_visualizations(analysis_data):
    """ì‹œê°í™” íƒ­"""
    st.markdown("### ğŸ“Š ì‹œê°í™”")
    
    visualizations = analysis_data.get("visualizations", {})
    if not visualizations:
        st.info("ì‹œê°í™” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Store ì°¨íŠ¸ë“¤
    store_charts = visualizations.get("store_charts", [])
    if store_charts:
        st.markdown("#### ğŸª ë§¤ì¥ ë¶„ì„ ì°¨íŠ¸")
        cols = st.columns(2)
        for i, chart_info in enumerate(store_charts[:6]):  # ìµœëŒ€ 6ê°œ í‘œì‹œ
            col_idx = i % 2
            with cols[col_idx]:
                chart_path = chart_info.get("path")
                chart_name = chart_info.get("name", f"Chart {i+1}")
                
                if chart_path and Path(chart_path).exists():
                    try:
                        st.image(chart_path, caption=chart_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name}")
                else:
                    st.write(f"ì°¨íŠ¸ ì—†ìŒ: {chart_name}")
    
    # Mobility ì°¨íŠ¸ë“¤
    mobility_charts = visualizations.get("mobility_charts", [])
    if mobility_charts:
        st.markdown("#### ğŸš¶ ì´ë™ ë¶„ì„ ì°¨íŠ¸")
        cols = st.columns(2)
        for i, chart_info in enumerate(mobility_charts[:6]):  # ìµœëŒ€ 6ê°œ í‘œì‹œ
            col_idx = i % 2
            with cols[col_idx]:
                chart_path = chart_info.get("path")
                chart_name = chart_info.get("name", f"Chart {i+1}")
                
                if chart_path and Path(chart_path).exists():
                    try:
                        st.image(chart_path, caption=chart_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name}")
                else:
                    st.write(f"ì°¨íŠ¸ ì—†ìŒ: {chart_name}")
    
    # Panorama ì´ë¯¸ì§€ë“¤
    panorama_images = visualizations.get("panorama_images", [])
    if panorama_images:
        st.markdown("#### ğŸ˜ï¸ íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì´ë¯¸ì§€")
        cols = st.columns(2)
        for i, img_info in enumerate(panorama_images[:4]):  # ìµœëŒ€ 4ê°œ í‘œì‹œ
            col_idx = i % 2
            with cols[col_idx]:
                img_path = img_info.get("path")
                img_name = img_info.get("name", f"Image {i+1}")
                
                if img_path and Path(img_path).exists():
                    try:
                        st.image(img_path, caption=img_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {img_name}")
                else:
                    st.write(f"ì´ë¯¸ì§€ ì—†ìŒ: {img_name}")
    
    # Spatial íŒŒì¼ë“¤
    spatial_files = visualizations.get("spatial_files", [])
    if spatial_files:
        st.markdown("#### ğŸ—ºï¸ ê³µê°„ ë¶„ì„")
        for file_info in spatial_files:
            file_path = file_info.get("path")
            file_name = file_info.get("name", "Unknown")
            file_type = file_info.get("type", "unknown")
            
            if file_path and Path(file_path).exists():
                if file_type == "spatial_chart" or file_type == "panorama_map":
                    try:
                        st.image(file_path, caption=file_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {file_name}")
                elif file_type == "spatial_map" or file_type == "panorama_map":
                    st.write(f"**{file_name}:** [ì§€ë„ íŒŒì¼]({file_path})")
                else:
                    st.write(f"**{file_name}:** {file_path}")
            else:
                st.write(f"íŒŒì¼ ì—†ìŒ: {file_name}")
    
    if not store_charts and not mobility_charts and not panorama_images and not spatial_files:
        st.info("í‘œì‹œí•  ì‹œê°í™” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

def save_final_reports(store_code, md_content, json_content):
    """ìµœì¢… ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥"""
    try:
        output_dir = Path(__file__).parent.parent / "output"
        output_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_dir = output_dir / f"final_reports_{store_code}_{timestamp}"
        report_dir.mkdir(parents=True, exist_ok=True)
        
        # MD íŒŒì¼ ì €ì¥
        if md_content:
            md_file = report_dir / "final.md"
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(md_content)
            print(f"Final MD saved: {md_file}")
        
        # JSON íŒŒì¼ ì €ì¥
        if json_content:
            json_file = report_dir / "final.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(json_content, f, ensure_ascii=False, indent=2)
            print(f"Final JSON saved: {json_file}")
        
        return str(report_dir)
        
    except Exception as e:
        print(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

def merge_all_analysis_files(analysis_data):
    """ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ JSONê³¼ MDë¡œ í†µí•© (ìš”ì•½ì´ ì•„ë‹Œ ì›ë³¸ ë°ì´í„° ì „ë¶€)"""
    try:
        # í†µí•©ëœ ì „ì²´ ë°ì´í„°
        merged_data = {
            "store_code": analysis_data.get("store_code", "N/A"),
            "analysis_timestamp": datetime.now().isoformat(),
            "analysis_directory": analysis_data.get("analysis_dir", "N/A"),
            "store_analysis": analysis_data.get("store_analysis", {}),
            "marketing_analysis": analysis_data.get("marketing_analysis", {}),
            "marketplace_analysis": analysis_data.get("marketplace_analysis", {}),
            "panorama_analysis": analysis_data.get("panorama_analysis", {}),
            "mobility_analysis": analysis_data.get("mobility_analysis", {}),
            "comprehensive_analysis": analysis_data.get("comprehensive_analysis", {}),
            "visualizations": analysis_data.get("visualizations", {})
        }
        
        # ë¶„ì„ ë””ë ‰í† ë¦¬ì— í†µí•© íŒŒì¼ ì €ì¥
        if "analysis_dir" in analysis_data:
            analysis_dir = Path(analysis_data["analysis_dir"])
            
            # JSON íŒŒì¼ ì €ì¥
            merged_json_file = analysis_dir / "merged_analysis_full.json"
            with open(merged_json_file, 'w', encoding='utf-8') as f:
                json.dump(merged_data, f, ensure_ascii=False, indent=2)
            
            print(f"[OK] í†µí•© JSON íŒŒì¼ ì €ì¥: {merged_json_file}")
            print(f"[OK] í†µí•© ë°ì´í„° í¬ê¸°: {len(json.dumps(merged_data))} bytes")
            
            # MD íŒŒì¼ ìƒì„±
            merged_md_file = analysis_dir / "merged_analysis_full.md"
            md_content = generate_comprehensive_markdown(merged_data)
            
            with open(merged_md_file, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            print(f"[OK] í†µí•© MD íŒŒì¼ ì €ì¥: {merged_md_file}")
            
            return str(merged_json_file), str(merged_md_file)
        
        return None, None
        
    except Exception as e:
        print(f"[ERROR] í†µí•© íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def generate_comprehensive_markdown(merged_data):
    """í†µí•© ë¶„ì„ ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
    store_code = merged_data.get("store_code", "N/A")
    timestamp = merged_data.get("analysis_timestamp", "N/A")
    
    md = f"""# ë§¤ì¥ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ (ì „ì²´)

## ê¸°ë³¸ ì •ë³´
- ìƒì  ì½”ë“œ: {store_code}
- ë¶„ì„ ì¼ì‹œ: {timestamp}
- ë¶„ì„ ë””ë ‰í† ë¦¬: {merged_data.get('analysis_directory', 'N/A')}

---

"""
    
    # 1. Store ë¶„ì„
    store_analysis = merged_data.get("store_analysis", {})
    if store_analysis:
        md += f"""## 1. ë§¤ì¥ ë¶„ì„ (Store Analysis)

### ê¸°ë³¸ ì •ë³´
"""
        store_summary = store_analysis.get("store_summary", {})
        if store_summary:
            md += f"""- ë§¤ì¥ëª…: {store_summary.get('store_name', 'N/A')}
- ì—…ì¢…: {store_summary.get('industry', 'N/A')}
- ìƒê¶Œ: {store_summary.get('commercial_area', 'N/A')}
- í’ˆì§ˆ ì ìˆ˜: {store_summary.get('quality_score', 'N/A')}
- ì£¼ìš” ê³ ê°ì¸µ: {store_summary.get('main_customer', 'N/A')}
- ê³ ê° ìœ í˜•: {store_summary.get('customer_type', 'N/A')}

"""
    
    # 2. Marketing ë¶„ì„
    marketing_analysis = merged_data.get("marketing_analysis", {})
    if marketing_analysis:
        md += f"""## 2. ë§ˆì¼€íŒ… ë¶„ì„ (Marketing Analysis)

### í˜ë¥´ì†Œë‚˜ ì •ë³´
- í˜ë¥´ì†Œë‚˜ íƒ€ì…: {marketing_analysis.get('persona_type', 'N/A')}
- ë¦¬ìŠ¤í¬ ë ˆë²¨: {marketing_analysis.get('risk_level', 'N/A')}

### ë§ˆì¼€íŒ… ì „ëµ
"""
        strategies = marketing_analysis.get("strategies", [])
        for i, strategy in enumerate(strategies, 1):
            md += f"""
#### ì „ëµ {i}: {strategy.get('title', 'N/A')}
- ì„¤ëª…: {strategy.get('description', 'N/A')}
- íƒ€ê²Ÿ: {strategy.get('target', 'N/A')}
- ì˜ˆìƒ íš¨ê³¼: {strategy.get('expected_impact', 'N/A')}
"""
        
        md += "\n### ë§ˆì¼€íŒ… ìº í˜ì¸\n"
        campaigns = marketing_analysis.get("campaigns", [])
        for i, campaign in enumerate(campaigns, 1):
            md += f"""
#### ìº í˜ì¸ {i}: {campaign.get('name', 'N/A')}
- ì„¤ëª…: {campaign.get('description', 'N/A')}
- ì±„ë„: {campaign.get('channels', 'N/A')}
- ì˜ˆì‚°: {campaign.get('budget', 'N/A')}
"""
    
    # 3. Marketplace ë¶„ì„
    marketplace_analysis = merged_data.get("marketplace_analysis", {})
    if marketplace_analysis:
        md += f"""## 3. ìƒê¶Œ ë¶„ì„ (Marketplace Analysis)

### ê¸°ë³¸ ì •ë³´
- ìƒê¶Œëª…: {marketplace_analysis.get('ìƒê¶Œëª…', 'N/A')}
- ë¶„ì„ì¼ì‹œ: {marketplace_analysis.get('ë¶„ì„ì¼ì‹œ', 'N/A')}

### ìƒê¶Œ ë°ì´í„°
"""
        data_section = marketplace_analysis.get("ë°ì´í„°", [])
        for item in data_section:
            if item.get("ìœ í˜•") == "ì¢…í•©ì˜ê²¬":
                area_info = item.get("ë©´ì ", {})
                if area_info:
                    md += f"- ë¶„ì„ ë©´ì : {area_info.get('ë¶„ì„', 'N/A')}ã¡\n"
                
                store_count = item.get("ì í¬ìˆ˜", {})
                if store_count:
                    current = store_count.get("í˜„ì¬", {})
                    md += f"- í˜„ì¬ ì í¬ìˆ˜: {current.get('ê°’', 'N/A')}ê°œ ({current.get('ê¸°ì¤€', 'N/A')})\n"
                    
                    quarter_change = store_count.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                    if quarter_change:
                        md += f"- ì „ë¶„ê¸° ëŒ€ë¹„: {quarter_change.get('ë³€í™”', 'N/A')}ê°œ\n"
                    
                    year_change = store_count.get("ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„", {})
                    if year_change:
                        md += f"- ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„: {year_change.get('ë³€í™”', 'N/A')}ê°œ\n"
                
                sales_info = item.get("ë§¤ì¶œì•¡", {})
                if sales_info:
                    current_sales = sales_info.get("í˜„ì¬", {})
                    md += f"- í˜„ì¬ ë§¤ì¶œì•¡: {current_sales.get('ê°’', 'N/A')}ë§Œì› ({current_sales.get('ê¸°ì¤€', 'N/A')})\n"
                    
                    quarter_sales = sales_info.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                    if quarter_sales:
                        md += f"- ì „ë¶„ê¸° ëŒ€ë¹„: {quarter_sales.get('ë³€í™”', 'N/A')}ë§Œì›\n"
                
                break
    
    # 4. Panorama ë¶„ì„
    panorama_analysis = merged_data.get("panorama_analysis", {})
    if panorama_analysis:
        md += f"""
## 4. íŒŒë…¸ë¼ë§ˆ ë¶„ì„ (Panorama Analysis)

### ìœ„ì¹˜ ì •ë³´
- ì£¼ì†Œ: {panorama_analysis.get('address', 'N/A')}
- ì¢Œí‘œ: {panorama_analysis.get('coordinates', 'N/A')}
- í–‰ì •ë™: {panorama_analysis.get('administrative_dong', 'N/A')}
- ìƒê¶Œ: {panorama_analysis.get('marketplace', 'N/A')}

"""
    
    # 5. Mobility ë¶„ì„
    mobility_analysis = merged_data.get("mobility_analysis", {})
    if mobility_analysis:
        md += f"""## 5. ì´ë™ íŒ¨í„´ ë¶„ì„ (Mobility Analysis)

### ì´ë™ ë°ì´í„°
- ë°ì´í„° í¬í•¨: {len(mobility_analysis)} í•­ëª©

"""
    
    # 6. Comprehensive ë¶„ì„
    comprehensive_analysis = merged_data.get("comprehensive_analysis", {})
    if comprehensive_analysis:
        md += f"""## 6. ì¢…í•© ë¶„ì„ (Comprehensive Analysis)

{json.dumps(comprehensive_analysis, ensure_ascii=False, indent=2)}

"""
    
    # 7. ì‹œê°í™” ì •ë³´
    visualizations = merged_data.get("visualizations", {})
    if visualizations:
        md += f"""## 7. ì‹œê°í™” íŒŒì¼ ëª©ë¡

"""
        for viz_type, files in visualizations.items():
            md += f"### {viz_type}\n"
            for file_info in files:
                md += f"- {file_info.get('name', 'N/A')}: {file_info.get('path', 'N/A')}\n"
    
    md += f"""
---

## ë¶„ì„ ì™„ë£Œ
ì´ ë¦¬í¬íŠ¸ëŠ” ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•œ ì „ì²´ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ìƒë‹´ ëª¨ë“œì—ì„œ ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
    
    return md

# ë©”ì¸ 2íŒ¨ë„ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([1, 1])

# ì™¼ìª½ íŒ¨ë„: ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
with col1:
    st.markdown("## BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤")
    
    # ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€
    if not st.session_state.messages:
        st.session_state.messages = [{
            "role": "assistant", 
            "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¹„ë°€ ìƒë‹´ì‚¬ AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤. 10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì‹œë©´ ì¢…í•© ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. (ì˜ˆ: 000F03E44A, 002816BA73)"
        }]
    
    # ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    # ë¶„ì„ ì¤‘ì¼ ë•Œ ë¡œë”© í‘œì‹œ
    if st.session_state.is_analyzing:
        with st.chat_message("assistant"):
            st.markdown("ğŸ”„ 5ì°¨ì› ì¢…í•© ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ì•½ 3-5ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.")
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # Query Classifierë¡œ ì˜ë„ íŒŒì•…
        if AGENTS_AVAILABLE:
            query_result = classify_query_sync(prompt)
            intent = query_result.get("intent", "general_consultation")
            detected_store_code = query_result.get("store_code")
            
            # 1. ìƒì  ì½”ë“œ ì¿¼ë¦¬
            if intent == "store_code_query" and detected_store_code and not st.session_state.analysis_complete:
                store_code = detected_store_code
                st.session_state.store_code = store_code
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸
                print(f"[DEBUG] ìƒì  ì½”ë“œ {store_code}ì— ëŒ€í•œ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸ ì¤‘...")
                existing_analysis = load_analysis_data_from_output(store_code)
                print(f"[DEBUG] ê¸°ì¡´ ë¶„ì„ ê²°ê³¼: {existing_analysis is not None}")
                
                if existing_analysis:
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"âœ… ìƒì  ì½”ë“œ {store_code}ì˜ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤! ë°”ë¡œ í‘œì‹œí•˜ê² ìŠµë‹ˆë‹¤."
                    })
                    st.session_state.analysis_data = existing_analysis
                    st.session_state.analysis_complete = True
                    st.session_state.is_analyzing = False
                    
                    # ê¸°ì¡´ ë¶„ì„ë„ í†µí•© íŒŒì¼ ìƒì„± (JSON + MD)
                    merged_json, merged_md = merge_all_analysis_files(existing_analysis)
                    if merged_json and merged_md:
                        print(f"[OK] ê¸°ì¡´ ë¶„ì„ í†µí•© íŒŒì¼ ìƒì„±ë¨: JSON={merged_json}, MD={merged_md}")
                    
                    st.rerun()
                else:
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤... 5ì°¨ì› ì¢…í•© ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ì•½ 3-5ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤."
                    })
                    st.session_state.is_analyzing = True
                    st.rerun()
            
            # 2. ì¬ì‹œì‘ ìš”ì²­
            elif intent == "restart_analysis":
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": "ìƒˆë¡œìš´ ë¶„ì„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
                })
                # ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.analysis_complete = False
                st.session_state.consultation_mode = False
                st.session_state.consultation_chain = None
                st.session_state.consultation_memory = None
                st.rerun()
            
            # 3. ì¼ë°˜ ìƒë‹´ (Consultation ëª¨ë“œ)
            elif st.session_state.consultation_mode and st.session_state.consultation_chain:
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                with st.spinner("ìƒë‹´ì‚¬ê°€ ë‹µë³€ì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        response = chat_with_consultant(
                            st.session_state.consultation_chain,
                            st.session_state.consultation_memory,
                            prompt
                        )
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    except Exception as e:
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        })
                st.rerun()
            
            # 4. ë¶„ì„ ì™„ë£Œ í›„ ìƒë‹´ ì‹œì‘ ìœ ë„
            elif st.session_state.analysis_complete:
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "ìƒë‹´ ëª¨ë“œë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ 'ğŸ’¬ ìƒë‹´ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. AI ìƒë‹´ì‚¬ê°€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤."
                })
                st.rerun()
            
            # 5. ê¸°ë³¸ (ìƒì  ì½”ë“œ ì…ë ¥ ìœ ë„)
            else:
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 000F03E44A, 002816BA73)"
                })
                st.rerun()
        
        else:
            # Agents ë¯¸ì‚¬ìš© ì‹œ ê°„ë‹¨í•œ ì •ê·œì‹ ë§¤ì¹­
            import re
            store_code_match = re.search(r'[A-Z0-9]{10}', prompt)
            
            if store_code_match and not st.session_state.analysis_complete:
                store_code = store_code_match.group()
                st.session_state.store_code = store_code
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                existing_analysis = load_analysis_data_from_output(store_code)
                
                if existing_analysis:
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"âœ… ìƒì  ì½”ë“œ {store_code}ì˜ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!"
                    })
                    st.session_state.analysis_data = existing_analysis
                    st.session_state.analysis_complete = True
                    st.session_state.is_analyzing = False
                    st.rerun()
                else:
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
                    })
                    st.session_state.is_analyzing = True
                    st.rerun()
            else:
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 000F03E44A)"
                })
                st.rerun()

# ì˜¤ë¥¸ìª½ íŒ¨ë„: ë¶„ì„ ê²°ê³¼ ëŒ€ì‹œë³´ë“œ
with col2:
    st.markdown("## ë¶„ì„ ê²°ê³¼")
    
    # ë¶„ì„ ì§„í–‰ ì¤‘
    if st.session_state.is_analyzing and not st.session_state.analysis_complete:
        st.info("ğŸ”„ ë¶„ì„ ì§„í–‰ ì¤‘...")
        
        # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
        try:
            result = asyncio.run(run_full_analysis_pipeline(st.session_state.store_code))
            
            if result and result.get("status") == "success":
                st.session_state.is_analyzing = False
                st.session_state.analysis_complete = True
                st.session_state.analysis_data = result
                
                # ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ í†µí•© (JSON + MD)
                merged_json, merged_md = merge_all_analysis_files(result)
                if merged_json and merged_md:
                    print(f"[OK] í†µí•© ë¶„ì„ íŒŒì¼ ìƒì„±ë¨: JSON={merged_json}, MD={merged_md}")
                
                # ì™„ë£Œ ë©”ì‹œì§€ ì¶”ê°€
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": "ë¶„ì„ ì™„ë£Œ! ìš°ì¸¡ íŒ¨ë„ì—ì„œ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"
                })
                
                # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ í‘œì‹œ
                if st.button("ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (Gemini)", type="primary"):
                    with st.spinner("Geminië¡œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„± ì¤‘..."):
                        md_content, json_content = generate_final_report_with_gemini(result)
                        if md_content:
                            report_dir = save_final_reports(st.session_state.store_code, md_content, json_content)
                            if report_dir:
                                st.success(f"ìµœì¢… ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_dir}")
                                st.session_state.final_report_generated = True
                                st.rerun()
                        else:
                            st.error("ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                st.rerun()
            else:
                st.error("ë¶„ì„ ì‹¤íŒ¨")
                st.session_state.is_analyzing = False
                st.rerun()
                
        except Exception as e:
            st.error(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            st.session_state.is_analyzing = False
            st.rerun()
    
    # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ
    elif st.session_state.analysis_complete and st.session_state.analysis_data:
        # ì‹¤ì œ output í´ë”ì—ì„œ ë°ì´í„° ë¡œë“œ
        store_code = st.session_state.store_code
        analysis_data = load_analysis_data_from_output(store_code)
        
        if not analysis_data:
            st.error("ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ({analysis_data['timestamp']})")
            
            # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
            display_basic_info(analysis_data)
            
            # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼
            display_final_report_button(store_code, analysis_data)
            
            # ìƒë‹´ ì‹œì‘ ë²„íŠ¼
            st.markdown("---")
            if not st.session_state.consultation_mode:
                if st.button("ğŸ’¬ ìƒë‹´ ì‹œì‘", type="primary", use_container_width=True):
                    if AGENTS_AVAILABLE:
                        with st.spinner("ìƒë‹´ ì‹œìŠ¤í…œì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤..."):
                            try:
                                # í†µí•© ë¶„ì„ íŒŒì¼ ë¡œë“œ
                                merged_data, merged_md = load_merged_analysis(analysis_data["analysis_dir"])
                                
                                if merged_data and merged_md:
                                    print(f"[OK] í†µí•© íŒŒì¼ ë¡œë“œ ì™„ë£Œ")
                                    print(f"[DEBUG] Analysis Dir: {analysis_data['analysis_dir']}")
                                    print(f"[DEBUG] MD íŒŒì¼ í¬ê¸°: {len(merged_md)} bytes")
                                    
                                    # Langchain Consultation Chain ìƒì„±
                                    chain, memory = create_consultation_chain(store_code, merged_data, merged_md)
                                    
                                    if chain and memory:
                                        st.session_state.consultation_chain = chain
                                        st.session_state.consultation_memory = memory
                                        st.session_state.merged_data = merged_data
                                        st.session_state.merged_md = merged_md
                                        st.session_state.consultation_mode = True
                                        
                                        st.session_state.messages.append({
                                            "role": "assistant",
                                            "content": "ìƒë‹´ì„ ì‹œì‘í•©ë‹ˆë‹¤! í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ğŸ“Š"
                                        })
                                        st.success("âœ… ìƒë‹´ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                        st.rerun()
                                    else:
                                        st.error("ìƒë‹´ ì²´ì¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                else:
                                    st.error(f"í†µí•© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            except Exception as e:
                                st.error(f"ìƒë‹´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                                import traceback
                                traceback.print_exc()
                    else:
                        st.warning("AI Agentsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            else:
                st.info("âœ… ìƒë‹´ ëª¨ë“œ í™œì„±í™”ë¨ - ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!")
            
            # íƒ­ìœ¼ë¡œ ìƒì„¸ ê²°ê³¼ í‘œì‹œ
            tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
                "ê°œìš”", "ê³ ê° ë¶„ì„", "ì´ë™ íŒ¨í„´", "ì§€ì—­ ë¶„ì„", "ìƒê¶Œ ë¶„ì„", "ë§ˆì¼€íŒ…", "ì‹œê°í™”"
            ])
            
            with tab1:
                display_store_overview(analysis_data)
            
            with tab2:
                display_customer_analysis(analysis_data)
            
            with tab3:
                display_mobility_analysis(analysis_data)
            
            with tab4:
                display_panorama_analysis(analysis_data)
            
            with tab5:
                display_marketplace_analysis(analysis_data)
            
            with tab6:
                display_marketing_analysis(analysis_data)
            
            with tab7:
                display_visualizations(analysis_data)
    
    else:
        # ì´ˆê¸° ìƒíƒœ
        st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”!")
        
        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ìƒì  ì½”ë“œ ì˜ˆì‹œ í‘œì‹œ
        st.markdown("### ğŸ“Š ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ìƒì  ì½”ë“œ:")
        st.code("000F03E44A  # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ìˆìŒ")
        st.code("002816BA73  # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ìˆìŒ")
