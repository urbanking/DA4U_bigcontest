"""

BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤

Langchain + Gemini ë²„ì „ (OpenAI Agents SDK ì œê±°)

"""

import streamlit as st


# í˜ì´ì§€ ì„¤ì • (ê°€ì¥ ë¨¼ì € ì‹¤í–‰ë˜ì–´ì•¼ í•¨)
st.set_page_config(
    page_title="BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤",
    page_icon="ğŸª",
    layout="wide",
    initial_sidebar_state="expanded"
)

from pathlib import Path

import json

import asyncio

import os

import sys

import time

from datetime import datetime

import platform

from dotenv import load_dotenv

import io

import threading

from contextlib import redirect_stdout, redirect_stderr

import logging

from streamlit_autorefresh import st_autorefresh



# .env íŒŒì¼ ë¡œë“œ
load_dotenv()



# í•œê¸€ í°íŠ¸ ì„¤ì •
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import seaborn as sns

def set_korean_font():
    """í•œê¸€ í°íŠ¸ ì„¤ì •"""
    system = platform.system()
    
    if system == "Windows":
        font_name = "Malgun Gothic"
    elif system == "Darwin":  # macOS
        font_name = "AppleGothic"
    else:  # Linux
        font_name = "DejaVu Sans"
    
    # matplotlib í°íŠ¸ ì„¤ì •
    plt.rcParams['font.family'] = font_name
    plt.rcParams['axes.unicode_minus'] = False
    
    # seaborn í°íŠ¸ ì„¤ì •
    sns.set_style("whitegrid")
    sns.set_palette("husl")
    
    return font_name

# í°íŠ¸ ì„¤ì • ì‹¤í–‰
KOREAN_FONT = set_korean_font()

# ì°¨íŠ¸ í°íŠ¸ ì„¤ì • í•¨ìˆ˜
def configure_chart_fonts():
    """ì°¨íŠ¸ì—ì„œ í•œê¸€ í°íŠ¸ ì„¤ì •"""
    # Plotly í°íŠ¸ ì„¤ì •
    import plotly.graph_objects as go
    import plotly.express as px
    
    # Plotly ê¸°ë³¸ í°íŠ¸ ì„¤ì •
    go.layout.template = "plotly_white"
    
    # Plotly í°íŠ¸ ì„¤ì •ì„ ìœ„í•œ ë ˆì´ì•„ì›ƒ
    plotly_font_config = {
        'family': 'Malgun Gothic, ë§‘ì€ ê³ ë”•, sans-serif',
        'size': 12,
        'color': 'black'
    }
    
    return plotly_font_config

# ì°¨íŠ¸ í°íŠ¸ ì„¤ì • ì‹¤í–‰
CHART_FONT_CONFIG = configure_chart_fonts()

# Streamlit CSS ì„¤ì • (í•œê¸€ í°íŠ¸)

# CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
st.markdown(f"""
<style>
    /* í•œê¸€ í°íŠ¸ ì„¤ì • */
    .main .block-container {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
    
    .stApp {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
    
    .stSelectbox label,
    .stTextInput label,
    .stTextArea label,
    .stNumberInput label,
    .stDateInput label,
    .stTimeInput label,
    .stFileUploader label,
    .stRadio label,
    .stCheckbox label,
    .stSlider label,
    .stMultiSelect label {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
    
    /* ì°¨íŠ¸ ì œëª© ë° ë¼ë²¨ í°íŠ¸ ì„¤ì • */
    .plotly-graph-div {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif !important;
    }}
    
    /* í…Œì´ë¸” í°íŠ¸ ì„¤ì • */
    .dataframe {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
    
    /* ë©”íŠ¸ë¦­ í°íŠ¸ ì„¤ì • */
    .metric-container {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
    
    /* ì•Œë¦¼ ë©”ì‹œì§€ í°íŠ¸ ì„¤ì • */
    .stAlert {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
    
    /* ë²„íŠ¼ í°íŠ¸ ì„¤ì • */
    .stButton button {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
    
    /* íƒ­ í°íŠ¸ ì„¤ì • */
    .stTabs [data-baseweb="tab-list"] {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
    
    /* ì‚¬ì´ë“œë°” í°íŠ¸ ì„¤ì • */
    .css-1d391kg {{
        font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
    }}
</style>
""", unsafe_allow_html=True)


# ê°œì„ ëœ Streamlit ë¡œê¹… í•¸ë“¤ëŸ¬

class StreamlitHandler(logging.Handler):

    def emit(self, record):

        log_entry = self.format(record)

        if "log_data" not in st.session_state:

            st.session_state["log_data"] = ""

        st.session_state["log_data"] += log_entry + "\n"

        

        # ë¡œê·¸ê°€ ë„ˆë¬´ ë§ì•„ì§€ë©´ ìµœê·¼ 1000ì¤„ë§Œ ìœ ì§€

        if len(st.session_state["log_data"].split('\n')) > 1000:

            lines = st.session_state["log_data"].split('\n')

            st.session_state["log_data"] = '\n'.join(lines[-1000:])



# ë¡œê±° ì„¤ì •

logger = logging.getLogger(__name__)

handler = StreamlitHandler()

formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')

handler.setFormatter(formatter)

logger.addHandler(handler)

logger.setLevel(logging.INFO)



# ê¸°ì¡´ LogCapture í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤

class LogCapture:

    def __init__(self):

        self.logs = []

        

    def add_log(self, message, level="INFO"):

        """ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ ì¶”ê°€"""

        if level == "INFO":

            logger.info(message)

        elif level == "SUCCESS":

            logger.info(f"âœ… {message}")

        elif level == "ERROR":

            logger.error(message)

        elif level == "WARN":

            logger.warning(message)

        elif level == "DEBUG":

            logger.debug(message)

        elif level == "OK":

            logger.info(f"âœ“ {message}")

        else:

            logger.info(f"[{level}] {message}")

        

    def get_logs(self, max_lines=100):

        """ìµœê·¼ ë¡œê·¸ ë°˜í™˜"""

        if "log_data" in st.session_state:

            lines = st.session_state["log_data"].split('\n')

            return lines[-max_lines:] if lines else []

        return []

        

    def clear_logs(self):

        """ë¡œê·¸ ì´ˆê¸°í™”"""

        if "log_data" in st.session_state:

            st.session_state["log_data"] = ""



# ì „ì—­ ë¡œê·¸ ìº¡ì²˜ ì¸ìŠ¤í„´ìŠ¤

log_capture = LogCapture()



# ëˆ„ë½ëœ í•¨ìˆ˜ë“¤ ì •ì˜
def convert_store_to_marketing_format(store_analysis):
    """Store ë¶„ì„ ê²°ê³¼ë¥¼ ë§ˆì¼€íŒ… ì—ì´ì „íŠ¸ìš© í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    if not store_analysis:
        return None
    
    # ê¸°ë³¸ ë³€í™˜ ë¡œì§
    marketing_format = {
        "store_code": store_analysis.get("store_code", ""),
        "store_overview": store_analysis.get("store_overview", {}),
        "sales_analysis": store_analysis.get("sales_analysis", {}),
        "customer_analysis": store_analysis.get("customer_analysis", {}),
        "analysis_timestamp": datetime.now().isoformat()
    }
    
    return marketing_format

def _convert_enums_to_strings(obj):
    """Enum ê°ì²´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜"""
    if isinstance(obj, dict):
        return {key: _convert_enums_to_strings(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [_convert_enums_to_strings(item) for item in obj]
    elif hasattr(obj, 'value'):  # Enum ê°ì²´
        return obj.value
    else:
        return obj

# ë¶„ì„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ í•¨ìˆ˜

def update_analysis_progress(step: str, status: str = "in_progress"):

    """ë¶„ì„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸"""

    if "analysis_progress" not in st.session_state:

        st.session_state.analysis_progress = {}

    

    st.session_state.analysis_progress[step] = status



# matplotlib import ë° ì„¤ì •

import matplotlib

import matplotlib.pyplot as plt

import seaborn as sns



# í•œê¸€ í°íŠ¸ ì„¤ì •ì€ ìœ„ì—ì„œ ì´ë¯¸ ì²˜ë¦¬ë¨


print("[OK] Matplotlib loaded successfully")









# run_analysis.py ì§ì ‘ import

sys.path.insert(0, str(Path(__file__).parent.parent))  # open_sdk ë””ë ‰í† ë¦¬ ì¶”ê°€

sys.path.insert(0, str(Path(__file__).parent.parent.parent / "agents_new"))  # agents_new ì¶”ê°€

from run_analysis import run_full_analysis_pipeline

# Marketing Module import (LangChain Version)
MARKETING_MODULE_AVAILABLE = False
try:
    from agents_new.marketing_agent.marketing_langchain import run_marketing_sync_langchain as run_marketing_sync
    MARKETING_MODULE_AVAILABLE = True
    print("[OK] Marketing Module (LangChain) loaded successfully")
except ImportError as e:

    print(f"[WARN] Marketing Module import failed: {e}")
except Exception as e:

    print(f"[ERROR] Marketing Module error: {e}")
    import traceback
    traceback.print_exc()

# Google Maps MCP Lookup import (HTTP Version)
MCP_LOOKUP_AVAILABLE = False
GOOGLE_MAPS_TOOLS_AVAILABLE = False
try:
    from agents_new.google_map_mcp.http_client import run_lookup_from_code_http as run_gm_lookup
    from agents_new.google_map_mcp.langchain_tools import get_google_maps_tools
    MCP_LOOKUP_AVAILABLE = True
    GOOGLE_MAPS_TOOLS_AVAILABLE = True
    print("[OK] Google Maps MCP Lookup (HTTP) loaded successfully")
    print("[OK] Google Maps LangChain Tools loaded successfully")
except ImportError as e:
    print(f"[WARN] Google Maps MCP Lookup import failed: {e}")
except Exception as e:
    print(f"[ERROR] Google Maps MCP Lookup error: {e}")
    import traceback

    traceback.print_exc()

# Panorama AnalysisëŠ” ìœ„ì—ì„œ ì´ˆê¸°í™”ë¨

# Langchain AI Agents import

AGENTS_AVAILABLE = False

try:

    from ai_agents import (

        classify_query_sync,

        create_consultation_chain,

        chat_with_consultant,

        load_merged_analysis

    )

    AGENTS_AVAILABLE = True

    print("[OK] Langchain AI Agents loaded successfully")

except ImportError as e:

    print(f"[WARN] AI Agents import failed: {e}")

except Exception as e:

    print(f"[ERROR] AI Agents error: {e}")

    import traceback

    traceback.print_exc()



# OpenAI SDKë¡œ Gemini 2.5 Flash ì‚¬ìš©

try:

    from openai import OpenAI

    OPENAI_AVAILABLE = True

    # OpenAI SDKë¡œ Gemini API í˜¸ì¶œ

    openai_client = OpenAI(

        api_key=os.getenv("GEMINI_API_KEY"),

        base_url="https://generativelanguage.googleapis.com/v1beta/openai/"

    )

    print("[OK] OpenAI SDK with Gemini 2.5 Flash initialized")

except Exception as e:

    OPENAI_AVAILABLE = False

    openai_client = None

    print(f"OpenAI client with Gemini not available: {e}")





# ìë™ ìƒˆë¡œê³ ì¹¨ ë¹„í™œì„±í™” (ë¬´í•œ ë£¨í”„ ë°©ì§€)

# if st.session_state.get('is_analyzing', False) and not st.session_state.get('stop_autorefresh', False):

#     st_autorefresh(interval=5000, limit=50, key="logrefresh")



# ì»¤ìŠ¤í…€ CSS (í•œê¸€ í°íŠ¸ ì ìš©)

st.markdown("""

    <style>

        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap');

        

        * {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

        

        .stMarkdown, .stText, .stSelectbox, .stTextInput, .stButton, .stMetric, .stExpander {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

        

        .stMarkdown h1, .stMarkdown h2, .stMarkdown h3, .stMarkdown h4, .stMarkdown h5, .stMarkdown h6 {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

        

        .stTabs [data-baseweb="tab-list"] {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

        

        .stTabs [data-baseweb="tab"] {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

        

        .stSelectbox label, .stTextInput label {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

        

        .stButton > button {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

        

        .stMetric [data-testid="metric-container"] {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

        

        .stExpander [data-testid="stExpander"] {

            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;

        }

    </style>

    """, unsafe_allow_html=True)



# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

if 'store_code' not in st.session_state:

    st.session_state.store_code = None

if 'is_analyzing' not in st.session_state:

    st.session_state.is_analyzing = False

if 'analysis_complete' not in st.session_state:

    st.session_state.analysis_complete = False

if 'consultation_mode' not in st.session_state:

    st.session_state.consultation_mode = False

if 'messages' not in st.session_state:

    st.session_state.messages = []

if 'analysis_data' not in st.session_state:

    st.session_state.analysis_data = None

if 'final_report_generated' not in st.session_state:

    st.session_state.final_report_generated = False

if 'consultation_chain' not in st.session_state:

    st.session_state.consultation_chain = None

if 'consultation_memory' not in st.session_state:

    st.session_state.consultation_memory = None

if 'merged_data' not in st.session_state:

    st.session_state.merged_data = None

if 'merged_md' not in st.session_state:

    st.session_state.merged_md = None

if 'mcp_search_initialized' not in st.session_state:

    st.session_state.mcp_search_initialized = False

if 'mcp_search_progress' not in st.session_state:

    st.session_state.mcp_search_progress = {

        "total": 0,

        "processed": 0,

        "success": 0,

        "failed": 0

    }



def generate_marketplace_summary_with_gemini(marketplace_data):

    """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê¶Œ ë¶„ì„ ìš”ì•½ ìƒì„±"""

    try:

        # OpenAI í´ë¼ì´ì–¸íŠ¸ í™•ì¸

        if not OPENAI_AVAILABLE or not openai_client:

            return None

        

        # ìƒê¶Œ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜

        data_text = json.dumps(marketplace_data, ensure_ascii=False, indent=2)

        

        # OpenAI í”„ë¡¬í”„íŠ¸

        prompt = f"""

ë‹¤ìŒì€ ìƒê¶Œ ë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ìƒì„¸í•œ ìƒê¶Œ ë¶„ì„ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.



ìƒê¶Œ ë°ì´í„°:

{data_text}



ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:



## ğŸ¬ ìƒê¶Œ ë¶„ì„ ìš”ì•½



### ğŸ“ ìƒê¶Œ ê°œìš”

- ìƒê¶Œ ìœ í˜•: [ìœ í˜•]

- ë¶„ì„ ë©´ì : [ë©´ì ]

- ì í¬ìˆ˜: [ì í¬ìˆ˜]



### ğŸ“Š ì£¼ìš” ì§€í‘œ

- ë§¤ì¶œ í˜„í™©: [í˜„ì¬ ë§¤ì¶œì•¡]

- ì„±ì¥ë¥ : [ì „ë…„ ëŒ€ë¹„]

- ìƒê¶Œ í™œì„±ë„: [ì í¬ ì¦ê°]



### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸

1. ìƒê¶Œ ê°•ì : [ê°•ì  ë¶„ì„]

2. ìƒê¶Œ ì•½ì : [ì•½ì  ë¶„ì„]

3. ê¸°íšŒ ìš”ì†Œ: [ê¸°íšŒ ë¶„ì„]

4. ìœ„í—˜ ìš”ì†Œ: [ìœ„í—˜ ë¶„ì„]



### ğŸ¯ ì¶”ì²œ ì—…ì¢…

- ì í•©í•œ ì—…ì¢…: [ì—…ì¢… ì¶”ì²œ]

- ì„±ê³µ ìš”ì¸: [ì„±ê³µ ì¡°ê±´]

- ì£¼ì˜ì‚¬í•­: [ì£¼ì˜ì ]



### ğŸ“ˆ ì „ë§ ë° ì œì–¸

- ìƒê¶Œ ì „ë§: [ë¯¸ë˜ ì „ë§]

- ì°½ì—… ì œì–¸: [ì°½ì—… ê°€ì´ë“œ]

- ë§ˆì¼€íŒ… ì „ëµ: [ë§ˆì¼€íŒ… ë°©í–¥]



ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ê´€ì ì—ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.

"""

        

        # OpenAI SDKë¡œ Gemini 2.5 Flash í˜¸ì¶œ

        response = openai_client.chat.completions.create(

            model="gemini-2.5-flash",

            messages=[

                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ìƒê¶Œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},

                {"role": "user", "content": prompt}

            ],

            temperature=0.7,

            max_tokens=2000

        )

        

        if response and response.choices:

            return response.choices[0].message.content

        else:

            return None

            

    except Exception as e:

        print(f"OpenAI ìƒê¶Œ ë¶„ì„ ì‹¤íŒ¨: {e}")

        return None



def generate_final_report_with_gemini(analysis_data):

    """OpenAIë¥¼ ì‚¬ìš©í•´ì„œ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±"""

    if not OPENAI_AVAILABLE or not openai_client:

        return None, None

    

    try:

        # ë¶„ì„ ë°ì´í„°ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜

        analysis_json = json.dumps(analysis_data, ensure_ascii=False, indent=2)

        

        prompt = f"""

ë‹¤ìŒì€ ë§¤ì¥ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.



ë¶„ì„ ë°ì´í„°:

{analysis_json}



ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:



# ë§¤ì¥ ë¶„ì„ ìµœì¢… ë¦¬í¬íŠ¸



## 1. ì‹¤í–‰ ìš”ì•½

- í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ê°€ì§€

- ì£¼ìš” ë¬¸ì œì  2ê°€ì§€  

- ì¶”ì²œ ì „ëµ 3ê°€ì§€



## 2. ë§¤ì¥ í˜„í™© ë¶„ì„

- ë§¤ì¥ ê¸°ë³¸ ì •ë³´

- ë§¤ì¶œ ë° ê³ ê° ë¶„ì„

- ìƒê¶Œ í™˜ê²½ ë¶„ì„



## 3. ë§ˆì¼€íŒ… ì „ëµ

- íƒ€ê²Ÿ ê³ ê° ë¶„ì„

- ì¶”ì²œ ë§ˆì¼€íŒ… ì „ëµ

- ì‹¤í–‰ ê³„íš



## 4. ê°œì„  ë°©ì•ˆ

- ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­

- ì¤‘ì¥ê¸° ë°œì „ ë°©í–¥

- ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘ ë°©ì•ˆ



## 5. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­

- ì¢…í•© í‰ê°€

- ìµœìš°ì„  ì‹¤í–‰ ê³¼ì œ

- ì„±ê³µ ì§€í‘œ ì„¤ì •



JSON í˜•ì‹ìœ¼ë¡œë„ ìš”ì•½í•´ì£¼ì„¸ìš”:

{{

  "executive_summary": {{

    "key_insights": ["ì¸ì‚¬ì´íŠ¸1", "ì¸ì‚¬ì´íŠ¸2", "ì¸ì‚¬ì´íŠ¸3"],

    "main_issues": ["ë¬¸ì œ1", "ë¬¸ì œ2"],

    "recommended_strategies": ["ì „ëµ1", "ì „ëµ2", "ì „ëµ3"]

  }},

  "store_analysis": {{

    "performance_score": 85,

    "strengths": ["ê°•ì 1", "ê°•ì 2"],

    "weaknesses": ["ì•½ì 1", "ì•½ì 2"]

  }},

  "marketing_recommendations": {{

    "target_customers": "íƒ€ê²Ÿ ê³ ê° ì„¤ëª…",

    "primary_strategy": "ì£¼ìš” ì „ëµ",

    "implementation_priority": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ"

  }},

  "action_plan": {{

    "immediate_actions": ["ì¦‰ì‹œ ì‹¤í–‰1", "ì¦‰ì‹œ ì‹¤í–‰2"],

    "short_term_goals": ["ë‹¨ê¸° ëª©í‘œ1", "ë‹¨ê¸° ëª©í‘œ2"],

    "long_term_vision": "ì¥ê¸° ë¹„ì „"

  }}

}}

"""

        

        response = openai_client.chat.completions.create(

            model="gemini-2.5-flash",

            messages=[

                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµê³¼ ëª…í™•í•œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."},

                {"role": "user", "content": prompt}

            ],

            temperature=0.7,

            max_tokens=3000

        )

        

        # MDì™€ JSON ë¶„ë¦¬

        md_content = response.choices[0].message.content

        json_content = None

        

        # JSON ë¶€ë¶„ ì¶”ì¶œ

        if "```json" in md_content:

            json_start = md_content.find("```json") + 7

            json_end = md_content.find("```", json_start)

            if json_end > json_start:

                json_str = md_content[json_start:json_end].strip()

                try:

                    json_content = json.loads(json_str)

                except:

                    json_content = None

        

        return md_content, json_content

        

    except Exception as e:

        print(f"OpenAI ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

        return None, None



def convert_absolute_to_relative_path(absolute_path: str) -> str:

    """ì ˆëŒ€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""

    if not absolute_path:

        return absolute_path

    

    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°

    project_root = Path(__file__).parent.parent.parent

    

    try:

        abs_path = Path(absolute_path)

        if abs_path.is_absolute():

            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°

            relative_path = abs_path.relative_to(project_root)

            return str(relative_path).replace('\\', '/')  # Windows ê²½ë¡œ êµ¬ë¶„ì í†µì¼

        else:

            return absolute_path

    except ValueError:

        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë°–ì˜ ê²½ë¡œì¸ ê²½ìš° ì›ë³¸ ë°˜í™˜

        return absolute_path





def load_analysis_data_from_output(store_code):

    """output í´ë”ì—ì„œ ì‹¤ì œ ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œ"""

    try:

        output_dir = Path(__file__).parent.parent / "output"

        print(f"[DEBUG] output_dir: {output_dir}")

        print(f"[DEBUG] output_dir exists: {output_dir.exists()}")

        

        # ê°€ì¥ ìµœì‹  ë¶„ì„ í´ë” ì°¾ê¸° (analysis_{store_code}_{timestamp} í˜•ì‹)

        analysis_dirs = list(output_dir.glob(f"analysis_{store_code}_*"))

        print(f"[DEBUG] ì°¾ì€ ë¶„ì„ í´ë”: {analysis_dirs}")

        

        if not analysis_dirs:

            print(f"[ERROR] {store_code}ì— ëŒ€í•œ ë¶„ì„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

            return None

        

        # ê°€ì¥ ìµœì‹  í´ë” ì„ íƒ

        latest_dir = max(analysis_dirs, key=os.path.getctime)

        print(f"[INFO] ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ë¡œë“œ: {latest_dir.name}")

        

        # ê° ë¶„ì„ ê²°ê³¼ ë¡œë“œ

        data = {

            "store_code": store_code,

            "analysis_dir": str(latest_dir),

            "is_existing_analysis": True,  # ê¸°ì¡´ ë¶„ì„ì„ì„ í‘œì‹œ

            "timestamp": latest_dir.name.split("_")[-1]

        }

        

        # 1. í†µí•© ë¶„ì„ ê²°ê³¼ (analysis_result.json)

        analysis_file = latest_dir / "analysis_result.json"

        if analysis_file.exists():

            try:

                with open(analysis_file, 'r', encoding='utf-8') as f:

                    data["analysis_result"] = json.load(f)

                print(f"[OK] analysis_result.json ë¡œë“œ ì„±ê³µ")

            except PermissionError:

                print(f"[WARN] analysis_result.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")

            except Exception as e:

                print(f"[WARN] analysis_result.json ë¡œë“œ ì‹¤íŒ¨: {e}")

        

        # 2. ì¢…í•© ë¶„ì„ ê²°ê³¼ (comprehensive_analysis.json) - ì„ íƒì 

        comprehensive_file = latest_dir / "comprehensive_analysis.json"

        if comprehensive_file.exists():

            try:

                with open(comprehensive_file, 'r', encoding='utf-8') as f:

                    data["comprehensive_analysis"] = json.load(f)

                print(f"[OK] comprehensive_analysis.json ë¡œë“œ ì„±ê³µ")

            except PermissionError:

                print(f"[WARN] comprehensive_analysis.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")

            except Exception as e:

                print(f"[WARN] comprehensive_analysis.json ë¡œë“œ ì‹¤íŒ¨: {e}")

        

        # 3. Store ë¶„ì„ ê²°ê³¼ - ì„ íƒì 

        store_file = latest_dir / "store_analysis_report.json"

        if store_file.exists():

            try:

                with open(store_file, 'r', encoding='utf-8') as f:

                    data["store_analysis"] = json.load(f)

                print(f"[OK] store_analysis_report.json ë¡œë“œ ì„±ê³µ")

            except PermissionError:

                print(f"[WARN] store_analysis_report.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")

            except Exception as e:

                print(f"[WARN] store_analysis_report.json ë¡œë“œ ì‹¤íŒ¨: {e}")

        

        # 4. Marketing ë¶„ì„ ê²°ê³¼ - ì„ íƒì 

        marketing_file = latest_dir / "marketing_strategy.json"

        if marketing_file.exists():

            try:

                with open(marketing_file, 'r', encoding='utf-8') as f:

                    data["marketing_analysis"] = json.load(f)

                print(f"[OK] marketing_strategy.json ë¡œë“œ ì„±ê³µ")

            except PermissionError:

                print(f"[WARN] marketing_strategy.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")

            except Exception as e:

                print(f"[WARN] marketing_strategy.json ë¡œë“œ ì‹¤íŒ¨: {e}")

        

        # 5. Marketplace ë¶„ì„ ê²°ê³¼
        # store_analysisì—ì„œ ìƒê¶Œëª… ê°€ì ¸ì˜¤ê¸°
        marketplace_json = None
        commercial_area_name = None
        
        if "store_analysis" in data and data["store_analysis"]:
            try:
                store_analysis = data["store_analysis"]
                # ë¨¼ì € store_overviewì—ì„œ ì§ì ‘ í™•ì¸
                if "store_overview" in store_analysis:
                    commercial_area_name = store_analysis["store_overview"].get("commercial_area", None)
                # ì—†ìœ¼ë©´ json_output ì•ˆì—ì„œ í™•ì¸
                elif "json_output" in store_analysis and "store_overview" in store_analysis["json_output"]:
                    commercial_area_name = store_analysis["json_output"]["store_overview"].get("commercial_area", None)
                
                if commercial_area_name:
                    print(f"[INFO] ìƒê¶Œëª… í™•ì¸: {commercial_area_name}")
                else:
                    print(f"[WARN] ìƒê¶Œëª…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"[WARN] ìƒê¶Œëª… ì¶”ì¶œ ì‹¤íŒ¨: {e}")
        
        # ìƒê¶Œëª…ì´ ìˆìœ¼ë©´ ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤_ê²°ê³¼ í´ë”ì—ì„œ JSON íŒŒì¼ ì°¾ê¸°
        if commercial_area_name:
            marketplace_folder = Path(__file__).parent.parent.parent / "agents_new" / "data outputs" / "ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤_ê²°ê³¼"
            marketplace_json_file = marketplace_folder / f"{commercial_area_name}.json"
            
            if marketplace_json_file.exists():
                try:
                    with open(marketplace_json_file, 'r', encoding='utf-8') as f:
                        marketplace_json = json.load(f)
                    print(f"[OK] ìƒê¶Œ ë¶„ì„ JSON ë¡œë“œ ì„±ê³µ: {commercial_area_name}")
                except Exception as e:
                    print(f"[WARN] ìƒê¶Œ ë¶„ì„ JSON ë¡œë“œ ì‹¤íŒ¨: {e}")
            else:
                print(f"[WARN] ìƒê¶Œ ë¶„ì„ JSON íŒŒì¼ ì—†ìŒ: {marketplace_json_file}")
        
        # marketplace_jsonì´ ìˆìœ¼ë©´ ì‚¬ìš©
        if marketplace_json:
            data["marketplace_analysis"] = marketplace_json
        else:
            # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback: ë¨¼ì € analysis í´ë” ë‚´ë¶€ì—ì„œ ì°¾ê¸°
            marketplace_file = latest_dir / "marketplace" / "marketplace_data.json"
            
            # ë‚´ë¶€ì— ì—†ìœ¼ë©´ ë³„ë„ marketplace_{timestamp} í´ë”ì—ì„œ ì°¾ê¸°
            if not marketplace_file.exists():
                marketplace_dirs = sorted(
                    output_dir.glob("marketplace_*"), 
                    key=os.path.getmtime, 
                    reverse=True
                )
                if marketplace_dirs:
                    marketplace_file = marketplace_dirs[0] / "marketplace_data.json"
                    print(f"[INFO] marketplace íŒŒì¼ì„ ë³„ë„ í´ë”ì—ì„œ ì°¾ìŒ: {marketplace_file.parent.name}")

            if marketplace_file.exists():
                try:
                    with open(marketplace_file, 'r', encoding='utf-8') as f:
                        data["marketplace_analysis"] = json.load(f)
                    print(f"[OK] marketplace_data.json ë¡œë“œ ì„±ê³µ")
                except PermissionError:
                    print(f"[WARN] marketplace_data.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
                except Exception as e:
                    print(f"[WARN] marketplace_data.json ë¡œë“œ ì‹¤íŒ¨: {e}")

        

        # 6. Panorama ë¶„ì„ ê²°ê³¼

        panorama_file = latest_dir / "panorama" / "analysis_result.json"

        if panorama_file.exists():

            try:

                with open(panorama_file, 'r', encoding='utf-8') as f:

                    data["panorama_analysis"] = json.load(f)

                print(f"[OK] panorama analysis_result.json ë¡œë“œ ì„±ê³µ")

            except PermissionError:

                print(f"[WARN] panorama analysis_result.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")

            except Exception as e:

                print(f"[WARN] panorama analysis_result.json ë¡œë“œ ì‹¤íŒ¨: {e}")

        

        # 7. Mobility ë¶„ì„ ê²°ê³¼ - ì„ íƒì 

        mobility_file = latest_dir / "mobility_charts" / "mobility_data.json"

        if mobility_file.exists():

            try:

                with open(mobility_file, 'r', encoding='utf-8') as f:

                    data["mobility_analysis"] = json.load(f)

                print(f"[OK] mobility_data.json ë¡œë“œ ì„±ê³µ")

            except PermissionError:

                print(f"[WARN] mobility_data.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")

            except Exception as e:

                print(f"[WARN] mobility_data.json ë¡œë“œ ì‹¤íŒ¨: {e}")

        

        # 8. ì‹œê°í™” íŒŒì¼ë“¤ ë¡œë“œ

        data["visualizations"] = load_visualization_files(latest_dir)

        

        # ìµœì†Œí•œ í•˜ë‚˜ì˜ ë¶„ì„ ë°ì´í„°ë¼ë„ ìˆìœ¼ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼

        loaded_sections = [k for k, v in data.items() if k not in ["store_code", "analysis_dir", "is_existing_analysis", "timestamp"] and v is not None]

        

        if loaded_sections:

            print(f"[OK] ë¶„ì„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(loaded_sections)}ê°œ ì„¹ì…˜ ({', '.join(loaded_sections)})")

            return data

        else:

            print(f"[ERROR] ë¡œë“œëœ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")

            return None

        

    except Exception as e:

        print(f"[ERROR] ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")

        return None



def load_visualization_files(analysis_dir):

    """ì‹œê°í™” íŒŒì¼ë“¤ì„ ë¡œë“œ"""

    viz_data = {

        "store_charts": [],

        "mobility_charts": [],

        "panorama_images": [],

        "spatial_files": []

    }

    

    try:

        # Store ì°¨íŠ¸ë“¤

        store_charts_dir = analysis_dir / "store_charts"

        if store_charts_dir.exists():

            for chart_file in store_charts_dir.glob("*.png"):

                viz_data["store_charts"].append({

                    "name": chart_file.stem,

                    "path": str(chart_file),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©

                    "absolute_path": str(chart_file),

                    "type": "store_chart"

                })

        

        # Mobility ì°¨íŠ¸ë“¤

        mobility_charts_dir = analysis_dir / "mobility_charts"

        if mobility_charts_dir.exists():

            for chart_file in mobility_charts_dir.glob("*.png"):

                viz_data["mobility_charts"].append({

                    "name": chart_file.stem,

                    "path": str(chart_file),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©

                    "absolute_path": str(chart_file),

                    "type": "mobility_chart"

                })

        

        # Panorama ì´ë¯¸ì§€ë“¤

        panorama_images_dir = analysis_dir / "panorama" / "images"

        if panorama_images_dir.exists():

            for img_file in panorama_images_dir.glob("*.jpg"):

                viz_data["panorama_images"].append({

                    "name": img_file.stem,

                    "path": str(img_file),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©

                    "absolute_path": str(img_file),

                    "type": "panorama_image"

                })

        

        # Spatial ì‹œê°í™” íŒŒì¼ë“¤

        spatial_map = analysis_dir / "spatial_map.html"

        spatial_chart = analysis_dir / "spatial_analysis.png"

        

        if spatial_map.exists():

            viz_data["spatial_files"].append({

                "name": "ê³µê°„ ë¶„ì„ ì§€ë„",

                "path": str(spatial_map),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©

                "absolute_path": str(spatial_map),

                "type": "spatial_map"

            })

        

        if spatial_chart.exists():

            viz_data["spatial_files"].append({

                "name": "ê³µê°„ ë¶„ì„ ì°¨íŠ¸",

                "path": str(spatial_chart),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©

                "absolute_path": str(spatial_chart),

                "type": "spatial_chart"

            })

        

        # Panorama ì§€ë„

        panorama_map = analysis_dir / "panorama" / "analysis_map.html"

        if panorama_map.exists():

            viz_data["spatial_files"].append({

                "name": "íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì§€ë„",

                "path": str(panorama_map),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©

                "absolute_path": str(panorama_map),

                "type": "panorama_map"

            })

        

        print(f"[OK] ì‹œê°í™” íŒŒì¼ ë¡œë“œ: Store({len(viz_data['store_charts'])}), Mobility({len(viz_data['mobility_charts'])}), Panorama({len(viz_data['panorama_images'])}), Spatial({len(viz_data['spatial_files'])})")

        

    except Exception as e:

        print(f"[ERROR] ì‹œê°í™” íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

    

    return viz_data



def load_analysis_files_from_actual_locations(store_code):

    """ì‹¤ì œ ì €ì¥ëœ ë¶„ì„ íŒŒì¼ë“¤ì„ ë¡œë“œ (legacy í•¨ìˆ˜ - í˜¸í™˜ì„± ìœ ì§€)"""

    return load_analysis_data_from_output(store_code)



# ê° íƒ­ë³„ í‘œì‹œ í•¨ìˆ˜ë“¤

def display_basic_info(analysis_data):

    """ê¸°ë³¸ ì •ë³´ í‘œì‹œ"""

    st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")

    

    # Store ë¶„ì„ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ

    store_data = analysis_data.get("store_analysis", {})

    if store_data and "store_overview" in store_data:

        store_info = store_data["store_overview"]

        col1, col2, col3 = st.columns(3)

        

        with col1:

            st.metric("ë§¤ì¥ëª…", store_info.get("name", "N/A"))

        with col2:

            st.metric("ì—…ì¢…", store_info.get("industry", "N/A"))

        with col3:

            st.metric("ìƒê¶Œ", store_info.get("commercial_area", "N/A"))

    

    # Spatial ë¶„ì„ì—ì„œ ì£¼ì†Œ ì •ë³´

    comprehensive = analysis_data.get("comprehensive_analysis", {})

    if comprehensive and "spatial_analysis" in comprehensive:

        spatial = comprehensive["spatial_analysis"]

        st.write(f"**ì£¼ì†Œ:** {spatial.get('address', 'N/A')}")

        st.write(f"**í–‰ì •ë™:** {spatial.get('administrative_dong', 'N/A')}")



def display_final_report_button(store_code, analysis_data):

    """ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ í‘œì‹œ"""

    if not st.session_state.final_report_generated:

        if st.button("ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (Gemini)", type="primary"):

            with st.spinner("Geminië¡œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„± ì¤‘..."):

                md_content, json_content = generate_final_report_with_gemini(analysis_data)

                if md_content:

                    report_dir = save_final_reports(store_code, md_content, json_content)

                    if report_dir:

                        st.success(f"ìµœì¢… ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_dir}")

                        st.session_state.final_report_generated = True

                        st.rerun()

                else:

                    st.error("ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

    else:

        st.info("âœ… ìµœì¢… ë¦¬í¬íŠ¸ê°€ ì´ë¯¸ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")





def generate_comprehensive_analysis_with_gemini(analysis_data):

    """OpenAI SDK(Gemini 2.5 Flash)ë¥¼ ì‚¬ìš©í•´ì„œ ì „ì²´ ë¶„ì„ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""

    try:

        if not OPENAI_AVAILABLE or not openai_client:

            return None

        

        # ë¶„ì„ ë°ì´í„° ìš”ì•½

        store_data = analysis_data.get("store_analysis", {})

        marketing_data = analysis_data.get("marketing_strategy", {})

        panorama_data = analysis_data.get("panorama_analysis", {})

        marketplace_data = analysis_data.get("marketplace_analysis", {})

        mobility_data = analysis_data.get("mobility_analysis", {})

        

        # ë°ì´í„° ìš”ì•½ ìƒì„±

        summary_text = f"""

## ë§¤ì¥ ë¶„ì„ ë°ì´í„° ìš”ì•½



### ğŸª ë§¤ì¥ ê¸°ë³¸ ì •ë³´

- ë§¤ì¥ëª…: {store_data.get('store_overview', {}).get('name', 'N/A')}

- ì—…ì¢…: {store_data.get('store_overview', {}).get('industry', 'N/A')}

- ìƒê¶Œ: {store_data.get('store_overview', {}).get('commercial_area', 'N/A')}

- ìš´ì˜ ê°œì›”: {store_data.get('store_overview', {}).get('operating_months', 'N/A')}ê°œì›”



### ğŸ“ˆ ë§¤ì¶œ ë¶„ì„

- ë§¤ì¶œì•¡ ì¶”ì„¸: {store_data.get('sales_analysis', {}).get('trends', {}).get('sales_amount', {}).get('trend', 'N/A')}

- ë§¤ì¶œê±´ìˆ˜ ì¶”ì„¸: {store_data.get('sales_analysis', {}).get('trends', {}).get('sales_count', {}).get('trend', 'N/A')}

- ê³ ìœ ê³ ê° ì¶”ì„¸: {store_data.get('sales_analysis', {}).get('trends', {}).get('unique_customers', {}).get('trend', 'N/A')}

- í‰ê·  ê±°ë˜ì•¡ ì¶”ì„¸: {store_data.get('sales_analysis', {}).get('trends', {}).get('avg_transaction', {}).get('trend', 'N/A')}



### ğŸ‘¥ ê³ ê° ë¶„ì„

- ì„±ë³„ ë¶„í¬: ë‚¨ì„± {store_data.get('customer_analysis', {}).get('gender_distribution', {}).get('male_ratio', 0):.1f}% / ì—¬ì„± {store_data.get('customer_analysis', {}).get('gender_distribution', {}).get('female_ratio', 0):.1f}%

- ì£¼ìš” ì—°ë ¹ëŒ€: {max(store_data.get('customer_analysis', {}).get('age_group_distribution', {}), key=store_data.get('customer_analysis', {}).get('age_group_distribution', {}).get) if store_data.get('customer_analysis', {}).get('age_group_distribution') else 'N/A'}



### ğŸ¯ ë§ˆì¼€íŒ… ì „ëµ

- ì „ëµ ìˆ˜: {len(marketing_data.get('marketing_strategies', []))}ê°œ

- í˜ë¥´ì†Œë‚˜ ìœ í˜•: {marketing_data.get('persona_analysis', {}).get('persona_type', 'N/A')}



### ğŸŒ† ì§€ì—­ í™˜ê²½ ë¶„ì„

- ì§€ì—­ ìœ í˜•: {panorama_data.get('area_summary', {}).get('dominant_zone_type', 'N/A')}

- ìƒê¶Œ ë¶„ìœ„ê¸°: {panorama_data.get('comprehensive_scores', {}).get('commercial_atmosphere', 'N/A')}/10



### ğŸ¬ ìƒê¶Œ ë¶„ì„

- ì í¬ìˆ˜: {marketplace_data.get('ìƒê¶Œ_ì í¬ìˆ˜', 'N/A')}ê°œ

- ë§¤ì¶œì•¡: {marketplace_data.get('ìƒê¶Œ_ë§¤ì¶œì•¡', 'N/A')}ë§Œì›

        """

        

        prompt = f"""ë‹¤ìŒ ë§¤ì¥ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ì™€ ì „ëµì  ì œì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.



{summary_text}



ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:



## ğŸ¯ ì¢…í•© ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ë¦¬í¬íŠ¸



### ğŸ“Š í•µì‹¬ ì¸ì‚¬ì´íŠ¸

- ë§¤ì¥ì˜ ì£¼ìš” ê°•ì ê³¼ ì•½ì 

- ì‹œì¥ì—ì„œì˜ ìœ„ì¹˜ì™€ ê²½ìŸë ¥

- ì„±ì¥ ì ì¬ë ¥ í‰ê°€



### ğŸ” ìƒì„¸ ë¶„ì„

- ë§¤ì¶œ ë™í–¥ ë¶„ì„ ë° ì „ë§

- ê³ ê°ì¸µ íŠ¹ì„± ë° íƒ€ê²ŸíŒ… ì „ëµ

- ìƒê¶Œ í™˜ê²½ê³¼ì˜ ì í•©ì„±

- ë§ˆì¼€íŒ… ì „ëµì˜ íš¨ê³¼ì„±



### âš ï¸ ìœ„í—˜ ìš”ì†Œ ë° ì£¼ì˜ì‚¬í•­

- ë§¤ì¥ ìš´ì˜ìƒ ì£¼ì˜í•´ì•¼ í•  ì 

- ì‹œì¥ ë³€í™”ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬

- ê²½ìŸ í™˜ê²½ ë³€í™” ëŒ€ì‘ ë°©ì•ˆ



### ğŸš€ ì„±ì¥ ì „ëµ ì œì•ˆ

- ë§¤ì¶œ ì¦ëŒ€ë¥¼ ìœ„í•œ êµ¬ì²´ì  ë°©ì•ˆ

- ê³ ê° ìœ ì¹˜ ë° ë¦¬í…ì…˜ ì „ëµ

- ìƒê¶Œ íŠ¹ì„±ì„ í™œìš©í•œ ì°¨ë³„í™” ë°©ì•ˆ

- ë§ˆì¼€íŒ… ì „ëµ ê°œì„  ì œì•ˆ



### ğŸ’¡ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ

- ë‹¨ê¸° (1-3ê°œì›”) ì‹¤í–‰ ê³„íš

- ì¤‘ê¸° (3-6ê°œì›”) ì‹¤í–‰ ê³„íš

- ì¥ê¸° (6-12ê°œì›”) ì‹¤í–‰ ê³„íš



ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."""

        

        response = openai_client.chat.completions.create(

            model="gemini-2.5-flash",

            messages=[

                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ì´ì ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµì  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},

                {"role": "user", "content": prompt}

            ],

            temperature=0.7,

            max_tokens=3000

        )

        

        return response.choices[0].message.content.strip()

        

    except Exception as e:

        print(f"[ERROR] OpenAI(Gemini) ì¢…í•© ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}")

        return None





def display_store_overview(analysis_data):

    """ë§¤ì¥ ê°œìš” íƒ­ - ê°„ë‹¨í•˜ê³  í•µì‹¬ì ì¸ ê°œìš”"""

    st.markdown("### ğŸª ë§¤ì¥ ê°œìš”")

    

    store_data = analysis_data.get("store_analysis", {})

    if not store_data:

        st.info("ë§¤ì¥ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        return

    

    store_info = store_data.get("store_overview", {})

    sales_data = store_data.get("sales_analysis", {})

    customer_data = store_data.get("customer_analysis", {})

    marketing = analysis_data.get("marketing_strategy", {})

    marketplace = analysis_data.get("marketplace_analysis", {})

    

    # í•µì‹¬ ì •ë³´ë§Œ ê°„ë‹¨í•˜ê²Œ í‘œì‹œ

    col1, col2, col3 = st.columns(3)

    

    with col1:

        st.markdown("#### ğŸª ê¸°ë³¸ ì •ë³´")

        st.write(f"**ë§¤ì¥ëª…:** {store_info.get('name', 'N/A')}")

        st.write(f"**ì—…ì¢…:** {store_info.get('industry', 'N/A')}")

        st.write(f"**ìƒê¶Œ:** {store_info.get('commercial_area', 'N/A')}")

        st.write(f"**ìš´ì˜ê¸°ê°„:** {store_info.get('operating_months', 0):.1f}ê°œì›”")

    

    with col2:

        st.markdown("#### ğŸ“ˆ í•µì‹¬ ì§€í‘œ")

        # ë§¤ì¶œ ì¶”ì„¸

        sales_trend = sales_data.get("trends", {}).get("sales_amount", {}).get("trend", "N/A")

        trend_icon = "ğŸ“ˆ" if "ìƒìŠ¹" in sales_trend else "ğŸ“‰" if "í•˜ë½" in sales_trend else "â¡ï¸"

        st.write(f"**ë§¤ì¶œ ì¶”ì„¸:** {trend_icon} {sales_trend}")

        

        # ê³ ê° ì¶”ì„¸

        customer_trend = sales_data.get("trends", {}).get("unique_customers", {}).get("trend", "N/A")

        trend_icon = "ğŸ“ˆ" if "ìƒìŠ¹" in customer_trend else "ğŸ“‰" if "í•˜ë½" in customer_trend else "â¡ï¸"

        st.write(f"**ê³ ê° ì¶”ì„¸:** {trend_icon} {customer_trend}")

        

        # ìˆœìœ„

        industry_rank = sales_data.get("rankings", {}).get("industry_rank", {}).get("average", "N/A")

        st.write(f"**ë™ì¢…ì—…ê³„ ìˆœìœ„:** {industry_rank}ìœ„")

        

        # í’ˆì§ˆ ì ìˆ˜

        quality_score = store_data.get("report_metadata", {}).get("quality_score", 0)

        st.write(f"**ë¶„ì„ í’ˆì§ˆ:** {quality_score:.1%}")

    

    with col3:

        st.markdown("#### ğŸ‘¥ ê³ ê° íŠ¹ì„±")

        # ì„±ë³„

        male_ratio = customer_data.get("gender_distribution", {}).get("male_ratio", 0)

        female_ratio = customer_data.get("gender_distribution", {}).get("female_ratio", 0)

        st.write(f"**ì„±ë³„:** ë‚¨ì„± {male_ratio:.1f}% / ì—¬ì„± {female_ratio:.1f}%")

        

        # ì£¼ìš” ì—°ë ¹ëŒ€

        age_dist = customer_data.get("age_group_distribution", {})

        main_age = max(age_dist, key=age_dist.get) if age_dist else "N/A"

        main_ratio = age_dist.get(main_age, 0) if age_dist else 0

        st.write(f"**ì£¼ìš” ì—°ë ¹ëŒ€:** {main_age} ({main_ratio:.1f}%)")

        

        # ê³ ê° ìœ í˜•

        customer_dist = customer_data.get("customer_type_analysis", {}).get("customer_distribution", {})

        floating_ratio = customer_dist.get("floating", 0)

        st.write(f"**ê³ ê° ìœ í˜•:** ìœ ë™ {floating_ratio:.1f}%")

        

        # ë§ˆì¼€íŒ… ì „ëµ ìˆ˜

        strategy_count = len(marketing.get("marketing_strategies", []))

        st.write(f"**ë§ˆì¼€íŒ… ì „ëµ:** {strategy_count}ê°œ")

    # ë§ˆì¼€íŒ… & Google Maps í†µí•© ê²°ê³¼ í‘œì‹œ
    integration_result = analysis_data.get("marketing_google_maps_integration")
    if integration_result:
        st.markdown("#### ğŸ”— ë§ˆì¼€íŒ… & Google Maps í†µí•© ë¶„ì„")
        
        if integration_result.get("integration_status") == "success":
            st.success("âœ… í†µí•© ë¶„ì„ ì™„ë£Œ")
            
            # í†µí•© ê²°ê³¼ íŒŒì¼ í‘œì‹œ
            output_file = integration_result.get("output_file")
            if output_file and os.path.exists(output_file):
                st.markdown(f"ğŸ“„ **í†µí•© ë¶„ì„ ê²°ê³¼ íŒŒì¼:** `{os.path.basename(output_file)}`")
                
                # íŒŒì¼ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
                with st.expander("ğŸ“‹ í†µí•© ë¶„ì„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°", expanded=False):
                    try:
                        with open(output_file, 'r', encoding='utf-8') as f:
                            content = f.read()
                            st.text(content[:1000] + "..." if len(content) > 1000 else content)
                    except Exception as e:
                        st.error(f"íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
            
            # Google Maps ì •ë³´ ìš”ì•½
            google_maps_info = integration_result.get("google_maps_info", {})
            if "error" not in google_maps_info:
                place_details = google_maps_info.get("place_details", {})
                if place_details and "error" not in place_details:
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**ë§¤ì¥ëª…:** {place_details.get('name', 'N/A')}")
                        st.write(f"**í‰ì :** {place_details.get('rating', 'N/A')}/5.0")
                    with col2:
                        st.write(f"**ë¦¬ë·° ìˆ˜:** {place_details.get('user_ratings_total', 0)}ê°œ")
                        st.write(f"**ì „í™”ë²ˆí˜¸:** {place_details.get('formatted_phone_number', 'N/A')}")
        else:
            st.warning("âš ï¸ í†µí•© ë¶„ì„ ì‹¤íŒ¨")
            error_msg = integration_result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
            st.error(f"ì˜¤ë¥˜: {error_msg}")

    

    # ìƒê¶Œ ì •ë³´ (ê°„ë‹¨í•˜ê²Œ)

    if marketplace:

        st.markdown("#### ğŸ˜ï¸ ìƒê¶Œ ì •ë³´")

        col1, col2 = st.columns(2)

        with col1:

            st.write(f"**ìƒê¶Œëª…:** {marketplace.get('ìƒê¶Œëª…', 'N/A')}")

        with col2:

            store_count = marketplace.get("ìƒê¶Œ_ì í¬ìˆ˜", "N/A")

            st.write(f"**ì í¬ìˆ˜:** {store_count}ê°œ")

    

    # MCP êµ¬ê¸€ë§µ ê²€ìƒ‰ ê²°ê³¼ (ìˆìœ¼ë©´ í‘œì‹œ)

    mcp_result = analysis_data.get("mcp_search_result", {})

    mcp_file_path_str = mcp_result.get("output_path") or mcp_result.get("file")
    if mcp_file_path_str:
        st.markdown("---")

        st.markdown("#### ğŸ—ºï¸ Google Maps ì •ë³´")

        

        # txt íŒŒì¼ ì½ê¸°

        try:

            mcp_file_path = Path(mcp_file_path_str)
            if mcp_file_path.exists():

                with open(mcp_file_path, 'r', encoding='utf-8') as f:

                    mcp_content = f.read()

                

                # expanderë¡œ ì¶•ì•½í•´ì„œ í‘œì‹œ

                with st.expander("ğŸ“ Google Maps ê²€ìƒ‰ ê²°ê³¼ ë³´ê¸°", expanded=False):

                    st.text(mcp_content)

        except Exception as e:

            st.warning(f"MCP ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

    

    # AI ì¢…í•© ë¶„ì„ ë²„íŠ¼

    st.markdown("---")

    st.markdown("#### ğŸ¤– AI ì¢…í•© ë¶„ì„")

    if st.button("ğŸ” ì¢…í•© ë¶„ì„ ìƒì„±", type="primary", help="ëª¨ë“  ë¶„ì„ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ AIê°€ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"):

        with st.spinner("AIê°€ ì¢…í•© ë¶„ì„ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):

            comprehensive_analysis = generate_comprehensive_analysis_with_gemini(analysis_data)

            if comprehensive_analysis:

                st.markdown("##### ğŸ“‹ AI ì¢…í•© ë¶„ì„ ê²°ê³¼")

                st.write(comprehensive_analysis)

            else:

                st.error("ì¢…í•© ë¶„ì„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")



def display_customer_analysis(analysis_data):

    """ê³ ê° ë¶„ì„ íƒ­ + ì‹œê°í™” - JSON ë°ì´í„° ê¸°ë°˜ ì²´ê³„ì  ë¶„ì„"""

    st.markdown("### ğŸ‘¥ ê³ ê° ë¶„ì„")

    

    store_data = analysis_data.get("store_analysis", {})

    if not store_data:

        st.info("ë§¤ì¥ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        return

    

    customer_data = store_data.get("customer_analysis", {})

    if not customer_data:

        st.info("ê³ ê° ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        return

    

    # 1. ì„±ë³„ ë¶„í¬ (ìƒì„¸ ë¶„ì„)

    gender_data = customer_data.get("gender_distribution", {})

    if gender_data:

        st.markdown("#### ğŸ“Š ì„±ë³„ ë¶„í¬")

        col1, col2, col3 = st.columns([1, 1, 2])

        

        with col1:

            male_ratio = gender_data.get("male_ratio", 0)

            st.metric("ë‚¨ì„±", f"{male_ratio:.1f}%", help="ì „ì²´ ê³ ê° ì¤‘ ë‚¨ì„± ë¹„ìœ¨")

        

        with col2:

            female_ratio = gender_data.get("female_ratio", 0)

            st.metric("ì—¬ì„±", f"{female_ratio:.1f}%", help="ì „ì²´ ê³ ê° ì¤‘ ì—¬ì„± ë¹„ìœ¨")

        

        with col3:

            # ì„±ë³„ ë¹„ìœ¨ ì°¨ì´ ë¶„ì„

            gender_diff = abs(male_ratio - female_ratio)

            if gender_diff > 30:

                st.warning(f"ì„±ë³„ í¸ì¤‘ì´ ì‹¬í•©ë‹ˆë‹¤ (ì°¨ì´: {gender_diff:.1f}%)")

            elif gender_diff > 15:

                st.info(f"ì„±ë³„ í¸ì¤‘ì´ ìˆìŠµë‹ˆë‹¤ (ì°¨ì´: {gender_diff:.1f}%)")

            else:

                st.success("ì„±ë³„ ë¶„í¬ê°€ ê· í˜•ì ì…ë‹ˆë‹¤")

    

    # 2. ì—°ë ¹ëŒ€ë³„ ë¶„í¬ (ìƒì„¸ ë¶„ì„)

    age_data = customer_data.get("age_group_distribution", {})

    if age_data:

        st.markdown("#### ğŸ‚ ì—°ë ¹ëŒ€ë³„ ê³ ê° ë¶„í¬")

        

        # ì—°ë ¹ëŒ€ë³„ ì¹´ë“œ í‘œì‹œ

        age_cols = st.columns(5)

        age_groups = ["20ëŒ€ ì´í•˜", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"]

        

        for i, age_group in enumerate(age_groups):

            with age_cols[i]:

                ratio = age_data.get(age_group, 0)

                st.metric(age_group, f"{ratio:.1f}%")

        

        # ì£¼ìš” ì—°ë ¹ëŒ€ ë¶„ì„

        max_age = max(age_data.items(), key=lambda x: x[1])

        st.info(f"**ì£¼ìš” ê³ ê°ì¸µ:** {max_age[0]} ({max_age[1]:.1f}%)")

    

    # 3. ìƒì„¸ ê³ ê° ë¹„ìœ¨ (ì„±ë³„+ì—°ë ¹ëŒ€ ì¡°í•©)

    detailed_ratios = customer_data.get("detailed_customer_ratios", {})

    if detailed_ratios:

        st.markdown("#### ğŸ” ìƒì„¸ ê³ ê° ë¹„ìœ¨ (ì„±ë³„+ì—°ë ¹ëŒ€)")

        

        # ìƒìœ„ 5ê°œ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ í‘œì‹œ

        top_segments = sorted(detailed_ratios.items(), key=lambda x: x[1], reverse=True)[:5]

        

        for i, (segment, ratio) in enumerate(top_segments, 1):

            col1, col2 = st.columns([1, 4])

            with col1:

                st.write(f"**{i}ìœ„**")

            with col2:

                st.write(f"{segment}: {ratio:.1f}%")

                # ì§„í–‰ë¥  ë°”

                st.progress(ratio / 100)

    

    # 4. ê³ ê° ìœ í˜• ë¶„ì„ (ìˆ˜ì •ëœ í™”ì‚´í‘œ ë°©í–¥)

    customer_type = customer_data.get("customer_type_analysis", {})

    if customer_type:

        st.markdown("#### ğŸ”„ ê³ ê° ìœ í˜• ë¶„ì„")

        

        new_customers = customer_type.get("new_customers", {})

        returning_customers = customer_type.get("returning_customers", {})

        

        col1, col2 = st.columns(2)

        

        with col1:

            new_ratio = new_customers.get("ratio", 0)

            new_trend = new_customers.get("trend", "N/A")

            

            # í™”ì‚´í‘œ ë°©í–¥ ìˆ˜ì •

            if "ìƒìŠ¹" in new_trend or "ì¦ê°€" in new_trend:

                delta_icon = "ğŸ“ˆ"

            elif "í•˜ë½" in new_trend or "ê°ì†Œ" in new_trend:

                delta_icon = "ğŸ“‰"

            else:

                delta_icon = "â¡ï¸"

            

            st.metric("ì‹ ê·œ ê³ ê°", f"{new_ratio:.1f}%", delta=f"{delta_icon} {new_trend}")

        

        with col2:

            return_ratio = returning_customers.get("ratio", 0)

            return_trend = returning_customers.get("trend", "N/A")

            

            # í™”ì‚´í‘œ ë°©í–¥ ìˆ˜ì •

            if "ìƒìŠ¹" in return_trend or "ì¦ê°€" in return_trend:

                delta_icon = "ğŸ“ˆ"

            elif "í•˜ë½" in return_trend or "ê°ì†Œ" in return_trend:

                delta_icon = "ğŸ“‰"

            else:

                delta_icon = "â¡ï¸"

            

            st.metric("ì¬ë°©ë¬¸ ê³ ê°", f"{return_ratio:.1f}%", delta=f"{delta_icon} {return_trend}")

        

        # ê³ ê° ë¶„í¬ (ìƒì„¸ ë¶„ì„)

        distribution = customer_type.get("customer_distribution", {})

        if distribution:

            st.markdown("#### ğŸ  ê³ ê° ë¶„í¬ ìœ í˜•")

            

            dist_cols = st.columns(3)

            dist_types = [

                ("ì£¼ê±°í˜•", "residential", "ğŸ ", "ì§€ì—­ ì£¼ë¯¼"),

                ("ì§ì¥í˜•", "workplace", "ğŸ¢", "ì§ì¥ì¸"),

                ("ìœ ë™í˜•", "floating", "ğŸš¶", "ìœ ë™ì¸êµ¬")

            ]

            

            for i, (name, key, icon, desc) in enumerate(dist_types):

                with dist_cols[i]:

                    ratio = distribution.get(key, 0)

                    st.metric(f"{icon} {name}", f"{ratio:.1f}%", help=desc)

            

            # ì£¼ìš” ê³ ê° ìœ í˜• ë¶„ì„

            max_type = max(distribution.items(), key=lambda x: x[1])

            type_names = {"residential": "ì£¼ê±°í˜•", "workplace": "ì§ì¥í˜•", "floating": "ìœ ë™í˜•"}

            st.info(f"**ì£¼ìš” ê³ ê° ìœ í˜•:** {type_names.get(max_type[0], max_type[0])} ({max_type[1]:.1f}%)")

    

    # 5. ê³ ê° ë¶„ì„ ìš”ì•½

    st.markdown("#### ğŸ“‹ ê³ ê° ë¶„ì„ ìš”ì•½")

    

    # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ìƒì„±

    insights = []

    

    if gender_data:

        male_ratio = gender_data.get("male_ratio", 0)

        if male_ratio > 60:

            insights.append(f"ë‚¨ì„± ê³ ê°ì´ {male_ratio:.1f}%ë¡œ ì••ë„ì ")

        elif male_ratio < 40:

            insights.append(f"ì—¬ì„± ê³ ê°ì´ {100-male_ratio:.1f}%ë¡œ ë§ìŒ")

        else:

            insights.append("ì„±ë³„ ë¶„í¬ê°€ ê· í˜•ì ")

    

    if age_data:

        max_age = max(age_data.items(), key=lambda x: x[1])

        insights.append(f"{max_age[0]} ê³ ê°ì¸µì´ {max_age[1]:.1f}%ë¡œ ì£¼ë ¥")

    

    if customer_type:

        new_ratio = customer_type.get("new_customers", {}).get("ratio", 0)

        return_ratio = customer_type.get("returning_customers", {}).get("ratio", 0)

        if return_ratio > new_ratio:

            insights.append(f"ì¬ë°©ë¬¸ ê³ ê°({return_ratio:.1f}%)ì´ ì‹ ê·œ ê³ ê°({new_ratio:.1f}%)ë³´ë‹¤ ë§ìŒ")

        else:

            insights.append(f"ì‹ ê·œ ê³ ê°({new_ratio:.1f}%)ì´ ì¬ë°©ë¬¸ ê³ ê°({return_ratio:.1f}%)ë³´ë‹¤ ë§ìŒ")

    

    if insights:

        for i, insight in enumerate(insights, 1):

            st.write(f"{i}. {insight}")

    

    # ===== ì‹œê°í™” ì¶”ê°€ =====

    visualizations = analysis_data.get("visualizations", {})

    store_charts = visualizations.get("store_charts", [])

    

    if store_charts:

        st.markdown("---")

        st.markdown("#### ğŸ“Š ê³ ê° ë¶„ì„ ì°¨íŠ¸")

        

        # ê³ ê° ê´€ë ¨ ì°¨íŠ¸ í•„í„°ë§

        customer_charts = [c for c in store_charts if any(keyword in c.get("name", "").lower() 

                          for keyword in ["age", "gender", "customer", "ì—°ë ¹", "ì„±ë³„", "ê³ ê°"])]

        

        if customer_charts:

            cols = st.columns(2)

            for idx, chart_info in enumerate(customer_charts[:6]):  # ìµœëŒ€ 6ê°œ

                col_idx = idx % 2

                with cols[col_idx]:

                    chart_path = chart_info.get("path")

                    chart_name = chart_info.get("name", f"Chart {idx+1}")

                    

                    if chart_path and Path(chart_path).exists():

                        try:

                            st.image(chart_path, caption=chart_name, use_container_width=True)

                        except Exception as e:

                            st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name}")

        else:

            st.info("ê³ ê° ê´€ë ¨ ì°¨íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")



def display_mobility_analysis(analysis_data):

    """ì´ë™ íŒ¨í„´ ë¶„ì„ íƒ­ - JSON ë°ì´í„° ê¸°ë°˜ ì²´ê³„ì  ë¶„ì„"""

    st.markdown("### ğŸš¶ ì´ë™ íŒ¨í„´ ë¶„ì„")

    

    mobility_data = analysis_data.get("mobility_analysis", {})

    if not mobility_data:

        st.info("ì´ë™ íŒ¨í„´ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        return

    

    analysis = mobility_data.get("analysis", {})

    if not analysis:

        st.info("ì´ë™ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

        return

    

    # 1. ê¸°ë³¸ ì •ë³´

    st.markdown("#### ğŸ“ ë¶„ì„ ê¸°ë³¸ ì •ë³´")

    col1, col2 = st.columns(2)

    

    with col1:

        st.write(f"**ë¶„ì„ ëŒ€ìƒ:** {mobility_data.get('target_dong', 'N/A')}")

        st.write(f"**ë¶„ì„ ì‹œì :** {mobility_data.get('timestamp', 'N/A')}")

    

    with col2:

        total_moves = sum(analysis.get("part1_move_types", {}).values())

        st.write(f"**ì´ ì´ë™ëŸ‰:** {total_moves:,}ëª…")

    

    # 2. ì´ë™ ìœ í˜• ë¶„ì„ (ìƒì„¸)

    move_types = analysis.get("part1_move_types", {})

    if move_types:

        st.markdown("#### ğŸ”„ ì´ë™ ìœ í˜• ë¶„ì„")

        

        inflow = move_types.get('ìœ ì…', 0)

        outflow = move_types.get('ìœ ì¶œ', 0)

        internal = move_types.get('ë‚´ë¶€ì´ë™', 0)

        total = inflow + outflow + internal

        

        col1, col2, col3 = st.columns(3)

        

        with col1:

            inflow_ratio = (inflow / total * 100) if total > 0 else 0

            st.metric("ìœ ì…", f"{inflow:,}ëª…", f"{inflow_ratio:.1f}%")

        

        with col2:

            outflow_ratio = (outflow / total * 100) if total > 0 else 0

            st.metric("ìœ ì¶œ", f"{outflow:,}ëª…", f"{outflow_ratio:.1f}%")

        

        with col3:

            internal_ratio = (internal / total * 100) if total > 0 else 0

            st.metric("ë‚´ë¶€ì´ë™", f"{internal:,}ëª…", f"{internal_ratio:.1f}%")

        

        # ì´ë™ ìœ í˜• ë¶„ì„

        if outflow > inflow:

            st.warning("ìœ ì¶œì´ ìœ ì…ë³´ë‹¤ ë§ì•„ ì¸êµ¬ ê°ì†Œ ì¶”ì„¸ì…ë‹ˆë‹¤")

        elif inflow > outflow:

            st.success("ìœ ì…ì´ ìœ ì¶œë³´ë‹¤ ë§ì•„ ì¸êµ¬ ì¦ê°€ ì¶”ì„¸ì…ë‹ˆë‹¤")

        else:

            st.info("ìœ ì…ê³¼ ìœ ì¶œì´ ê· í˜•ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤")

    

    # 3. ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„ (ìƒì„¸)

    time_pattern = analysis.get("part2_time_pattern", {})

    if time_pattern:

        st.markdown("#### â° ì‹œê°„ëŒ€ë³„ ì´ë™ íŒ¨í„´")

        

        # ìµœëŒ€ ì´ë™ ì‹œê°„

        peak_hour = max(time_pattern.items(), key=lambda x: x[1])

        st.write(f"**ìµœëŒ€ ì´ë™ ì‹œê°„:** {peak_hour[0]}ì‹œ ({peak_hour[1]:,}ëª…)")

        

        # ì‹œê°„ëŒ€ë³„ ë¶„ë¥˜

        morning_hours = {k: v for k, v in time_pattern.items() if 6 <= int(k) <= 9}

        afternoon_hours = {k: v for k, v in time_pattern.items() if 10 <= int(k) <= 17}

        evening_hours = {k: v for k, v in time_pattern.items() if 18 <= int(k) <= 22}

        night_hours = {k: v for k, v in time_pattern.items() if 23 <= int(k) or int(k) <= 5}

        

        col1, col2, col3, col4 = st.columns(4)

        

        with col1:

            morning_total = sum(morning_hours.values())

            st.metric("ì˜¤ì „ (6-9ì‹œ)", f"{morning_total:,}ëª…")

        

        with col2:

            afternoon_total = sum(afternoon_hours.values())

            st.metric("ì˜¤í›„ (10-17ì‹œ)", f"{afternoon_total:,}ëª…")

        

        with col3:

            evening_total = sum(evening_hours.values())

            st.metric("ì €ë… (18-22ì‹œ)", f"{evening_total:,}ëª…")

        

        with col4:

            night_total = sum(night_hours.values())

            st.metric("ì•¼ê°„ (23-5ì‹œ)", f"{night_total:,}ëª…")

        

        # ìƒìœ„ 5ê°œ ì‹œê°„ëŒ€

        top_hours = sorted(time_pattern.items(), key=lambda x: x[1], reverse=True)[:5]

        st.write("**ìƒìœ„ ì´ë™ ì‹œê°„ëŒ€:**")

        for i, (hour, count) in enumerate(top_hours, 1):

            st.write(f"{i}. {hour}ì‹œ: {count:,}ëª…")

    

    # 4. ëª©ì ë³„ ë¶„ì„ (ìƒì„¸)

    purpose_data = analysis.get("part3_purpose", {})

    if purpose_data:

        st.markdown("#### ğŸ¯ ëª©ì ë³„ ì´ë™ ë¶„ì„")

        

        total_purpose = sum(purpose_data.values())

        top_purposes = sorted(purpose_data.items(), key=lambda x: x[1], reverse=True)[:5]

        

        for i, (purpose, count) in enumerate(top_purposes, 1):

            percentage = (count / total_purpose * 100) if total_purpose > 0 else 0

            col1, col2 = st.columns([1, 3])

            

            with col1:

                st.write(f"**{i}ìœ„**")

            with col2:

                st.write(f"{purpose}: {count:,}ëª… ({percentage:.1f}%)")

                st.progress(percentage / 100)

    

    # 5. êµí†µìˆ˜ë‹¨ë³„ ë¶„ì„ (ìƒì„¸)

    transport_data = analysis.get("part4_transport", {})

    if transport_data:

        st.markdown("#### ğŸš— êµí†µìˆ˜ë‹¨ë³„ ì´ìš© ë¶„ì„")

        

        total_transport = sum(transport_data.values())

        

        # ì£¼ìš” êµí†µìˆ˜ë‹¨

        main_transports = {

            "ì°¨ëŸ‰": transport_data.get('ì°¨ëŸ‰', 0),

            "ì§€í•˜ì² ": transport_data.get('ì§€í•˜ì² ', 0),

            "ë„ë³´": transport_data.get('ë„ë³´', 0),

            "ë²„ìŠ¤": transport_data.get('ì¼ë°˜ë²„ìŠ¤', 0) + transport_data.get('ê´‘ì—­ë²„ìŠ¤', 0),

            "ê¸°íƒ€": transport_data.get('ê¸°íƒ€', 0)

        }

        

        col1, col2 = st.columns(2)

        

        with col1:

            for transport, count in list(main_transports.items())[:3]:

                percentage = (count / total_transport * 100) if total_transport > 0 else 0

                st.metric(transport, f"{count:,}ëª…", f"{percentage:.1f}%")

        

        with col2:

            for transport, count in list(main_transports.items())[3:]:

                percentage = (count / total_transport * 100) if total_transport > 0 else 0

                st.metric(transport, f"{count:,}ëª…", f"{percentage:.1f}%")

    

    # 6. ì—°ë ¹ëŒ€ë³„ ë¶„ì„ (ìƒì„¸)

    age_data = analysis.get("part5_age", {})

    if age_data:

        st.markdown("#### ğŸ‘¥ ì—°ë ¹ëŒ€ë³„ ì´ë™ ë¶„ì„")

        

        total_age = sum(age_data.values())

        age_groups = {

            "10ëŒ€ ì´í•˜": age_data.get("00ëŒ€", 0) + age_data.get("10ëŒ€", 0),

            "20-30ëŒ€": age_data.get("20ëŒ€", 0) + age_data.get("30ëŒ€", 0),

            "40-50ëŒ€": age_data.get("40ëŒ€", 0) + age_data.get("50ëŒ€", 0),

            "60ëŒ€ ì´ìƒ": age_data.get("60ëŒ€", 0) + age_data.get("70ëŒ€ ì´ìƒ", 0)

        }

        

        age_cols = st.columns(4)

        for i, (age_group, count) in enumerate(age_groups.items()):

            with age_cols[i]:

                percentage = (count / total_age * 100) if total_age > 0 else 0

                st.metric(age_group, f"{count:,}ëª…", f"{percentage:.1f}%")

    

    # 7. ì—°ë ¹ëŒ€ë³„ ëª©ì  ë¶„ì„

    age_purpose_data = analysis.get("part5_2_age_purpose", {})

    if age_purpose_data:

        st.markdown("#### ğŸ¯ ì—°ë ¹ëŒ€ë³„ ì£¼ìš” ëª©ì ")

        

        for age_group, data in age_purpose_data.items():

            if isinstance(data, dict):

                purpose = data.get("top_purpose", "N/A")

                percentage = data.get("percentage", 0)

                st.write(f"**{age_group}:** {purpose} ({percentage:.1f}%)")

    

    # 8. ì´ë™ íŒ¨í„´ ìš”ì•½

    st.markdown("#### ğŸ“‹ ì´ë™ íŒ¨í„´ ìš”ì•½")

    

    insights = []

    

    if move_types:

        inflow = move_types.get('ìœ ì…', 0)

        outflow = move_types.get('ìœ ì¶œ', 0)

        if outflow > inflow:

            insights.append(f"ìœ ì¶œ({outflow:,}ëª…)ì´ ìœ ì…({inflow:,}ëª…)ë³´ë‹¤ ë§ì•„ ì¸êµ¬ ê°ì†Œ ì¶”ì„¸")

        else:

            insights.append(f"ìœ ì…({inflow:,}ëª…)ì´ ìœ ì¶œ({outflow:,}ëª…)ë³´ë‹¤ ë§ì•„ ì¸êµ¬ ì¦ê°€ ì¶”ì„¸")

    

    if time_pattern:

        peak_hour = max(time_pattern.items(), key=lambda x: x[1])

        insights.append(f"{peak_hour[0]}ì‹œì— ìµœëŒ€ ì´ë™ëŸ‰({peak_hour[1]:,}ëª…) ë°œìƒ")

    

    if purpose_data:

        top_purpose = max(purpose_data.items(), key=lambda x: x[1])

        insights.append(f"ì£¼ìš” ì´ë™ ëª©ì : {top_purpose[0]}({top_purpose[1]:,}ëª…)")

    

    if transport_data:

        top_transport = max(transport_data.items(), key=lambda x: x[1])

        insights.append(f"ì£¼ìš” êµí†µìˆ˜ë‹¨: {top_transport[0]}({top_transport[1]:,}ëª…)")

    

    if insights:

        for i, insight in enumerate(insights, 1):

            st.write(f"{i}. {insight}")

    

    # 9. ì‹œê°í™” (ê¸°ì¡´ ì°¨íŠ¸ í‘œì‹œ)

    visualizations = analysis_data.get("visualizations", {})

    mobility_charts = visualizations.get("mobility_charts", [])

    

    if mobility_charts:

        st.markdown("---")

        st.markdown("#### ğŸ“Š ì´ë™ íŒ¨í„´ ì°¨íŠ¸")

        

        cols = st.columns(2)

        for idx, chart_info in enumerate(mobility_charts[:6]):  # ìµœëŒ€ 6ê°œ

            col_idx = idx % 2

            with cols[col_idx]:

                chart_path = chart_info.get("path")

                chart_name = chart_info.get("name", f"Chart {idx+1}")

                

                if chart_path and Path(chart_path).exists():

                    try:

                        st.image(chart_path, caption=chart_name, use_container_width=True)

                    except Exception as e:

                        st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name}")

    else:

        st.info("ì´ë™ íŒ¨í„´ ì°¨íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")



def display_panorama_analysis(analysis_data):

    """ì§€ì—­ ë¶„ì„ íƒ­"""

    st.markdown("### ğŸ˜ï¸ ì§€ì—­ ë¶„ì„ (íŒŒë…¸ë¼ë§ˆ)")

    

    panorama_data = analysis_data.get("panorama_analysis", {})

    if not panorama_data:

        st.info("íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        return
    
    # Get analysis directory for image loading
    analysis_dir_str = analysis_data.get("analysis_dir", "")
    panorama_images_dir = None
    if analysis_dir_str:
        panorama_images_dir = Path(analysis_dir_str) / "panorama" / "images"

    

    metadata = panorama_data.get("metadata", {})

    if metadata:

        st.write(f"**ë¶„ì„ ì£¼ì†Œ:** {metadata.get('input_address', 'N/A')}")

        st.write(f"**ë¶„ì„ ë°˜ê²½:** {metadata.get('buffer_meters', 'N/A')}m")

        st.write(f"**ë¶„ì„ ì´ë¯¸ì§€:** {metadata.get('images_analyzed', 0)}ê°œ")

    

    # ì¢…í•© ë¶„ì„ ê²°ê³¼

    synthesis = panorama_data.get("synthesis", {})

    if synthesis:

        st.markdown("#### ì¢…í•© ë¶„ì„ ê²°ê³¼")

        

        area_summary = synthesis.get("area_summary", {})

        if area_summary:

            st.write(f"**ì§€ì—­ íŠ¹ì„±:** {area_summary.get('overall_character', 'N/A')}")

            st.write(f"**ìƒê¶Œ ìœ í˜•:** {area_summary.get('primary_commercial_type', 'N/A')}")

        

        scores = synthesis.get("comprehensive_scores", {})

        if scores:

            st.markdown("#### ì§€ì—­ ì ìˆ˜")

            col1, col2, col3 = st.columns(3)

            with col1:

                st.metric("ìƒê¶Œ í™œë ¥", f"{scores.get('commercial_atmosphere', 0)}/10")

                st.metric("ê±°ë¦¬ ë¶„ìœ„ê¸°", f"{scores.get('street_atmosphere', 0)}/10")

            with col2:

                st.metric("ì²­ê²°ë„", f"{scores.get('cleanliness', 0)}/10")

                st.metric("ìœ ì§€ë³´ìˆ˜", f"{scores.get('maintenance', 0)}/10")

            with col3:

                st.metric("ë³´í–‰ì„±", f"{scores.get('walkability', 0)}/10")

                st.metric("ì•ˆì „ê°", f"{scores.get('safety_perception', 0)}/10")

        

        detailed_assessment = synthesis.get("detailed_assessment", {})

        if detailed_assessment:

            strengths = detailed_assessment.get("strengths", [])

            weaknesses = detailed_assessment.get("weaknesses", [])

            

            if strengths:

                st.markdown("#### ê°•ì ")

                for strength in strengths:

                    st.write(f"âœ… {strength}")

            

            if weaknesses:

                st.markdown("#### ì•½ì ")

                for weakness in weaknesses:

                    st.write(f"âŒ {weakness}")

            

            expert_opinion = detailed_assessment.get("expert_opinion")

            if expert_opinion:

                st.markdown("#### ì „ë¬¸ê°€ ì˜ê²¬")

                st.write(expert_opinion)

    

    # ===== ì‹œê°í™” ì¶”ê°€ =====
    
    # panorama_analysisì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ ê²½ë¡œ ì¶”ì¶œ
    panorama_images_list = []
    
    # 0. panorama/images í´ë”ì—ì„œ ëª¨ë“  ì´ë¯¸ì§€ íŒŒì¼ ìë™ ë¡œë“œ
    if panorama_images_dir and panorama_images_dir.exists():
        image_files = sorted([f for f in panorama_images_dir.iterdir() 
                             if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']])
        for img_file in image_files[:10]:  # ìµœëŒ€ 10ê°œ
            panorama_images_list.append({
                "path": str(img_file),
                "name": img_file.name
            })
    
    # 1. individual_analyses ë°°ì—´ì—ì„œ ì´ë¯¸ì§€ ì¶”ì¶œ
    if "panorama_analysis" in analysis_data:
        panorama_data = analysis_data["panorama_analysis"]
        
        individual_analyses = panorama_data.get("individual_analyses", [])
        if isinstance(individual_analyses, list):
            for idx, analysis_item in enumerate(individual_analyses, 1):
                if isinstance(analysis_item, dict):
                    # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ (JSONì—ì„œ ê°€ì ¸ì˜´)
                    original_img_path = analysis_item.get("image_path", "")
                    
                    # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ (í™•ì¥ì í¬í•¨)
                    img_filename = Path(original_img_path).name if original_img_path else None
                    
                    # panorama/images í´ë”ì—ì„œ ë™ì¼í•œ íŒŒì¼ëª… ì°¾ê¸° (JPG, PNG ëª¨ë‘ ì§€ì›)
                    if img_filename and panorama_images_dir:
                        # JPGë¡œ ì‹œë„
                        local_img_path_jpg = panorama_images_dir / img_filename
                        local_img_path_png = panorama_images_dir / f"{Path(img_filename).stem}.png"
                        local_img_path = None
                        
                        if local_img_path_jpg.exists():
                            local_img_path = local_img_path_jpg
                        elif local_img_path_png.exists():
                            local_img_path = local_img_path_png
                        
                        # íŒŒì¼ì´ ì¡´ì¬í•˜ë©´ ì‚¬ìš©
                        if local_img_path:
                            point_id = analysis_item.get("point_id", idx)
                            lon = analysis_item.get("lon", "N/A")
                            lat = analysis_item.get("lat", "N/A")
                            img_name = f"í¬ì¸íŠ¸ {point_id} (ê²½ë„: {lon}, ìœ„ë„: {lat})"
                            panorama_images_list.append({"path": str(local_img_path), "name": img_name})
                        else:
                            # íŒŒì¼ì´ ì—†ìœ¼ë©´ ì›ë³¸ ê²½ë¡œ ì‚¬ìš© ì‹œë„
                            point_id = analysis_item.get("point_id", idx)
                            lon = analysis_item.get("lon", "N/A")
                            lat = analysis_item.get("lat", "N/A")
                            img_name = f"í¬ì¸íŠ¸ {point_id} (ê²½ë„: {lon}, ìœ„ë„: {lat})"
                            if original_img_path and Path(original_img_path).exists():
                                panorama_images_list.append({"path": original_img_path, "name": img_name})
    
    # 2. visualizationsì—ì„œ ì´ë¯¸ì§€ ì¶”ê°€
    visualizations = analysis_data.get("visualizations", {})
    panorama_images_from_viz = visualizations.get("panorama_images", [])
    
    if panorama_images_from_viz:
        panorama_images_list.extend(panorama_images_from_viz)
    
    # ì´ë¯¸ì§€ í‘œì‹œ
    if panorama_images_list:
        st.markdown("---")
        st.markdown("#### ğŸ“· íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€")
        cols = st.columns(2)
        
        for idx, img_info in enumerate(panorama_images_list[:6]):  # ìµœëŒ€ 6ê°œ
            col_idx = idx % 2
            with cols[col_idx]:
                img_path = img_info.get("path") if isinstance(img_info, dict) else img_info
                img_name = img_info.get("name", f"Image {idx+1}") if isinstance(img_info, dict) else f"Image {idx+1}"
                
                if img_path:
                    try:
                        if Path(img_path).exists():
                            st.image(img_path, caption=img_name, use_container_width=True)
                        else:
                            # ì ˆëŒ€ ê²½ë¡œ ë³€í™˜ ì‹œë„
                            absolute_path = Path(img_path).resolve()
                            if absolute_path.exists():
                                st.image(str(absolute_path), caption=img_name, use_container_width=True)
                            else:
                                st.write(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {img_name}")
                    except Exception as e:
                        st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {img_name} ({str(e)})")

    

    # ê³µê°„ ë¶„ì„ ì§€ë„

    spatial_files = visualizations.get("spatial_files", [])

    if spatial_files:

        st.markdown("---")

        st.markdown("#### ğŸ—ºï¸ ê³µê°„ ë¶„ì„")

        for file_info in spatial_files:

            file_path = file_info.get("path")

            file_name = file_info.get("name", "Unknown")

            file_type = file_info.get("type", "unknown")

            

            if file_path and Path(file_path).exists():

                if file_type == "spatial_chart" or file_type == "panorama_map":

                    try:

                        st.image(file_path, caption=file_name, use_container_width=True)

                    except Exception as e:

                        st.error(f"íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {file_name}")

                elif file_type == "spatial_map" or file_type == "panorama_map":

                    st.write(f"**{file_name}:** [ì§€ë„ íŒŒì¼]({file_path})")

                else:

                    st.write(f"**{file_name}:** {file_path}")

            else:

                st.write(f"íŒŒì¼ ì—†ìŒ: {file_name}")

    




def save_final_reports(store_code, md_content, json_content):

    """ìµœì¢… ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥"""

    try:

        output_dir = Path(__file__).parent.parent / "output"

        output_dir.mkdir(parents=True, exist_ok=True)

        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        report_dir = output_dir / f"final_reports_{store_code}_{timestamp}"

        report_dir.mkdir(parents=True, exist_ok=True)

        

        # MD íŒŒì¼ ì €ì¥

        if md_content:

            md_file = report_dir / "final.md"

            with open(md_file, 'w', encoding='utf-8') as f:

                f.write(md_content)

            print(f"Final MD saved: {md_file}")

        

        # JSON íŒŒì¼ ì €ì¥

        if json_content:

            json_file = report_dir / "final.json"

            with open(json_file, 'w', encoding='utf-8') as f:

                json.dump(json_content, f, ensure_ascii=False, indent=2)

            print(f"Final JSON saved: {json_file}")

        

        return str(report_dir)

        

    except Exception as e:

        print(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")

        return None



def merge_all_analysis_files(analysis_data):

    """ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ JSONê³¼ MDë¡œ í†µí•© (ìš”ì•½ì´ ì•„ë‹Œ ì›ë³¸ ë°ì´í„° ì „ë¶€)"""

    try:

        # í†µí•©ëœ ì „ì²´ ë°ì´í„°

        merged_data = {

            "store_code": analysis_data.get("store_code", "N/A"),

            "analysis_timestamp": datetime.now().isoformat(),

            "analysis_directory": analysis_data.get("analysis_dir", "N/A"),

            "store_analysis": analysis_data.get("store_analysis", {}),

            "marketing_analysis": analysis_data.get("marketing_analysis", {}),

            "marketplace_analysis": analysis_data.get("marketplace_analysis", {}),

            "panorama_analysis": analysis_data.get("panorama_analysis", {}),

            "mobility_analysis": analysis_data.get("mobility_analysis", {}),

            "comprehensive_analysis": analysis_data.get("comprehensive_analysis", {}),

            "visualizations": analysis_data.get("visualizations", {})

        }

        

        # ë¶„ì„ ë””ë ‰í† ë¦¬ì— í†µí•© íŒŒì¼ ì €ì¥

        if "analysis_dir" in analysis_data:

            analysis_dir = Path(analysis_data["analysis_dir"])

            

            # JSON íŒŒì¼ ì €ì¥

            merged_json_file = analysis_dir / "merged_analysis_full.json"

            with open(merged_json_file, 'w', encoding='utf-8') as f:

                json.dump(merged_data, f, ensure_ascii=False, indent=2)

            

            print(f"[OK] í†µí•© JSON íŒŒì¼ ì €ì¥: {merged_json_file}")

            print(f"[OK] í†µí•© ë°ì´í„° í¬ê¸°: {len(json.dumps(merged_data))} bytes")

            

            # MD íŒŒì¼ ìƒì„±

            merged_md_file = analysis_dir / "merged_analysis_full.md"

            md_content = generate_comprehensive_markdown(merged_data)

            

            with open(merged_md_file, 'w', encoding='utf-8') as f:

                f.write(md_content)

            

            print(f"[OK] í†µí•© MD íŒŒì¼ ì €ì¥: {merged_md_file}")

            

            return str(merged_json_file), str(merged_md_file)

        

        return None, None

        

    except Exception as e:

        print(f"[ERROR] í†µí•© íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")

        import traceback

        traceback.print_exc()

        return None, None



def generate_comprehensive_markdown(merged_data):

    """í†µí•© ë¶„ì„ ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""

    store_code = merged_data.get("store_code", "N/A")

    timestamp = merged_data.get("analysis_timestamp", "N/A")

    

    md = f"""# ë§¤ì¥ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ (ì „ì²´)



## ê¸°ë³¸ ì •ë³´

- ìƒì  ì½”ë“œ: {store_code}

- ë¶„ì„ ì¼ì‹œ: {timestamp}

- ë¶„ì„ ë””ë ‰í† ë¦¬: {merged_data.get('analysis_directory', 'N/A')}



---



"""

    

    # 1. Store ë¶„ì„

    store_analysis = merged_data.get("store_analysis", {})

    if store_analysis:

        md += f"""## 1. ë§¤ì¥ ë¶„ì„ (Store Analysis)



### ê¸°ë³¸ ì •ë³´

"""

        store_summary = store_analysis.get("store_summary", {})

        if store_summary:

            md += f"""- ë§¤ì¥ëª…: {store_summary.get('store_name', 'N/A')}

- ì—…ì¢…: {store_summary.get('industry', 'N/A')}

- ìƒê¶Œ: {store_summary.get('commercial_area', 'N/A')}

- í’ˆì§ˆ ì ìˆ˜: {store_summary.get('quality_score', 'N/A')}

- ì£¼ìš” ê³ ê°ì¸µ: {store_summary.get('main_customer', 'N/A')}

- ê³ ê° ìœ í˜•: {store_summary.get('customer_type', 'N/A')}

- ë°°ë‹¬ ë¹„ì¤‘: {store_summary.get('delivery_ratio', 'N/A')}



"""

    

    # 2. Marketing ë¶„ì„

    marketing_analysis = merged_data.get("marketing_analysis", {})

    if marketing_analysis:

        md += f"""## 2. ë§ˆì¼€íŒ… ë¶„ì„ (Marketing Analysis)



### í˜ë¥´ì†Œë‚˜ ì •ë³´

- í˜ë¥´ì†Œë‚˜ íƒ€ì…: {marketing_analysis.get('persona_type', 'N/A')}

- ë¦¬ìŠ¤í¬ ë ˆë²¨: {marketing_analysis.get('risk_level', 'N/A')}



### ë§ˆì¼€íŒ… ì „ëµ

"""

        strategies = marketing_analysis.get("strategies", [])

        for i, strategy in enumerate(strategies, 1):

            md += f"""

#### ì „ëµ {i}: {strategy.get('title', 'N/A')}

- ì„¤ëª…: {strategy.get('description', 'N/A')}

- íƒ€ê²Ÿ: {strategy.get('target', 'N/A')}

- ì˜ˆìƒ íš¨ê³¼: {strategy.get('expected_impact', 'N/A')}

"""

        

        md += "\n### ë§ˆì¼€íŒ… ìº í˜ì¸\n"

        campaigns = marketing_analysis.get("campaigns", [])

        for i, campaign in enumerate(campaigns, 1):

            md += f"""

#### ìº í˜ì¸ {i}: {campaign.get('name', 'N/A')}

- ì„¤ëª…: {campaign.get('description', 'N/A')}

- ì±„ë„: {campaign.get('channels', 'N/A')}

- ì˜ˆì‚°: {campaign.get('budget', 'N/A')}

"""

    

    # 3. Marketplace ë¶„ì„

    marketplace_analysis = merged_data.get("marketplace_analysis", {})

    if marketplace_analysis:

        # ìƒê¶Œëª… ì‚¬ìš© (spatial_matcherì—ì„œ ì´ë¯¸ ì˜¬ë°”ë¥¸ ìƒê¶Œëª…ìœ¼ë¡œ ìˆ˜ì •ë¨)
        corrected_marketplace_name = marketplace_analysis.get('ìƒê¶Œëª…', 'N/A')
        
        md += f"""## 3. ìƒê¶Œ ë¶„ì„ (Marketplace Analysis)



### ê¸°ë³¸ ì •ë³´

- ë¶„ì„ì¼ì‹œ: {marketplace_analysis.get('ë¶„ì„ì¼ì‹œ', 'N/A')}



### ìƒê¶Œ ë°ì´í„°

"""

        data_section = marketplace_analysis.get("ë°ì´í„°", [])

        for item in data_section:

            if item.get("ìœ í˜•") == "ì¢…í•©ì˜ê²¬":

                area_info = item.get("ë©´ì ", {})

                if area_info:

                    md += f"- ë¶„ì„ ë©´ì : {area_info.get('ë¶„ì„', 'N/A')}ã¡\n"

                

                store_count = item.get("ì í¬ìˆ˜", {})

                if store_count:

                    current = store_count.get("í˜„ì¬", {})

                    md += f"- í˜„ì¬ ì í¬ìˆ˜: {current.get('ê°’', 'N/A')}ê°œ ({current.get('ê¸°ì¤€', 'N/A')})\n"

                    

                    quarter_change = store_count.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})

                    if quarter_change:

                        md += f"- ì „ë¶„ê¸° ëŒ€ë¹„: {quarter_change.get('ë³€í™”', 'N/A')}ê°œ\n"

                

                sales_info = item.get("ë§¤ì¶œì•¡", {})

                if sales_info:

                    current_sales = sales_info.get("í˜„ì¬", {})

                    md += f"- í˜„ì¬ ë§¤ì¶œì•¡: {current_sales.get('ê°’', 'N/A')}ë§Œì› ({current_sales.get('ê¸°ì¤€', 'N/A')})\n"

                    

                    quarter_sales = sales_info.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})

                    if quarter_sales:

                        md += f"- ì „ë¶„ê¸° ëŒ€ë¹„: {quarter_sales.get('ë³€í™”', 'N/A')}ë§Œì›\n"

                

                break

    

    # 4. Panorama ë¶„ì„

    panorama_analysis = merged_data.get("panorama_analysis", {})

    if panorama_analysis:

        md += f"""

## 4. íŒŒë…¸ë¼ë§ˆ ë¶„ì„ (Panorama Analysis)



### ìœ„ì¹˜ ì •ë³´

- ì£¼ì†Œ: {panorama_analysis.get('address', 'N/A')}

- ì¢Œí‘œ: {panorama_analysis.get('coordinates', 'N/A')}

- í–‰ì •ë™: {panorama_analysis.get('administrative_dong', 'N/A')}

- ìƒê¶Œ: {panorama_analysis.get('marketplace', 'N/A')}



"""

    

    # 5. Mobility ë¶„ì„

    mobility_analysis = merged_data.get("mobility_analysis", {})

    if mobility_analysis:

        md += f"""## 5. ì´ë™ íŒ¨í„´ ë¶„ì„ (Mobility Analysis)



### ì´ë™ ë°ì´í„°

- ë°ì´í„° í¬í•¨: {len(mobility_analysis)} í•­ëª©



"""

    

    # 6. Comprehensive ë¶„ì„

    comprehensive_analysis = merged_data.get("comprehensive_analysis", {})

    if comprehensive_analysis:

        md += f"""## 6. ì¢…í•© ë¶„ì„ (Comprehensive Analysis)



{json.dumps(comprehensive_analysis, ensure_ascii=False, indent=2)}



"""

    

    # 7. ì‹œê°í™” ì •ë³´

    visualizations = merged_data.get("visualizations", {})

    if visualizations:

        md += f"""## 7. ì‹œê°í™” íŒŒì¼ ëª©ë¡



"""

        for viz_type, files in visualizations.items():

            md += f"### {viz_type}\n"

            for file_info in files:

                md += f"- {file_info.get('name', 'N/A')}: {file_info.get('path', 'N/A')}\n"

    

    md += f"""

---



## ë¶„ì„ ì™„ë£Œ

ì´ ë¦¬í¬íŠ¸ëŠ” ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•œ ì „ì²´ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ìƒë‹´ ëª¨ë“œì—ì„œ ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

"""

    

    return md



# ì‚¬ì´ë“œë°”: ë¶„ì„ ì§„í–‰ ìƒí™© í‘œì‹œ

with st.sidebar:

    st.markdown("## ğŸ“Š ë¶„ì„ ì§„í–‰ ìƒí™©")

    

    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì•ˆë‚´
    if not os.getenv("GEMINI_API_KEY") and not os.getenv("GOOGLE_API_KEY"):
        st.error("âš ï¸ GEMINI_API_KEY ë˜ëŠ” GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        st.markdown("""
        **í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ë°©ë²•:**
        1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— `.env` íŒŒì¼ ìƒì„±
        2. ë‹¤ìŒ ë‚´ìš© ì¶”ê°€:
        ```
        GEMINI_API_KEY=your_gemini_api_key_here
        GOOGLE_API_KEY=your_google_api_key_here
        MCP_SERVER_URL=http://localhost:3000
        ```
        3. ì•± ì¬ì‹œì‘
        """)
        st.markdown("---")
    
    # MCP ì„œë²„ ìƒíƒœ í™•ì¸
    mcp_server_url = os.getenv("MCP_SERVER_URL", "http://localhost:3000")
    if not MCP_LOOKUP_AVAILABLE:
        st.warning("âš ï¸ Google Maps MCP ì„œë²„ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        st.markdown(f"""
        **MCP ì„œë²„ ì„¤ì • ë°©ë²•:**
        1. MCP ì„œë²„ ì‹¤í–‰:
        ```bash
        npx @cablate/mcp-google-map --port 3000 --apikey YOUR_GOOGLE_API_KEY
        ```
        2. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •:
        ```
        MCP_SERVER_URL=http://localhost:3000
        GOOGLE_API_KEY=your_google_api_key_here
        ```
        """)
        st.markdown("---")
    
    
    # ë¶„ì„ ìƒíƒœ í‘œì‹œ

    if st.session_state.get('is_analyzing', False):

        st.info("ğŸ”„ ë¶„ì„ ì§„í–‰ ì¤‘...")

        

        # ì§„í–‰ ë‹¨ê³„ í‘œì‹œ (ì ‘ì„ ìˆ˜ ìˆëŠ” í˜•íƒœ)

        with st.expander("ğŸ“‹ í˜„ì¬ ì§„í–‰ ë‹¨ê³„", expanded=True):

            progress = st.session_state.get('analysis_progress', {})

            

            steps = [

                ("ì£¼ì†Œ ì •ë³´ ë¶„ì„", "address"),

                ("Store Agent ë¶„ì„", "store"),

                ("Marketing ë¶„ì„", "marketing"),

                ("Mobility ë¶„ì„", "mobility"),

                ("Panorama ë¶„ì„", "panorama"),

                ("Marketplace ë¶„ì„", "marketplace"),

                ("ê²°ê³¼ í†µí•©", "integration")

            ]

            

            for i, (step_name, step_key) in enumerate(steps, 1):

                status = progress.get(step_key, "waiting")

                

                if status == "completed":

                    st.write(f"{i}. âœ… {step_name}")

                elif status == "in_progress":

                    st.write(f"{i}. ğŸ”„ {step_name} ì¤‘...")

                else:

                    st.write(f"{i}. â³ {step_name} ëŒ€ê¸°")

            

    elif st.session_state.get('analysis_complete', False):

        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

        

        # ì™„ë£Œëœ ë¶„ì„ ì •ë³´

        with st.expander("ğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½", expanded=True):

            store_code = st.session_state.get('store_code', 'N/A')

            st.write(f"**ìƒì  ì½”ë“œ:** {store_code}")

            st.write("**ë¶„ì„ ì™„ë£Œ ì‹œê°„:** ë°©ê¸ˆ ì „")

            st.write("**ë¶„ì„ í•­ëª©:** 5ì°¨ì› ì¢…í•© ë¶„ì„")

            st.write("**ìƒíƒœ:** ëª¨ë“  ë¶„ì„ ì™„ë£Œ")

            

    else:

        st.info("â³ ëŒ€ê¸° ì¤‘...")

        

        # ëŒ€ê¸° ìƒíƒœ ì•ˆë‚´

        with st.expander("ğŸ“‹ ì‚¬ìš© ë°©ë²•", expanded=True):

            st.write("1. ìƒì  ì½”ë“œ ì…ë ¥")

            st.write("2. ë¶„ì„ ì‹œì‘")

            st.write("3. ê²°ê³¼ í™•ì¸")

            st.write("4. ìƒë‹´ ì‹œì‘")

    

    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼

    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True):

        st.rerun()



# ë©”ì¸ 2íŒ¨ë„ ë ˆì´ì•„ì›ƒ

col1, col2 = st.columns([1, 1])



# ì™¼ìª½ íŒ¨ë„: ì±„íŒ… ì¸í„°í˜ì´ìŠ¤

with col1:

    st.markdown("## BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤")

    

    # ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€

    if not st.session_state.messages:

        st.session_state.messages = [{

            "role": "assistant", 

            "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¹„ë°€ ìƒë‹´ì‚¬ AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤. 10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì‹œë©´ ì¢…í•© ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. (ì˜ˆ: 000F03E44A, 002816BA73)"

        }]

    

    # ë©”ì‹œì§€ í‘œì‹œ

    for message in st.session_state.messages:

        with st.chat_message(message["role"]):

            st.write(message["content"])

    

    # ë¶„ì„ ì¤‘ì¼ ë•Œ ë¡œë”© í‘œì‹œ

    if st.session_state.is_analyzing:

        with st.chat_message("assistant"):

            st.markdown("ğŸ”„ 5ì°¨ì› ì¢…í•© ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ì•½ 3-5ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.")

    

    # ì‚¬ìš©ì ì…ë ¥

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):

        # Query Classifierë¡œ ì˜ë„ íŒŒì•…

        if AGENTS_AVAILABLE:

            query_result = classify_query_sync(prompt)

            intent = query_result.get("intent", "general_consultation")

            detected_store_code = query_result.get("store_code")

            

            # 1. ìƒì  ì½”ë“œ ì¿¼ë¦¬

            if intent == "store_code_query" and detected_store_code and not st.session_state.analysis_complete:

                store_code = detected_store_code

                st.session_state.store_code = store_code

                st.session_state.messages.append({"role": "user", "content": prompt})

                

                # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸

                print(f"[DEBUG] ìƒì  ì½”ë“œ {store_code}ì— ëŒ€í•œ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸ ì¤‘...")

                existing_analysis = load_analysis_data_from_output(store_code)

                print(f"[DEBUG] ê¸°ì¡´ ë¶„ì„ ê²°ê³¼: {existing_analysis is not None}")

                

                if existing_analysis:

                    st.session_state.messages.append({

                        "role": "assistant",

                        "content": f"âœ… ìƒì  ì½”ë“œ {store_code}ì˜ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤! ë°”ë¡œ í‘œì‹œí•˜ê² ìŠµë‹ˆë‹¤."

                    })

                    st.session_state.analysis_data = existing_analysis

                    st.session_state.analysis_complete = True

                    st.session_state.is_analyzing = False

                    

                    # ê¸°ì¡´ ë¶„ì„ë„ í†µí•© íŒŒì¼ ìƒì„± (JSON + MD)

                    merged_json, merged_md = merge_all_analysis_files(existing_analysis)

                    if merged_json and merged_md:

                        print(f"[OK] ê¸°ì¡´ ë¶„ì„ í†µí•© íŒŒì¼ ìƒì„±ë¨: JSON={merged_json}, MD={merged_md}")

                    

                    # ë¶„ì„ ë°ì´í„° ë¡œë“œ ì„±ê³µ ë¡œê·¸

                    print(f"[OK] ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(existing_analysis)} ì„¹ì…˜")

                    

                    st.rerun()

                else:

                    st.session_state.messages.append({

                        "role": "assistant", 

                        "content": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤... 5ì°¨ì› ì¢…í•© ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ì•½ 3-5ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤."

                    })

                    st.session_state.is_analyzing = True

                    st.rerun()

            

            # 2. ì¬ì‹œì‘ ìš”ì²­

            elif intent == "restart_analysis":

                st.session_state.messages.append({"role": "user", "content": prompt})

                st.session_state.messages.append({

                    "role": "assistant",

                    "content": "ìƒˆë¡œìš´ ë¶„ì„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."

                })

                # ìƒíƒœ ì´ˆê¸°í™”

                st.session_state.analysis_complete = False

                st.session_state.consultation_mode = False

                st.session_state.consultation_chain = None

                st.session_state.consultation_memory = None

                st.rerun()

            

            # 3. ì¼ë°˜ ìƒë‹´ (Consultation ëª¨ë“œ)

            elif st.session_state.consultation_mode and st.session_state.consultation_chain:

                st.session_state.messages.append({"role": "user", "content": prompt})

                

                with st.spinner("ìƒë‹´ì‚¬ê°€ ë‹µë³€ì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤..."):

                    try:

                        print(f"[INFO] ìƒë‹´ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {prompt[:50]}...")

                        # ìƒë‹´ì— í•„ìš”í•œ ë°ì´í„° ì „ë‹¬
                        store_data = st.session_state.merged_data.get("store_analysis", {}) if st.session_state.merged_data else {}
                        panorama_data = st.session_state.merged_data.get("panorama_analysis", {}) if st.session_state.merged_data else {}
                        
                        response = chat_with_consultant(

                            st.session_state.consultation_chain,

                            st.session_state.consultation_memory,

                            prompt,
                            store_data,
                            panorama_data
                        )

                        print(f"[SUCCESS] ìƒë‹´ ë‹µë³€ ìƒì„± ì™„ë£Œ")

                        st.session_state.messages.append({"role": "assistant", "content": response})

                    except Exception as e:

                        print(f"[ERROR] ìƒë‹´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

                        st.session_state.messages.append({

                            "role": "assistant",

                            "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

                        })

                st.rerun()

            

            # 4. ë¶„ì„ ì™„ë£Œ í›„ ìƒë‹´ ì‹œì‘ ìœ ë„

            elif st.session_state.analysis_complete:

                st.session_state.messages.append({"role": "user", "content": prompt})

                st.session_state.messages.append({

                    "role": "assistant", 

                    "content": "ìƒë‹´ ëª¨ë“œë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ 'ğŸ’¬ ìƒë‹´ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. AI ìƒë‹´ì‚¬ê°€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤."

                })

                st.rerun()

            

            # 5. ê¸°ë³¸ (ìƒì  ì½”ë“œ ì…ë ¥ ìœ ë„)

            else:

                st.session_state.messages.append({"role": "user", "content": prompt})

                st.session_state.messages.append({

                    "role": "assistant", 

                    "content": "10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 000F03E44A, 002816BA73)"

                })

                st.rerun()

        

        else:

            # Agents ë¯¸ì‚¬ìš© ì‹œ ê°„ë‹¨í•œ ì •ê·œì‹ ë§¤ì¹­

            import re

            store_code_match = re.search(r'[A-Z0-9]{10}', prompt)

            

            if store_code_match and not st.session_state.analysis_complete:

                store_code = store_code_match.group()

                st.session_state.store_code = store_code

                st.session_state.messages.append({"role": "user", "content": prompt})

                

                log_capture.add_log(f"ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸ ì¤‘: {store_code}", "INFO")

                existing_analysis = load_analysis_data_from_output(store_code)

                

                if existing_analysis:

                    log_capture.add_log(f"ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ë°œê²¬: {store_code}", "SUCCESS")

                    st.session_state.messages.append({

                        "role": "assistant",

                        "content": f"âœ… ìƒì  ì½”ë“œ {store_code}ì˜ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!"

                    })

                    st.session_state.analysis_data = existing_analysis

                    st.session_state.analysis_complete = True

                    st.session_state.is_analyzing = False

                    st.rerun()

                else:

                    log_capture.add_log(f"ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì—†ìŒ, ìƒˆ ë¶„ì„ ì‹œì‘: {store_code}", "INFO")

                    st.session_state.messages.append({

                        "role": "assistant", 

                        "content": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."

                    })

                    st.session_state.is_analyzing = True

                    st.rerun()

            else:

                st.session_state.messages.append({"role": "user", "content": prompt})

                st.session_state.messages.append({

                    "role": "assistant", 

                    "content": "10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 000F03E44A)"

                })

                st.rerun()



# ì˜¤ë¥¸ìª½ íŒ¨ë„: ë¶„ì„ ê²°ê³¼ ëŒ€ì‹œë³´ë“œ

with col2:

    st.markdown("## ë¶„ì„ ê²°ê³¼")

    

    # ë¶„ì„ ì§„í–‰ ì¤‘

    if st.session_state.is_analyzing and not st.session_state.analysis_complete:

        st.info("ğŸ”„ ë¶„ì„ ì§„í–‰ ì¤‘...")

        

        # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰

        try:

            log_capture.add_log(f"ë¶„ì„ ì‹œì‘: {st.session_state.store_code}", "INFO")

            log_capture.add_log("5ì°¨ì› ì¢…í•© ë¶„ì„ ì§„í–‰ ì¤‘...", "INFO")

            

            # ë¶„ì„ ì§„í–‰ ìƒí™© ì´ˆê¸°í™”

            st.session_state.analysis_progress = {}

            

            # ë¶„ì„ ì‹¤í–‰
            try:
                result = asyncio.run(run_full_analysis_pipeline(st.session_state.store_code))
                print(f"[DEBUG] run_full_analysis_pipeline ê²°ê³¼: {result}")
                
                
            except Exception as e:
                print(f"[ERROR] run_full_analysis_pipeline ì‹¤í–‰ ì˜¤ë¥˜: {e}")
                import traceback
                traceback.print_exc()
                result = {"status": "failed", "error": str(e)}

            

            # Marketing Moduleì€ ìƒë‹´ ì‹œì‘ ë‹¨ê³„ì—ì„œ ì‹¤í–‰ë˜ë„ë¡ ì´ë™
            

            # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ ë¡œë“œ

            if result and result.get("status") == "success":

                log_capture.add_log(f"ë¶„ì„ ì™„ë£Œ: {st.session_state.store_code}", "SUCCESS")

                st.session_state.is_analyzing = False

                st.session_state.analysis_complete = True

                

                # ì‹¤ì œ output í´ë”ì—ì„œ ìµœì‹  ê²°ê³¼ ë¡œë“œ

                analysis_data = load_analysis_data_from_output(st.session_state.store_code)

                if analysis_data:

                    st.session_state.analysis_data = analysis_data

                    log_capture.add_log("ë¶„ì„ ë°ì´í„° ë¡œë“œ ì„±ê³µ", "OK")

                else:

                    st.session_state.analysis_data = result

                    log_capture.add_log("ê¸°ë³¸ ë§ˆì¼€íŒ… ê²°ê³¼ ì‚¬ìš©", "WARN")

                

                # ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ í†µí•© (JSON + MD)

                log_capture.add_log("ë¶„ì„ ê²°ê³¼ í†µí•© ì¤‘...", "INFO")

                merged_json, merged_md = merge_all_analysis_files(st.session_state.analysis_data)

                if merged_json and merged_md:

                    log_capture.add_log(f"í†µí•© ë¶„ì„ íŒŒì¼ ìƒì„±ë¨: JSON={merged_json}, MD={merged_md}", "OK")

                

                # ì™„ë£Œ ë©”ì‹œì§€ ì¶”ê°€

                st.session_state.messages.append({

                    "role": "assistant",

                    "content": "ë¶„ì„ ì™„ë£Œ! ìš°ì¸¡ íŒ¨ë„ì—ì„œ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"

                })

                

                # ë¶„ì„ ì™„ë£Œ í›„ ì¦‰ì‹œ ê²°ê³¼ í‘œì‹œ

                st.success("âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")

                st.rerun()

                

                # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ í‘œì‹œ

                if st.button("ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (Gemini)", type="primary"):

                    with st.spinner("Geminië¡œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„± ì¤‘..."):

                        md_content, json_content = generate_final_report_with_gemini(result)

                        if md_content:

                            report_dir = save_final_reports(st.session_state.store_code, md_content, json_content)

                            if report_dir:

                                st.success(f"ìµœì¢… ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_dir}")

                                st.session_state.final_report_generated = True

                                st.rerun()

                        else:

                            st.error("ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                

                st.rerun()

            else:

                log_capture.add_log(f"ë¶„ì„ ì‹¤íŒ¨: {st.session_state.store_code}", "ERROR")

                st.error("ë¶„ì„ ì‹¤íŒ¨")

                st.session_state.is_analyzing = False

                st.rerun()

                

        except Exception as e:

            log_capture.add_log(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "ERROR")

            st.error(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")

            st.session_state.is_analyzing = False

            st.rerun()

    

    # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ

    elif st.session_state.analysis_complete and st.session_state.analysis_data:

        # session_stateì— ì €ì¥ëœ ë¶„ì„ ë°ì´í„° ì‚¬ìš©

        store_code = st.session_state.store_code

        analysis_data = st.session_state.analysis_data

        

        if not analysis_data:

            st.error("ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        else:

            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ({analysis_data.get('timestamp', 'N/A')})")

            

            # ê¸°ë³¸ ì •ë³´ í‘œì‹œ

            display_basic_info(analysis_data)

            

            # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼

            display_final_report_button(store_code, analysis_data)

            

            # ìƒë‹´ ì‹œì‘ ë²„íŠ¼

            st.markdown("---")

            if not st.session_state.consultation_mode:

                if st.button("ğŸ’¬ ìƒë‹´ ì‹œì‘ (ë¶„ì„ 3~5ë¶„ ì†Œìš”)", type="primary", use_container_width=True):
                    print(f"[INFO] ìƒë‹´ ëª¨ë“œ ì‹œì‘ ìš”ì²­: {store_code}")

                    if AGENTS_AVAILABLE:

                        print(f"[INFO] Langchain AI Agents ì‚¬ìš©í•˜ì—¬ ìƒë‹´ ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘...")

                        with st.spinner("íŒŒë…¸ë¼ë§ˆ ë¶„ì„ â†’ ë§ˆì¼€íŒ… ì „ëµ â†’ MCP ê²€ìƒ‰ â†’ í¬ë¡¤ë§ â†’ ìƒë‹´ ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘..."):
                            try:
                                # 1. íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ë¨¼ì € ì‹¤í–‰
                                log_capture.add_log("íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì‹œì‘...", "INFO")
                                try:
                                    from agents_new.panorama_img_anal.analyze_area_by_address import analyze_area_by_address
                                    
                                    # ì£¼ì†Œ ê°€ì ¸ì˜¤ê¸°
                                    address = analysis_data.get("address", "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬")
                                    
                                    # íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì‹¤í–‰
                                    panorama_result = analyze_area_by_address(
                                        address=address,
                                        buffer_meters=300,
                                        max_images=5,
                                        create_map=True
                                    )
                                    
                                    # ê²°ê³¼ë¥¼ analysis_dataì— ì €ì¥
                                    analysis_data["panorama_analysis"] = panorama_result
                                    log_capture.add_log(f"íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì™„ë£Œ: {panorama_result.get('output_folder', 'N/A')}", "OK")
                                    
                                except Exception as e:
                                    log_capture.add_log(f"íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì˜¤ë¥˜: {e}", "ERROR")
                                    analysis_data["panorama_analysis"] = {"error": str(e)}

                                # 2. í†µí•© ë¶„ì„ íŒŒì¼ ë¡œë“œ
                                log_capture.add_log("í†µí•© ë¶„ì„ íŒŒì¼ ë¡œë“œ ì¤‘...", "INFO")
                                merged_data, merged_md = load_merged_analysis(analysis_data["analysis_dir"])

                                

                                if merged_data and merged_md:

                                    log_capture.add_log("í†µí•© íŒŒì¼ ë¡œë“œ ì™„ë£Œ", "OK")

                                    log_capture.add_log(f"Analysis Dir: {analysis_data['analysis_dir']}", "DEBUG")

                                    log_capture.add_log(f"MD íŒŒì¼ í¬ê¸°: {len(merged_md)} bytes", "DEBUG")

                                    

                                    # ===== 1ë‹¨ê³„: Marketing Module ì‹¤í–‰ =====
                                    print("\n" + "="*60)

                                    print("[1/3] Marketing Module ì‹¤í–‰!")
                                    print("="*60)

                                    
                                    # Marketing Module ê²°ê³¼ê°€ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
                                    marketing_file = Path(analysis_data.get("analysis_dir", "")) / "marketing_result.json"
                                    if marketing_file.exists():
                                        print(f"[INFO] Marketing result already exists: {marketing_file.name}")
                                        log_capture.add_log(f"âœ… Marketing Module ê²°ê³¼ ì´ë¯¸ ì¡´ì¬: {marketing_file.name}", "INFO")
                                        
                                        # ê¸°ì¡´ ê²°ê³¼ ë¡œë“œ
                                        with open(marketing_file, 'r', encoding='utf-8') as f:
                                            marketing_result = json.load(f)
                                        analysis_data["marketing_analysis"] = marketing_result
                                        
                                        # í”„ë¡ íŠ¸ì—”ë“œ í‘œì‹œë¥¼ ìœ„í•´ marketing_resultë„ ì„¤ì •
                                        analysis_data["marketing_result"] = marketing_result
                                        
                                        # ê¸°ì¡´ ë§ˆì¼€íŒ… ê²°ê³¼ì— ëŒ€í•´ì„œë„ Google Maps ì—°ë™ ìˆ˜í–‰
                                        try:
                                            log_capture.add_log("ğŸ”„ ê¸°ì¡´ ë§ˆì¼€íŒ… ê²°ê³¼ì— ëŒ€í•œ Google Maps ìë™ ì—°ë™ ì‹œì‘...", "INFO")
                                            from agents_new.google_map_mcp.auto_integration import auto_marketing_google_maps_integration
                                            
                                            integration_result = auto_marketing_google_maps_integration(
                                                store_code=store_code,
                                                marketing_result=marketing_result,
                                                output_dir=analysis_data.get("analysis_dir", "")
                                            )
                                            
                                            if integration_result.get("integration_status") == "success":
                                                analysis_data["marketing_google_maps_integration"] = integration_result
                                                log_capture.add_log("âœ… Google Maps ìë™ ì—°ë™ ì™„ë£Œ!", "SUCCESS")
                                                log_capture.add_log(f"ğŸ“„ í†µí•© ê²°ê³¼ íŒŒì¼: {integration_result.get('output_file', 'N/A')}", "INFO")
                                            else:
                                                log_capture.add_log(f"âš ï¸ Google Maps ìë™ ì—°ë™ ì‹¤íŒ¨: {integration_result.get('error', 'N/A')}", "WARN")
                                                
                                        except Exception as e:
                                            log_capture.add_log(f"âŒ Google Maps ìë™ ì—°ë™ ì˜¤ë¥˜: {str(e)}", "ERROR")
                                    else:
                                        try:
                                            log_capture.add_log("[1/3] Marketing Module ë¶„ì„ ì‹œì‘...", "INFO")
                                            
                                            # Store analysisì—ì„œ marketing formatìœ¼ë¡œ ë³€í™˜
                                            store_analysis = analysis_data.get("store_analysis")
                                            if store_analysis:
                                                # Marketing Module ì‹¤í–‰ (JSON 2ê°œ ìë™ ì €ì¥)
                                                if MARKETING_MODULE_AVAILABLE:
                                                    marketing_result = run_marketing_sync(
                                                        store_code, 
                                                        analysis_data.get("analysis_dir", ""), 
                                                        store_analysis
                                                    )
                                                else:
                                                    log_capture.add_log("Marketing Moduleì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - GEMINI_API_KEY ë˜ëŠ” GOOGLE_API_KEY í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”", "WARN")
                                                    log_capture.add_log("ê¸°ë³¸ ë§ˆì¼€íŒ… ê²°ê³¼ë¥¼ ìƒì„±í•©ë‹ˆë‹¤...", "INFO")
                                                    marketing_result = None
                                                
                                                if marketing_result:
                                                    analysis_data["marketing_analysis"] = marketing_result
                                                    analysis_data["marketing_result"] = marketing_result
                                                    log_capture.add_log("âœ… Marketing Module ì™„ë£Œ!", "SUCCESS")
                                                    
                                                    # ë§ˆì¼€íŒ… ë¶„ì„ í›„ Google Maps ìë™ ì—°ë™
                                                    try:
                                                        log_capture.add_log("ğŸ”„ Google Maps ìë™ ì—°ë™ ì‹œì‘...", "INFO")
                                                        from agents_new.google_map_mcp.auto_integration import auto_marketing_google_maps_integration
                                                        
                                                        integration_result = auto_marketing_google_maps_integration(
                                                            store_code=store_code,
                                                            marketing_result=marketing_result,
                                                            output_dir=analysis_data.get("analysis_dir", "")
                                                        )
                                                        
                                                        if integration_result.get("integration_status") == "success":
                                                            analysis_data["marketing_google_maps_integration"] = integration_result
                                                            log_capture.add_log("âœ… Google Maps ìë™ ì—°ë™ ì™„ë£Œ!", "SUCCESS")
                                                            log_capture.add_log(f"ğŸ“„ í†µí•© ê²°ê³¼ íŒŒì¼: {integration_result.get('output_file', 'N/A')}", "INFO")
                                                        else:
                                                            log_capture.add_log(f"âš ï¸ Google Maps ìë™ ì—°ë™ ì‹¤íŒ¨: {integration_result.get('error', 'N/A')}", "WARN")
                                                            
                                                    except Exception as e:
                                                        log_capture.add_log(f"âŒ Google Maps ìë™ ì—°ë™ ì˜¤ë¥˜: {str(e)}", "ERROR")
                                                else:
                                                    log_capture.add_log("Marketing Module ì‹¤íŒ¨", "WARN")
                                            else:
                                                log_capture.add_log("Store ë¶„ì„ ì—†ìŒ", "WARN")
                                        except Exception as e:
                                            log_capture.add_log(f"âŒ Marketing Module ì˜¤ë¥˜: {str(e)}", "ERROR")
                                            import traceback
                                            traceback.print_exc()
                                    
                                    # ===== 2ë‹¨ê³„: MCP ë§¤ì¥ ê²€ìƒ‰ ì‹¤í–‰ =====
                                    print("\n" + "="*60)
                                    print("[2/3] MCP ë§¤ì¥ ê²€ìƒ‰ ì‹¤í–‰!")
                                    print("="*60)
                                    try:
                                        log_capture.add_log(f"[2/3] MCP ë§¤ì¥ ê²€ìƒ‰ ì‹œì‘: {store_code}", "INFO")
                                        print(f"ğŸ” MCP ê²€ìƒ‰ ì¤‘: {store_code}")
                                        
                                        if MCP_LOOKUP_AVAILABLE:
                                            # CSV ê²½ë¡œ: agents_new/google_map_mcp/matched_store_results.csv
                                            csv_path = Path(__file__).parent.parent.parent / "agents_new" / "google_map_mcp" / "matched_store_results.csv"

                                            if csv_path.exists():
                                                # ì¶œë ¥ ê²½ë¡œ: í˜„ì¬ ë¶„ì„ ë””ë ‰í† ë¦¬ ìš°ì„  ì‚¬ìš©
                                                out_dir = Path(analysis_data.get("analysis_dir") or (Path(__file__).parent.parent / "output"))
                                                out_dir.mkdir(parents=True, exist_ok=True)

                                                # MCP ì„œë²„ URL ì„¤ì • (í™˜ê²½ ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’)
                                                mcp_server_url = os.getenv("MCP_SERVER_URL", "http://localhost:3000")
                                                
                                                mcp_result = run_gm_lookup(
                                                    store_code,
                                                    csv_path=str(csv_path),
                                                    out_dir=str(out_dir),
                                                    force=False,
                                                    dry_run=False,
                                                    mcp_server_url=mcp_server_url
                                                )

                                                output_file = mcp_result.get("output_path", "")
                                                if output_file and Path(output_file).exists():
                                                    print(f"âœ… MCP ê²€ìƒ‰ ì„±ê³µ! ì €ì¥: {Path(output_file).name}")
                                                    log_capture.add_log(f"âœ… MCP ë§¤ì¥ ê²€ìƒ‰ ì„±ê³µ: {Path(output_file).name}", "SUCCESS")
                                                else:
                                                    log_capture.add_log("âš ï¸ MCP ê²€ìƒ‰ì€ ìˆ˜í–‰ë˜ì—ˆìœ¼ë‚˜ ì¶œë ¥ íŒŒì¼ í™•ì¸ ì‹¤íŒ¨", "WARNING")

                                                # ê²°ê³¼ ì €ì¥ (ì„±ê³µ/ì‹¤íŒ¨ ê´€ê³„ì—†ì´ ì„¸ë¶€ ë‚´ìš© ìœ ì§€)
                                                analysis_data["mcp_search_result"] = mcp_result
                                            else:
                                                log_capture.add_log(f"âš ï¸ MCP CSV íŒŒì¼ ì—†ìŒ: {csv_path}", "WARNING")
                                        else:
                                            log_capture.add_log("MCP Lookup ëª¨ë“ˆì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ - í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì˜ì¡´ì„± í™•ì¸", "WARN")

                                    except Exception as e:
                                        log_capture.add_log(f"âŒ MCP ë§¤ì¥ ê²€ìƒ‰ ì˜¤ë¥˜: {e}", "ERROR")
                                        import traceback
                                        traceback.print_exc()

                                    

                                    # ===== 3ë‹¨ê³„: New Product Agent ì‹¤í–‰ (ê°„ì†Œí™”) =====
                                    print("\n" + "="*60)
                                    print("[3/3] New Product Agent ì‹¤í–‰ (ê°„ì†Œí™”)")
                                    print("="*60)

                                    # New Product Agent ê°„ì†Œí™” ì‹¤í–‰
                                    try:
                                        log_capture.add_log("[3/3] New Product Agent ì‹¤í–‰ ì¤‘...", "INFO")
                                        
                                        # ê°„ì†Œí™”ëœ New Product Agent ì‹¤í–‰
                                        new_product_result = {"activated": False, "reason": "ê°„ì†Œí™”ëœ ë²„ì „"}
                                        analysis_data["new_product_result"] = new_product_result

                                        log_capture.add_log("âœ… New Product Agent ì™„ë£Œ (ê°„ì†Œí™”)", "SUCCESS")

                                    except Exception as e:
                                        log_capture.add_log(f"âŒ New Product Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}", "ERROR")
                                        analysis_data["new_product_result"] = {"activated": False, "error": str(e)}

                                    

                                    # ===== 4ë‹¨ê³„: Langchain Consultation Chain ìƒì„± =====
                                    # Langchain Consultation Chain ìƒì„±

                                    log_capture.add_log("Langchain Consultation Chain ìƒì„± ì¤‘...", "INFO")

                                    

                                    # MCP ê²€ìƒ‰ ê²°ê³¼ txt íŒŒì¼ ì½ê¸° (ìˆìœ¼ë©´)

                                    mcp_content = ""

                                    if "mcp_search_result" in analysis_data:
                                        mcp_file = analysis_data["mcp_search_result"].get("output_path") or analysis_data["mcp_search_result"].get("file")
                                        if mcp_file and Path(mcp_file).exists():

                                            try:

                                                with open(mcp_file, 'r', encoding='utf-8') as f:

                                                    mcp_content = f.read()

                                                log_capture.add_log(f"MCP ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {len(mcp_content)} bytes", "DEBUG")

                                            except Exception as e:

                                                log_capture.add_log(f"MCP íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}", "WARNING")

                                    

                                    chain, memory = create_consultation_chain(store_code, merged_data, merged_md, mcp_content)

                                    

                                    if chain and memory:

                                        log_capture.add_log("ìƒë‹´ ì²´ì¸ ìƒì„± ì™„ë£Œ", "SUCCESS")

                                        st.session_state.consultation_chain = chain

                                        st.session_state.consultation_memory = memory

                                        st.session_state.merged_data = merged_data

                                        st.session_state.merged_md = merged_md

                                        st.session_state.consultation_mode = True

                                        

                                        st.session_state.messages.append({

                                            "role": "assistant",

                                            "content": "âœ… ìƒë‹´ ì¤€ë¹„ ì™„ë£Œ! ë§ˆì¼€íŒ… ì „ëµ, MCP ê²€ìƒ‰, í¬ë¡¤ë§ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ğŸ“Š"
                                        })

                                        st.success("âœ… ìƒë‹´ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

                                        st.rerun()

                                    else:

                                        log_capture.add_log("ìƒë‹´ ì²´ì¸ ìƒì„± ì‹¤íŒ¨", "ERROR")

                                        st.error("ìƒë‹´ ì²´ì¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

                                else:

                                    log_capture.add_log("í†µí•© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "ERROR")

                                    st.error(f"í†µí•© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

                            except Exception as e:

                                log_capture.add_log(f"ìƒë‹´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", "ERROR")

                                st.error(f"ìƒë‹´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")

                                import traceback

                                traceback.print_exc()

                    else:

                        log_capture.add_log("AI Agentsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.", "WARN")

                        st.warning("AI Agentsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")

            else:

                st.info("âœ… ìƒë‹´ ëª¨ë“œ í™œì„±í™”ë¨ - ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!")

            

            # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€

            col1, col2, col3 = st.columns([1, 1, 1])

            with col2:

                if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", type="secondary", help="ìƒˆë¡œìš´ ìƒì  ì½”ë“œë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤"):

                    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”

                    for key in list(st.session_state.keys()):

                        if key not in ["log_data", "analysis_progress"]:

                            del st.session_state[key]

                    st.rerun()

            

            # íƒ­ìœ¼ë¡œ ìƒì„¸ ê²°ê³¼ í‘œì‹œ (ì‹œê°í™” íƒ­ ì œê±°)

            tab1, tab2, tab3, tab4, tab5, tab6, tab7= st.tabs([

                "ê°œìš”", "ê³ ê° ë¶„ì„", "ì´ë™ íŒ¨í„´", "ì§€ì—­ ë¶„ì„", "ìƒê¶Œ ë¶„ì„", "ë§ˆì¼€íŒ…", "ì‹ ë©”ë‰´ ì¶”ì²œ"

            ])

            

            with tab1:

                display_store_overview(analysis_data)

            

            with tab2:

                display_customer_analysis(analysis_data)

            

            with tab3:

                display_mobility_analysis(analysis_data)

            

            with tab4:

                display_panorama_analysis(analysis_data)

            

            with tab5:
                st.markdown("#### ğŸª ìƒê¶Œ ë¶„ì„")
                if "marketplace_analysis" in analysis_data:
                    marketplace_data = analysis_data["marketplace_analysis"]
                    
                    # ìƒê¶Œ ë¶„ì„ ìš”ì•½ ì •ë³´ í‘œì‹œ
                    if isinstance(marketplace_data, dict):
                        # ê¸°ë³¸ ì •ë³´
                        st.markdown("##### ğŸ“‹ ê¸°ë³¸ ì •ë³´")
                        col1, col2, col3, col4 = st.columns(4)
                        
                        with col1:
                            st.metric("ìƒê¶Œëª…", marketplace_data.get("ìƒê¶Œëª…", "N/A"))
                        with col2:
                            st.metric("ì´ í˜ì´ì§€", marketplace_data.get("ì´_í˜ì´ì§€", "N/A"))
                        with col3:
                            st.metric("ì¶”ì¶œ í˜ì´ì§€", marketplace_data.get("ì¶”ì¶œ_í˜ì´ì§€", "N/A"))
                        with col4:
                            analysis_date = marketplace_data.get("ë¶„ì„ì¼ì‹œ", "N/A")
                            if analysis_date and isinstance(analysis_date, str):
                                analysis_date = analysis_date.split("T")[0] if "T" in analysis_date else analysis_date
                            st.metric("ë¶„ì„ì¼ì‹œ", analysis_date)
                        
                        # ì¢…í•©ì˜ê²¬ ë° ì£¼ìš” ì§€í‘œ
                        if "ë°ì´í„°" in marketplace_data:
                            for item in marketplace_data["ë°ì´í„°"]:
                                if item.get("ìœ í˜•") == "ì¢…í•©ì˜ê²¬":
                                    st.markdown("---")
                                    st.markdown("##### ğŸ“Š ì¢…í•©ì˜ê²¬")
                                    
                                    # ì¢…í•©ì˜ê²¬ í…ìŠ¤íŠ¸
                                    opinions = item.get("ì¢…í•©ì˜ê²¬", [])
                                    if opinions:
                                        for opinion in opinions:
                                            st.write(f"- {opinion}")
                                    
                                    # ë©´ì  ì •ë³´
                                    if "ë©´ì " in item:
                                        area = item["ë©´ì "]
                                        st.markdown("**ğŸ“ ë©´ì  ì •ë³´**")
                                        col1, col2 = st.columns(2)
                                        with col1:
                                            selected_area = area.get('ì„ íƒ', 0)
                                            st.metric("ì„ íƒ ë©´ì ", f"{selected_area:,}ã¡", 
                                                     help="ë¶„ì„ ëŒ€ìƒìœ¼ë¡œ ì„ íƒëœ ë©´ì ")
                                        with col2:
                                            analyzed_area = area.get('ë¶„ì„', 0)
                                            st.metric("ë¶„ì„ ë©´ì ", f"{analyzed_area:,}ã¡",
                                                     help="ì‹¤ì œë¡œ ë¶„ì„ì´ ìˆ˜í–‰ëœ ë©´ì ")
                                    
                                    # ì í¬ìˆ˜ ì •ë³´
                                    if "ì í¬ìˆ˜" in item:
                                        store_count = item["ì í¬ìˆ˜"]
                                        st.markdown("---")
                                        st.markdown("##### ğŸª ì í¬ìˆ˜ ë¶„ì„")
                                        
                                        current_count = store_count.get('í˜„ì¬', {})
                                        current_value = current_count.get('ê°’', 0)
                                        qoq_change = store_count.get('ì „ë¶„ê¸°ëŒ€ë¹„', {}).get('ë³€í™”', 0)
                                        yoy_change = store_count.get('ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„', {}).get('ë³€í™”', 0)
                                        
                                        col1, col2, col3, col4 = st.columns(4)
                                        with col1:
                                            delta_str = f"{qoq_change:+}ê°œ" if qoq_change != 0 else None
                                            st.metric("í˜„ì¬ ì í¬ìˆ˜", f"{current_value:,}ê°œ", delta=delta_str,
                                                     help=f"ì „ë¶„ê¸° ëŒ€ë¹„ {qoq_change:+}ê°œ ë³€í™”")
                                        with col2:
                                            st.metric("ì „ë…„ëŒ€ë¹„", f"{yoy_change:+}ê°œ" if yoy_change != 0 else "0ê°œ",
                                                     help=f"ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„ {yoy_change:+}ê°œ ë³€í™”")
                                        with col3:
                                            rank = store_count.get('ìˆœìœ„', 'N/A')
                                            st.metric("ìˆœìœ„", rank,
                                                     help="ì„œìš¸ì‹œ ì „ì²´ ìƒê¶Œ ëŒ€ë¹„ ìˆœìœ„")
                                        with col4:
                                            criterion = current_count.get('ê¸°ì¤€', 'N/A')
                                            st.metric("ê¸°ì¤€", criterion,
                                                     help="ë°ì´í„° ì§‘ê³„ ê¸°ì¤€ ì‹œê¸°")
                                        
                                        # ì¸ì‚¬ì´íŠ¸
                                        if qoq_change > 0:
                                            st.info(f"ğŸ’¡ ì í¬ìˆ˜ê°€ {qoq_change}ê°œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ìƒê¶Œì´ í™•ì¥ë˜ê³  ìˆëŠ” ì‹œê¸°ë¡œ, ê²½ìŸ ê´€ê³„ ë³€í™”ì— ìœ ì˜í•˜ì„¸ìš”.")
                                        elif qoq_change < 0:
                                            st.warning(f"âš ï¸ ì í¬ìˆ˜ê°€ {abs(qoq_change)}ê°œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤. ìƒê¶Œ ì¶•ì†Œ ê°€ëŠ¥ì„±ì„ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.")
                                    
                                    # ë§¤ì¶œì•¡ ì •ë³´
                                    if "ë§¤ì¶œì•¡" in item:
                                        sales = item["ë§¤ì¶œì•¡"]
                                        st.markdown("---")
                                        st.markdown("##### ğŸ’° ë§¤ì¶œì•¡ ë¶„ì„")
                                        
                                        current_sales = sales.get('í˜„ì¬', {})
                                        current_value = current_sales.get('ê°’', 0)
                                        qoq_change = sales.get('ì „ë¶„ê¸°ëŒ€ë¹„', {}).get('ë³€í™”', 0)
                                        yoy_change = sales.get('ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„', {}).get('ë³€í™”', 0)
                                        
                                        col1, col2, col3, col4 = st.columns(4)
                                        with col1:
                                            delta_str = f"{qoq_change:+}ë§Œì›" if qoq_change != 0 else None
                                            st.metric("í˜„ì¬ ë§¤ì¶œì•¡", f"{current_value:,}ë§Œì›", delta=delta_str,
                                                     help=f"ì „ë¶„ê¸° ëŒ€ë¹„ {qoq_change:+}ë§Œì› ë³€í™”")
                                        with col2:
                                            st.metric("ì „ë…„ëŒ€ë¹„", f"{yoy_change:+}ë§Œì›" if yoy_change != 0 else "0ë§Œì›",
                                                     help=f"ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„ {yoy_change:+}ë§Œì› ë³€í™”")
                                        with col3:
                                            rank = sales.get('ìˆœìœ„', 'N/A')
                                            st.metric("ìˆœìœ„", rank,
                                                     help="ì„œìš¸ì‹œ ì „ì²´ ìƒê¶Œ ëŒ€ë¹„ ìˆœìœ„")
                                        with col4:
                                            criterion = current_sales.get('ê¸°ì¤€', 'N/A')
                                            st.metric("ê¸°ì¤€", criterion,
                                                     help="ë°ì´í„° ì§‘ê³„ ê¸°ì¤€ ì‹œê¸°")
                                        
                                        # ì¸ì‚¬ì´íŠ¸
                                        if yoy_change < 0:
                                            st.warning(f"âš ï¸ ì „ë…„ ëŒ€ë¹„ ë§¤ì¶œì•¡ì´ {abs(yoy_change)}ë§Œì› ê°ì†Œí–ˆìŠµë‹ˆë‹¤. ê²½ìŸ í™˜ê²½ ë³€í™” ë˜ëŠ” ì†Œë¹„ íŒ¨í„´ ë³€í™”ë¥¼ ê³ ë ¤í•´ë³´ì„¸ìš”.")
                                        elif qoq_change > 0:
                                            st.info(f"ğŸ’¡ ì „ë¶„ê¸° ëŒ€ë¹„ ë§¤ì¶œì•¡ì´ {qoq_change}ë§Œì› ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ìƒê¶Œ í™œì„±í™” ì¶”ì„¸ì…ë‹ˆë‹¤.")
                                    
                                    # ìœ ë™ì¸êµ¬ ì •ë³´
                                    if "ìœ ë™ì¸êµ¬" in item:
                                        flow = item["ìœ ë™ì¸êµ¬"]
                                        st.markdown("---")
                                        st.markdown("##### ğŸ‘¥ ìœ ë™ì¸êµ¬ ë¶„ì„")
                                        
                                        current_flow = flow.get('í˜„ì¬', {})
                                        current_value = current_flow.get('ê°’', 0)
                                        qoq_change = flow.get('ì „ë¶„ê¸°ëŒ€ë¹„', {}).get('ë³€í™”', 0)
                                        yoy_change = flow.get('ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„', {}).get('ë³€í™”', 0)
                                        
                                        col1, col2, col3, col4 = st.columns(4)
                                        with col1:
                                            delta_str = f"{qoq_change:+,}ëª…" if qoq_change != 0 else None
                                            st.metric("í˜„ì¬ ìœ ë™ì¸êµ¬", f"{current_value:,}ëª…", delta=delta_str,
                                                     help=f"ì „ë¶„ê¸° ëŒ€ë¹„ {qoq_change:+,}ëª… ë³€í™”")
                                        with col2:
                                            st.metric("ì „ë…„ëŒ€ë¹„", f"{yoy_change:+,}ëª…" if yoy_change != 0 else "0ëª…",
                                                     help=f"ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„ {yoy_change:+,}ëª… ë³€í™”")
                                        with col3:
                                            rank = flow.get('ìˆœìœ„', 'N/A')
                                            st.metric("ìˆœìœ„", rank,
                                                     help="ì„œìš¸ì‹œ ì „ì²´ ìƒê¶Œ ëŒ€ë¹„ ìˆœìœ„")
                                        with col4:
                                            criterion = current_flow.get('ê¸°ì¤€', 'N/A')
                                            st.metric("ê¸°ì¤€", criterion,
                                                     help="ë°ì´í„° ì§‘ê³„ ê¸°ì¤€ ì‹œê¸°")
                                        
                                        # ì¸ì‚¬ì´íŠ¸
                                        if abs(yoy_change) > 100000:
                                            if yoy_change < 0:
                                                st.error(f"ğŸš¨ ì „ë…„ ëŒ€ë¹„ ìœ ë™ì¸êµ¬ê°€ {abs(yoy_change):,}ëª… í¬ê²Œ ê°ì†Œí–ˆìŠµë‹ˆë‹¤. ìƒê¶Œ ì¹¨ì²´ ê°€ëŠ¥ì„±ì„ ë©´ë°€íˆ ëª¨ë‹ˆí„°ë§í•˜ì„¸ìš”.")
                                            else:
                                                st.success(f"âœ… ì „ë…„ ëŒ€ë¹„ ìœ ë™ì¸êµ¬ê°€ {yoy_change:,}ëª… í¬ê²Œ ì¦ê°€í–ˆìŠµë‹ˆë‹¤. ìƒê¶Œ í™œì„±ë„ê°€ ë†’ì•„ì§€ê³  ìˆìŠµë‹ˆë‹¤.")
                                    
                                    break
                            
                            # ìƒì„¸ í˜ì´ì§€ë³„ ë¶„ì„
                            st.markdown("---")
                            st.markdown("##### ğŸ“„ ìƒì„¸ ë¶„ì„")
                            
                            detail_items = [item for item in marketplace_data["ë°ì´í„°"] if item.get("ìœ í˜•") not in ["í‘œì§€", "ì¢…í•©ì˜ê²¬"] and item.get("ìœ í˜•")]
                            
                            for item in detail_items:
                                page_num = item.get("í˜ì´ì§€", "?")
                                item_type = item.get("ìœ í˜•", "N/A")
                                title = item.get("ì œëª©", "")
                                
                                with st.expander(f"ğŸ“„ í˜ì´ì§€ {page_num}: {title or item_type}", expanded=False):
                                    st.write(f"**ìœ í˜•:** {item_type}")
                                    
                                    # ì œëª©ì´ ìˆìœ¼ë©´ í‘œì‹œ
                                    if title:
                                        st.markdown(f"**ì œëª©:** {title}")
                                    
                                    # ì„¤ëª… ì •ë³´
                                    if "ì„¤ëª…" in item:
                                        descriptions = item.get("ì„¤ëª…", [])
                                        if descriptions:
                                            st.markdown("**ğŸ’¬ ì„¤ëª…**")
                                            for desc in descriptions:
                                                st.write(f"- {desc}")
                                    
                                    # ë¹„êµ ì •ë³´
                                    if "ë¹„êµ" in item:
                                        comparisons = item.get("ë¹„êµ", [])
                                        if comparisons:
                                            st.markdown("---")
                                            st.markdown("**ğŸ“Š ë¹„êµ ì •ë³´**")
                                            
                                            # ë¹„êµ ì •ë³´ë¥¼ í…Œì´ë¸” í˜•íƒœë¡œ í‘œì‹œ
                                            comparison_data = []
                                            for comp in comparisons:
                                                benchmark = comp.get('ê¸°ì¤€', 'N/A')
                                                change = comp.get('ë³€í™”', 'N/A')
                                                unit = comp.get('ë‹¨ìœ„', '')
                                                
                                                # ìˆ«ìì¸ ê²½ìš° í¬ë§·íŒ…
                                                if isinstance(change, (int, float)):
                                                    if abs(change) >= 1000:
                                                        change_str = f"{change:,.1f}"
                                                    else:
                                                        change_str = f"{change:.2f}" if isinstance(change, float) else str(change)
                                                else:
                                                    change_str = str(change)
                                                
                                                comparison_data.append({
                                                    "ê¸°ì¤€": benchmark,
                                                    "ë³€í™”": f"{change_str} {unit}"
                                                })
                                            
                                            st.table(comparison_data)
                                    
                                    # ì í¬ë‹¹ ì›”í‰ê·  ë§¤ì¶œê±´ìˆ˜
                                    if "ì í¬ë‹¹ì›”í‰ê· ë§¤ì¶œê±´ìˆ˜" in item:
                                        sales_count = item["ì í¬ë‹¹ì›”í‰ê· ë§¤ì¶œê±´ìˆ˜"]
                                        st.markdown("---")
                                        st.markdown("**ğŸ’° ë§¤ì¶œ ê±´ìˆ˜ ì •ë³´**")
                                        count_value = sales_count.get('ê°’', 0)
                                        count_unit = sales_count.get('ë‹¨ìœ„', 'ê±´')
                                        st.metric("ì í¬ë‹¹ ì›”í‰ê·  ë§¤ì¶œê±´ìˆ˜", f"{count_value:,}{count_unit}",
                                                 help="ìƒê¶Œ ë‚´ ì í¬ì˜ ì›”í‰ê·  ê±°ë˜ ê±´ìˆ˜")
                                        
                                        # ì¸ì‚¬ì´íŠ¸
                                        if count_value >= 500:
                                            st.info(f"ğŸ’¡ ì›”í‰ê·  {count_value}ê±´ì˜ ê±°ë˜ê°€ ë°œìƒí•˜ëŠ” í™œë°œí•œ ìƒê¶Œì…ë‹ˆë‹¤.")
                                        elif count_value < 200:
                                            st.warning(f"âš ï¸ ì›”í‰ê·  {count_value}ê±´ìœ¼ë¡œ ê±°ë˜ ë¹ˆë„ê°€ ìƒëŒ€ì ìœ¼ë¡œ ë‚®ìŠµë‹ˆë‹¤.")
                                    
                                    # ê°œì—…/íì—… ì •ë³´
                                    if "í˜ì—…ìˆ˜" in item:
                                        close_count = item["í˜ì—…ìˆ˜"]
                                        st.markdown("---")
                                        st.markdown("**ğŸšª íì—… í˜„í™©**")
                                        close_value = close_count.get('ê°’', 0)
                                        close_unit = close_count.get('ë‹¨ìœ„', 'ê°œ')
                                        st.metric("íì—…ìˆ˜", f"{close_value:,}{close_unit}")
                                    
                                    # ì‹ ìƒê¸°ì—…ìƒì¡´ìœ¨ ì •ë³´
                                    if title and "ì‹ ìƒê¸°ì—…ìƒì¡´ìœ¨" in title:
                                        if "ë¹„êµ" in item:
                                            comparisons = item.get("ë¹„êµ", [])
                                            seoul_bench = None
                                            district_bench = None
                                            
                                            for comp in comparisons:
                                                benchmark = comp.get('ê¸°ì¤€', '')
                                                change = comp.get('ë³€í™”', 0)
                                                
                                                if "ì„œìš¸ì‹œëŒ€ë¹„" in benchmark:
                                                    seoul_bench = change
                                                elif "ìì¹˜êµ¬ëŒ€ë¹„" in benchmark:
                                                    district_bench = change
                                            
                                            st.markdown("---")
                                            st.markdown("**ğŸ“ˆ ìƒì¡´ìœ¨ ë¹„êµ ë¶„ì„**")
                                            
                                            if seoul_bench is not None:
                                                st.metric("ì„œìš¸ì‹œ í‰ê·  ëŒ€ë¹„", f"{seoul_bench:.1f}ë…„",
                                                         delta="ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ë‚®ìŒ" if seoul_bench < 0 else "ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ ë†’ìŒ",
                                                         help="ì„œìš¸ì‹œ í‰ê·  ì˜ì—… ê¸°ê°„ê³¼ì˜ ì°¨ì´")
                                            
                                            if district_bench is not None:
                                                st.metric("ìì¹˜êµ¬ í‰ê·  ëŒ€ë¹„", f"{district_bench:.1f}ë…„",
                                                         delta="ìì¹˜êµ¬ í‰ê· ë³´ë‹¤ ë‚®ìŒ" if district_bench < 0 else "ìì¹˜êµ¬ í‰ê· ë³´ë‹¤ ë†’ìŒ",
                                                         help="ìì¹˜êµ¬ í‰ê·  ì˜ì—… ê¸°ê°„ê³¼ì˜ ì°¨ì´")
                                            
                                            # ì¸ì‚¬ì´íŠ¸
                                            if seoul_bench and seoul_bench < 0:
                                                st.warning(f"âš ï¸ ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ {abs(seoul_bench):.1f}ë…„ ì§§ì€ ì˜ì—… ê¸°ê°„ì„ ë³´ì…ë‹ˆë‹¤. ì´ ì—…ì¢…ì˜ ê²½ìŸë ¥ì´ ë¶€ì¡±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                            elif seoul_bench and seoul_bench > 0:
                                                st.success(f"âœ… ì„œìš¸ì‹œ í‰ê· ë³´ë‹¤ {seoul_bench:.1f}ë…„ ê¸´ ì˜ì—… ê¸°ê°„ì„ ë³´ì…ë‹ˆë‹¤. ì•ˆì •ì ì¸ ìƒê¶Œìœ¼ë¡œ íŒë‹¨ë©ë‹ˆë‹¤.")
                    else:
                        st.json(marketplace_data)
                else:
                    st.info("ìƒê¶Œ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            with tab6:
                st.markdown("#### ğŸ“ˆ ë§ˆì¼€íŒ… ë¶„ì„")
                if "marketing_analysis" in analysis_data:
                    marketing_data = analysis_data["marketing_analysis"]
                    
                    # formatted_outputì´ ìˆìœ¼ë©´ ë¨¼ì € í‘œì‹œí•˜ê³  ê³„ì† ì§„í–‰
                    if isinstance(marketing_data, dict) and "formatted_output" in marketing_data and marketing_data.get("formatted_output"):
                        st.markdown(marketing_data["formatted_output"])
                        st.markdown("---")
                        st.markdown("## ğŸ“Š ìƒì„¸ ë¶„ì„ ë°ì´í„°")
                    
                    # êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ í‘œì‹œ
                    if isinstance(marketing_data, dict):
                        
                        # ========== 1. ìœ„í—˜ ì§„ë‹¨ (Risk Diagnosis) ==========
                        if "risk_analysis" in marketing_data and marketing_data.get("risk_analysis"):
                            try:
                                risk = marketing_data["risk_analysis"]
                                st.markdown("### â–² ìœ„í—˜ ì§„ë‹¨ (Risk Diagnosis)")
                                
                                # ì „ì²´ ìœ„í—˜ ìˆ˜ì¤€
                                risk_level = risk.get('overall_risk_level', 'N/A')
                                risk_emoji = "ğŸ”´" if risk_level in ["ìœ„í—˜", "ë†’ìŒ"] else "ğŸŸ¡" if risk_level == "ë³´í†µ" else "ğŸŸ¢"
                                st.markdown(f"**ì „ì²´ ìœ„í—˜ ìˆ˜ì¤€:** {risk_emoji} **{risk_level}**")
                                
                                # ìœ„í—˜ ìš”ì†Œ ê°œìˆ˜ í‘œì‹œ
                                if "detected_risks" in risk and risk.get("detected_risks"):
                                    detected_risks = risk["detected_risks"]
                                    risk_codes = [r.get('code', '') for r in detected_risks if isinstance(r, dict) and r.get('code')]
                                    st.write(f"ì´ ë§¤ì¥ì—ì„œ íŒŒì•…ëœ ìœ„í—˜ ìš”ì†ŒëŠ” {', '.join(risk_codes)}ë¡œ {len(risk_codes)}ê°œì˜ ìš”ì†Œê°€ ìˆìŠµë‹ˆë‹¤.")
                                
                                st.markdown("---")
                                st.markdown("### â–  ìœ„í—˜ ìš”ì†Œ ìƒì„¸ (Detailed Risk Factors)")
                                
                                # ìœ„í—˜ ìš”ì†Œ ìƒì„¸ í‘œ
                                if isinstance(risk, dict) and "detected_risks" in risk and risk.get("detected_risks"):
                                    detected_risks = risk["detected_risks"]
                                    if isinstance(detected_risks, list) and len(detected_risks) > 0:
                                        # í…Œì´ë¸” í—¤ë”
                                        cols = st.columns([1, 3, 2, 2, 2])
                                        with cols[0]:
                                            st.markdown("**ì½”ë“œ**")
                                        with cols[1]:
                                            st.markdown("**ì˜ë¯¸**")
                                        with cols[2]:
                                            st.markdown("**ìˆ˜ì¤€**")
                                        with cols[3]:
                                            st.markdown("**ì ìˆ˜**")
                                        with cols[4]:
                                            st.markdown("**ìš°ì„ ìˆœìœ„**")
                                        
                                        st.divider()
                                        
                                        # í…Œì´ë¸” ë°ì´í„°
                                        for idx, risk_item in enumerate(detected_risks):
                                            if isinstance(risk_item, dict):
                                                cols = st.columns([1, 3, 2, 2, 2])
                                                with cols[0]:
                                                    st.write(risk_item.get('code', 'N/A'))
                                                with cols[1]:
                                                    st.write(risk_item.get('name', 'N/A'))
                                                with cols[2]:
                                                    st.write(risk_item.get('level', 'N/A'))
                                                with cols[3]:
                                                    st.write(risk_item.get('score', 'N/A'))
                                                with cols[4]:
                                                    st.write(risk_item.get('priority', 'N/A'))
                                                if idx < len(detected_risks) - 1:
                                                    st.divider()
                                        
                                        # ìœ„í—˜ ë¶„ì„ ìš”ì•½
                                        st.markdown("---")
                                        st.markdown("### â–  ìœ„í—˜ ë¶„ì„ ìš”ì•½ (Risk Analysis Summary)")
                                        if "analysis_summary" in risk:
                                            st.write(risk['analysis_summary'])
                                        
                                        # ìœ„í—˜ ìš”ì†Œ ìƒì„¸ ë¶„ì„
                                        st.markdown("**â— ìœ„í—˜ ìš”ì†Œ ìƒì„¸ ë¶„ì„:**")
                                        for risk_item in detected_risks:
                                            if isinstance(risk_item, dict):
                                                st.write(f"**{risk_item.get('code', 'N/A')}**: {risk_item.get('name', 'N/A')}")
                                                if risk_item.get('description'):
                                                    st.write(f"  - ì„¤ëª…: {risk_item.get('description')}")
                                                if risk_item.get('evidence'):
                                                    st.write(f"  - ê·¼ê±°: {risk_item.get('evidence')}")
                            except Exception as e:
                                st.error(f"ìœ„í—˜ ë¶„ì„ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
                        
                        # ========== 2. ì¢…í•© ê²°ë¡  (Overall Conclusion) ==========
                        if "persona_analysis" in marketing_data and marketing_data.get("persona_analysis"):
                            try:
                                persona = marketing_data["persona_analysis"]
                                
                                if "core_insights" in persona and "persona" in persona["core_insights"]:
                                    insights = persona["core_insights"]["persona"]
                                    
                                    st.markdown("---")
                                    st.markdown("### â–  ì¢…í•© ê²°ë¡  (Overall Conclusion)")
                                    
                                    # Summary í‘œì‹œ
                                    if "summary" in insights:
                                        st.write(insights["summary"])
                                    
                                    # ë§¤ì¥ íŠ¹ì„± í…Œì´ë¸”
                                    if "table_data" in insights and isinstance(insights["table_data"], dict):
                                        st.markdown("**ë§¤ì¥ íŠ¹ì„±:**")
                                        table_data = insights["table_data"]
                                        for key, value in table_data.items():
                                            st.write(f"**{key}**: {value}")
                            except Exception as e:
                                st.error(f"ì¢…í•© ê²°ë¡  ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
                        
                        # ========== 3. í™ë³´ ì•„ì´ë””ì–´ (Promotion Ideas) ==========
                        if "marketing_strategies" in marketing_data and marketing_data.get("marketing_strategies"):
                            try:
                                st.markdown("---")
                                st.markdown("### â–  í™ë³´ ì•„ì´ë””ì–´ (Promotion Ideas)")
                                strategies = marketing_data["marketing_strategies"]
                                
                                if isinstance(strategies, list):
                                    for i, strategy in enumerate(strategies, 1):
                                        if isinstance(strategy, dict):
                                            strategy_name = strategy.get('name', f'ì „ëµ {i}')
                                            strategy_desc = strategy.get('description', 'N/A')
                                            
                                            # nameê³¼ description ê²°í•©
                                            if strategy_desc and strategy_desc != 'N/A':
                                                full_text = f"{strategy_name} {strategy_desc}"
                                            else:
                                                full_text = strategy_name
                                            
                                            st.markdown(f"**{i}.** {full_text}")
                                            
                                            # ì˜ˆìƒ íš¨ê³¼, êµ¬í˜„ ê¸°ê°„ í‘œì‹œ
                                            if strategy.get('expected_impact'):
                                                st.caption(f"ğŸ“Š ì˜ˆìƒ íš¨ê³¼: {strategy.get('expected_impact')}")
                                            if strategy.get('implementation_time'):
                                                st.caption(f"â±ï¸ êµ¬í˜„ ê¸°ê°„: {strategy.get('implementation_time')}")
                                            st.divider()
                            except Exception as e:
                                st.error(f"í™ë³´ ì•„ì´ë””ì–´ ë¡œë“œ ì˜¤ë¥˜: {e}")
                        
                        # ========== 4. íƒ€ê²Ÿ ì „ëµ (Target Strategy) ==========
                        if "persona_analysis" in marketing_data and marketing_data.get("persona_analysis"):
                            try:
                                persona = marketing_data["persona_analysis"]
                                
                                st.markdown("---")
                                st.markdown("### â–  íƒ€ê²Ÿ ì „ëµ (Target Strategy)")
                                
                                # 1. ì£¼ íƒ€ê²Ÿ ê³ ê°ì¸µ
                                st.markdown("**1. ì£¼ íƒ€ê²Ÿ ê³ ê°ì¸µ (Primary Target Audience)**")
                                
                                if "components" in persona and isinstance(persona["components"], dict):
                                    components = persona["components"]
                                    
                                    if "customer_demographics" in components and isinstance(components["customer_demographics"], dict):
                                        demo = components["customer_demographics"]
                                        st.write(f"**ì„±ë³„:** {demo.get('gender', 'N/A')}")
                                        st.write(f"**ì—°ë ¹ëŒ€:** {demo.get('age', 'N/A')}")
                                    
                                    # í˜ë¥´ì†Œë‚˜ ì •ë³´
                                    if persona.get('persona_type'):
                                        st.write(f"**í˜ë¥´ì†Œë‚˜ íƒ€ì…:** {persona.get('persona_type', 'N/A')}")
                                    if persona.get('persona_description'):
                                        st.write(f"**íŠ¹ì„±:** {persona.get('persona_description', 'N/A')}")
                                    
                                    # ì¶”ì²œ ì±„ë„
                                    if "key_channels" in persona and isinstance(persona["key_channels"], list):
                                        st.markdown("**ì¶”ì²œ ì±„ë„:**")
                                        for channel in persona["key_channels"]:
                                            if channel:
                                                st.write(f"  - {channel}")
                                
                                # 2. ë³´ì¡° íƒ€ê²Ÿ ê³ ê°ì¸µ ë° í™•ì¥ ì „ëµ
                                st.markdown("---")
                                st.markdown("**2. ë³´ì¡° íƒ€ê²Ÿ ê³ ê°ì¸µ ë° í™•ì¥ ì „ëµ (Secondary Target Audience & Expansion Strategy)**")
                                if "persona_analysis" in marketing_data:
                                    persona = marketing_data["persona_analysis"]
                                    if "components" in persona:
                                        components = persona["components"]
                                        st.write(f"**ì—…ì¢… íŠ¹ì„±:** {components.get('industry', 'N/A')}")
                                        st.write(f"**ìƒê¶Œ íŠ¹ì„±:** {components.get('commercial_zone', 'N/A')}")
                                        st.write(f"**ë§¤ì¥ ì•ˆì •ì„±:** {components.get('store_age', 'N/A')}")
                            except Exception as e:
                                st.error(f"íƒ€ê²Ÿ ì „ëµ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
                        
                        # ========== 5. ë§ˆì¼€íŒ… ì±„ë„ ì „ëµ (Marketing Channel Strategy) ==========
                        if "channel_recommendation" in marketing_data and marketing_data.get("channel_recommendation"):
                            try:
                                st.markdown("---")
                                st.markdown("### â–  ë§ˆì¼€íŒ… ì±„ë„ ì „ëµ (Marketing Channel Strategy)")
                                channel_rec = marketing_data["channel_recommendation"]
                                
                                if isinstance(channel_rec, dict):
                                    # ì˜¨ë¼ì¸ ì±„ë„
                                    st.markdown("**ì˜¨ë¼ì¸ ì±„ë„:**")
                                    
                                    if "primary_channel" in channel_rec:
                                        st.write(f"**ì¶”ì²œ ì±„ë„:** {channel_rec.get('primary_channel', 'N/A')}")
                                    if "usage_rate" in channel_rec:
                                        st.write(f"**ì‚¬ìš©ë¥ :** {channel_rec.get('usage_rate', 'N/A')}%")
                                    if "reasoning" in channel_rec:
                                        st.write(f"**ì¶”ì²œ ì´ìœ :** {channel_rec['reasoning']}")
                                    
                                    # ì±„ë„ë³„ ìƒì„¸ ë°ì´í„°
                                    if "channel_data" in channel_rec and isinstance(channel_rec["channel_data"], list):
                                        st.markdown("**ì±„ë„ë³„ ì‚¬ìš©ë¥  ë° íŠ¸ë Œë“œ:**")
                                        for channel_data in channel_rec["channel_data"]:
                                            if isinstance(channel_data, dict):
                                                channel_name = channel_data.get('channel', 'N/A')
                                                usage = channel_data.get('usage_percent', 'N/A')
                                                trend = channel_data.get('trend_label', 'N/A')
                                                trend_emoji = channel_data.get('trend_emoji', '')
                                                recommendation = channel_data.get('recommendation', 'N/A')
                                                st.write(f"  - **{channel_name}**: {usage}% ({trend_emoji} {trend}) - {recommendation}")
                                    
                                    # í”¼í•  ì±„ë„
                                    if "avoid_channels" in channel_rec and channel_rec["avoid_channels"]:
                                        st.markdown("**âš ï¸ í”¼í•  ì±„ë„:**")
                                        for avoid_ch in channel_rec["avoid_channels"]:
                                            st.write(f"  - {avoid_ch}")
                                    
                                    # ì˜¤í”„ë¼ì¸ ì±„ë„
                                    st.markdown("---")
                                    st.markdown("**ì˜¤í”„ë¼ì¸ ì±„ë„:**")
                                    st.write("  - **ë§¤ì¥ POP/ì „ë‹¨ì§€**: MZê°ì„± í˜ë¥´ì†Œë‚˜ì— ë§ì¶˜ ë””ìì¸ìœ¼ë¡œ ì‹ ë©”ë‰´/ì´ë²¤íŠ¸ í™ë³´, ë§¤ì¥ ì£¼ë³€ 500m ë°°í¬")
                                    st.write("  - **í˜„ìˆ˜ë§‰/ê°„íŒ**: ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´/ê°ì„±ì„ ê°„ê²°í•˜ê²Œ ì „ë‹¬, ìœ ë™ ì¸êµ¬ ë§ì€ ìœ„ì¹˜ì— ì„¤ì¹˜")
                                    st.write("  - **ì´ë²¤íŠ¸/í”„ë¡œëª¨ì…˜**: ë§¤ì¥ ë‚´ í¬í† ì¡´ ì¸ì¦ìƒ·, ìŠ¤íƒ¬í”„ ì ë¦½ ì±Œë¦°ì§€, ì›ë°ì´ í´ë˜ìŠ¤/ì›Œí¬ìˆ")
                                    
                                    # í†µí•© ì±„ë„ ì „ëµ
                                    st.markdown("---")
                                    st.markdown("**í†µí•© ì±„ë„ ì „ëµ:**")
                                    st.write("  - **O2O ì „ëµ**: ì˜¨ë¼ì¸ì—ì„œ ì˜¤í”„ë¼ì¸ ë°©ë¬¸ ìœ ë„, ì˜¤í”„ë¼ì¸ì—ì„œ ì˜¨ë¼ì¸ ì¬ì°¸ì—¬ ìœ ë„")
                                    st.write("  - **ì±„ë„ ê°„ ì‹œë„ˆì§€ ê·¹ëŒ€í™”**: ì˜¨ë¼ì¸-ì˜¤í”„ë¼ì¸ ì—°ê³„ ì´ë²¤íŠ¸, QR ì½”ë“œ í™œìš©, ì§€ì—­ ì»¤ë®¤ë‹ˆí‹° ì œíœ´")
                            except Exception as e:
                                st.error(f"ë§ˆì¼€íŒ… ì±„ë„ ì „ëµ ë¡œë“œ ì˜¤ë¥˜: {e}")
                        
                        # ========== 6. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (Key Insights) ==========
                        st.markdown("---")
                        st.markdown("### â–  í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (Key Insights)")
                        
                        insights_list = []
                        
                        # ì¸ì‚¬ì´íŠ¸ 1: í•µì‹¬ ê³ ê°ì¸µ
                        if "persona_analysis" in marketing_data:
                            persona = marketing_data["persona_analysis"]
                            if persona.get("persona_type") and persona.get("persona_description"):
                                insights_list.append({
                                    "title": "í•µì‹¬ ê³ ê°ì¸µ",
                                    "content": f"ì´ ë§¤ì¥ì€ '{persona.get('persona_type', 'N/A')}' ìœ í˜•ì˜ ëª…í™•í•œ í˜ë¥´ì†Œë‚˜ë¥¼ ë³´ìœ í•˜ê³  ìˆìŠµë‹ˆë‹¤. {persona.get('persona_description', 'N/A')}"
                                })
                        
                        # ì¸ì‚¬ì´íŠ¸ 2: ê²½ìŸ ìš°ìœ„
                        if "persona_analysis" in marketing_data:
                            persona = marketing_data["persona_analysis"]
                            if "components" in persona:
                                components = persona["components"]
                                industry = components.get('industry', 'N/A')
                                zone = components.get('commercial_zone', 'N/A')
                                age = components.get('store_age', 'N/A')
                                insights_list.append({
                                    "title": "ê²½ìŸ ìš°ìœ„",
                                    "content": f"{industry} ì—…ì¢…ì˜ {zone} ìƒê¶Œì—ì„œ {age} ë‹¨ê³„ì˜ ì•ˆì •ì ì¸ ìš´ì˜ì„ í•˜ê³  ìˆìœ¼ë©°, ëª…í™•í•œ íƒ€ê²Ÿ í˜ë¥´ì†Œë‚˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì°¨ë³„í™”ëœ í¬ì§€ì…”ë‹ ì ì¬ë ¥ì„ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤."
                                })
                        
                        # ì¸ì‚¬ì´íŠ¸ 3: ê°œì„  í•„ìš” ì˜ì—­
                        if "risk_analysis" in marketing_data and marketing_data.get("risk_analysis"):
                            risk = marketing_data["risk_analysis"]
                            if "analysis_summary" in risk:
                                insights_list.append({
                                    "title": "ê°œì„  í•„ìš” ì˜ì—­",
                                    "content": risk.get('analysis_summary', 'N/A')
                                })
                        
                        # ì¸ì‚¬ì´íŠ¸ í‘œì‹œ
                        for i, insight in enumerate(insights_list, 1):
                            st.write(f"**{i}. {insight.get('title', 'N/A')}:**")
                            st.write(insight.get('content', 'N/A'))
                            if i < len(insights_list):
                                st.divider()
                        
                        # ========== 7. ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ (Next Step Proposals) ==========
                        if "recommendations" in marketing_data and marketing_data.get("recommendations"):
                            try:
                                st.markdown("---")
                                st.markdown("### â–  ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ (Next Step Proposals)")
                                rec = marketing_data["recommendations"]
                                
                                if isinstance(rec, dict):
                                    if "immediate_actions" in rec and rec.get("immediate_actions"):
                                        for i, action in enumerate(rec["immediate_actions"], 1):
                                            if action:
                                                st.write(f"**{i}. {action}**")
                                    
                                    if "short_term_goals" in rec and rec.get("short_term_goals"):
                                        st.markdown("---")
                                        st.markdown("**ë‹¨ê¸° ëª©í‘œ:**")
                                        for goal in rec["short_term_goals"]:
                                            if goal:
                                                st.write(f"  - {goal}")
                                    
                                    if "long_term_strategy" in rec and rec.get("long_term_strategy"):
                                        st.markdown("---")
                                        st.markdown("**ì¥ê¸° ì „ëµ:**")
                                        for strategy in rec["long_term_strategy"]:
                                            if strategy:
                                                st.write(f"  - {strategy}")
                            except Exception as e:
                                st.error(f"ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ ë¡œë“œ ì˜¤ë¥˜: {e}")
                        
                        # ========== 8. SNS ì½˜í…ì¸  (ì˜µì…˜) ==========
                        if "social_content" in marketing_data and marketing_data.get("social_content"):
                            try:
                                with st.expander("ğŸ“± SNS ì½˜í…ì¸  ë° í”„ë¡œëª¨ì…˜ í…ìŠ¤íŠ¸", expanded=False):
                                    social = marketing_data["social_content"]
                                    
                                    if "instagram_posts" in social and social.get("instagram_posts"):
                                        st.markdown("**ğŸ“¸ ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸:**")
                                        for i, post in enumerate(social["instagram_posts"], 1):
                                            if isinstance(post, dict):
                                                st.markdown(f"**í¬ìŠ¤íŠ¸ {i}:** {post.get('title', 'N/A')}")
                                                st.write(post.get('content', 'N/A'))
                                                if post.get('hashtags'):
                                                    st.caption(f"í•´ì‹œíƒœê·¸: {', '.join(post.get('hashtags', [])[:5])}")
                                                st.divider()
                                    
                                    if "facebook_posts" in social and social.get("facebook_posts"):
                                        st.markdown("**ğŸ‘¥ í˜ì´ìŠ¤ë¶ í¬ìŠ¤íŠ¸:**")
                                        for i, post in enumerate(social["facebook_posts"], 1):
                                            if isinstance(post, dict):
                                                st.markdown(f"**í¬ìŠ¤íŠ¸ {i}:** {post.get('title', 'N/A')}")
                                                st.write(post.get('content', 'N/A'))
                                                if post.get('call_to_action'):
                                                    st.caption(f"CTA: {post.get('call_to_action')}")
                                                st.divider()
                                    
                                    if "promotion_texts" in social and social.get("promotion_texts"):
                                        st.markdown("**ğŸ“§ í”„ë¡œëª¨ì…˜ í…ìŠ¤íŠ¸:**")
                                        for promo in social["promotion_texts"]:
                                            if isinstance(promo, dict):
                                                st.markdown(f"**{promo.get('type', 'N/A')}:**")
                                                st.write(f"ì œëª©: {promo.get('title', 'N/A')}")
                                                st.write(f"ë‚´ìš©: {promo.get('content', 'N/A')}")
                                                if promo.get('discount'):
                                                    st.caption(f"í• ì¸: {promo.get('discount')}")
                                                st.divider()
                            except Exception as e:
                                st.error(f"SNS ì½˜í…ì¸  ë¡œë“œ ì˜¤ë¥˜: {e}")
                        
                        # ========== 9. ì „ì²´ JSON ë°ì´í„° (ë°±ì—…) ==========
                        with st.expander("ğŸ“„ ì „ì²´ ë§ˆì¼€íŒ… ë°ì´í„° (JSON ì›ë³¸)", expanded=False):
                            st.json(marketing_data)
                    else:
                        st.json(marketing_data)
                else:
                    st.info("ë§ˆì¼€íŒ… ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            with tab7:
                st.markdown("#### ğŸ½ï¸ ì‹ ë©”ë‰´ ì¶”ì²œ")
                if "new_product_result" in analysis_data:
                    new_product_data = analysis_data["new_product_result"]
                    
                    # ì‹ ë©”ë‰´ ì¶”ì²œ ìš”ì•½ ì •ë³´ í‘œì‹œ
                    if isinstance(new_product_data, dict):
                        if "proposals" in new_product_data:
                            st.markdown("##### ğŸ½ï¸ ì¶”ì²œ ë©”ë‰´")
                            for i, proposal in enumerate(new_product_data["proposals"][:3], 1):
                                st.write(f"**ë©”ë‰´ {i}:** {proposal.get('menu_name', 'N/A')}")
                                st.write(f"**ì¹´í…Œê³ ë¦¬:** {proposal.get('category', 'N/A')}")
                                if "target" in proposal:
                                    target = proposal["target"]
                                    st.write(f"**íƒ€ê²Ÿ:** {target.get('gender', 'N/A')} {target.get('ages', 'N/A')}")
                                st.write("---")
                        else:
                            st.json(new_product_data)
                    else:
                        st.json(new_product_data)
                else:
                    st.info("ì‹ ë©”ë‰´ ì¶”ì²œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            
    

    else:

        # ì´ˆê¸° ìƒíƒœ

        st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”!")

        

        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ìƒì  ì½”ë“œë“¤ì„ ê°„ë‹¨íˆ í‘œì‹œ
        output_dir = Path("open_sdk/output")

        existing_analyses = []

        

        if output_dir.exists():

            for analysis_folder in output_dir.iterdir():

                if analysis_folder.is_dir() and analysis_folder.name.startswith("analysis_"):

                    # í´ë”ëª…ì—ì„œ ìƒì  ì½”ë“œ ì¶”ì¶œ (analysis_XXXXX_YYYYMMDD_HHMMSS í˜•ì‹)

                    parts = analysis_folder.name.split("_")

                    if len(parts) >= 2:

                        store_code = parts[1]

                        # analysis_result.json íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸

                        result_file = analysis_folder / "analysis_result.json"

                        if result_file.exists():

                            # ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ í¬ë§·
                            try:
                                if len(parts) >= 3:
                                    date_str = parts[2]  # YYYYMMDD
                                    if len(date_str) == 8:
                                        formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
                                    else:
                                        formatted_date = "N/A"
                                else:
                                    formatted_date = "N/A"
                            except:
                                formatted_date = "N/A"
                            
                            existing_analyses.append({

                                "store_code": store_code,

                                "analysis_date": formatted_date
                            })

        

