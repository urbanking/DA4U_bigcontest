"""
BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤
Langchain + Gemini ë²„ì „ (OpenAI Agents SDK ì œê±°)
"""
import streamlit as st
from pathlib import Path
import json
import asyncio
import os
import sys
import time
from datetime import datetime
import platform
from dotenv import load_dotenv
import io
import threading
from contextlib import redirect_stdout, redirect_stderr
import logging
from streamlit_autorefresh import st_autorefresh

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ê°œì„ ëœ Streamlit ë¡œê¹… í•¸ë“¤ëŸ¬
class StreamlitHandler(logging.Handler):
    def emit(self, record):
        log_entry = self.format(record)
        if "log_data" not in st.session_state:
            st.session_state["log_data"] = ""
        st.session_state["log_data"] += log_entry + "\n"
        
        # ë¡œê·¸ê°€ ë„ˆë¬´ ë§ì•„ì§€ë©´ ìµœê·¼ 1000ì¤„ë§Œ ìœ ì§€
        if len(st.session_state["log_data"].split('\n')) > 1000:
            lines = st.session_state["log_data"].split('\n')
            st.session_state["log_data"] = '\n'.join(lines[-1000:])

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
handler = StreamlitHandler()
formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
handler.setFormatter(formatter)
logger.addHandler(handler)
logger.setLevel(logging.INFO)

# ê¸°ì¡´ LogCapture í˜¸í™˜ì„±ì„ ìœ„í•œ ë˜í¼ í´ë˜ìŠ¤
class LogCapture:
    def __init__(self):
        self.logs = []
        
    def add_log(self, message, level="INFO"):
        """ìˆ˜ë™ìœ¼ë¡œ ë¡œê·¸ ì¶”ê°€"""
        if level == "INFO":
            logger.info(message)
        elif level == "SUCCESS":
            logger.info(f"âœ… {message}")
        elif level == "ERROR":
            logger.error(message)
        elif level == "WARN":
            logger.warning(message)
        elif level == "DEBUG":
            logger.debug(message)
        elif level == "OK":
            logger.info(f"âœ“ {message}")
        else:
            logger.info(f"[{level}] {message}")
        
    def get_logs(self, max_lines=100):
        """ìµœê·¼ ë¡œê·¸ ë°˜í™˜"""
        if "log_data" in st.session_state:
            lines = st.session_state["log_data"].split('\n')
            return lines[-max_lines:] if lines else []
        return []
        
    def clear_logs(self):
        """ë¡œê·¸ ì´ˆê¸°í™”"""
        if "log_data" in st.session_state:
            st.session_state["log_data"] = ""

# ì „ì—­ ë¡œê·¸ ìº¡ì²˜ ì¸ìŠ¤í„´ìŠ¤
log_capture = LogCapture()

# ë¶„ì„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸ í•¨ìˆ˜
def update_analysis_progress(step: str, status: str = "in_progress"):
    """ë¶„ì„ ì§„í–‰ ìƒí™© ì—…ë°ì´íŠ¸"""
    if "analysis_progress" not in st.session_state:
        st.session_state.analysis_progress = {}
    
    st.session_state.analysis_progress[step] = status

# matplotlib import ë° ì„¤ì •
import matplotlib
import matplotlib.pyplot as plt
import seaborn as sns

# í•œê¸€ í°íŠ¸ ì„¤ì •
system = platform.system()
if system == "Windows":
    plt.rcParams['font.family'] = 'Malgun Gothic'
elif system == "Darwin":
    plt.rcParams['font.family'] = 'AppleGothic'
else:
    plt.rcParams['font.family'] = 'NanumGothic'
matplotlib.rcParams['axes.unicode_minus'] = False

print("[OK] Matplotlib loaded successfully")




# run_analysis.py ì§ì ‘ import
sys.path.insert(0, str(Path(__file__).parent.parent))  # open_sdk ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "agents_new"))  # agents_new ì¶”ê°€
from run_analysis import run_full_analysis_pipeline, convert_store_to_marketing_format, _convert_enums_to_strings

# Marketing Agent import
MARKETING_AGENT_AVAILABLE = False
try:
    from agents_new.marketing_agent.marketing_agent import marketingagent
    MARKETING_AGENT_AVAILABLE = True
    print("[OK] Marketing Agent loaded successfully")
except ImportError as e:
    print(f"[WARN] Marketing Agent import failed: {e}")
except Exception as e:
    print(f"[ERROR] Marketing Agent error: {e}")
    import traceback
    traceback.print_exc()

# Langchain AI Agents import
AGENTS_AVAILABLE = False
try:
    from ai_agents import (
        classify_query_sync,
        create_consultation_chain,
        chat_with_consultant,
        load_merged_analysis
    )
    AGENTS_AVAILABLE = True
    print("[OK] Langchain AI Agents loaded successfully")
except ImportError as e:
    print(f"[WARN] AI Agents import failed: {e}")
except Exception as e:
    print(f"[ERROR] AI Agents error: {e}")
    import traceback
    traceback.print_exc()

# OpenAI SDKë¡œ Gemini 2.5 Flash ì‚¬ìš©
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
    # OpenAI SDKë¡œ Gemini API í˜¸ì¶œ
    openai_client = OpenAI(
        api_key=os.getenv("GEMINI_API_KEY"),
        base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
    )
    print("[OK] OpenAI SDK with Gemini 2.5 Flash initialized")
except Exception as e:
    OPENAI_AVAILABLE = False
    openai_client = None
    print(f"OpenAI client with Gemini not available: {e}")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤",
    page_icon="ğŸª",
    layout="wide"
)

# ìë™ ìƒˆë¡œê³ ì¹¨ ë¹„í™œì„±í™” (ë¬´í•œ ë£¨í”„ ë°©ì§€)
# if st.session_state.get('is_analyzing', False) and not st.session_state.get('stop_autorefresh', False):
#     st_autorefresh(interval=5000, limit=50, key="logrefresh")

# ì»¤ìŠ¤í…€ CSS (í•œê¸€ í°íŠ¸ ì ìš©)
st.markdown("""
    <style>
        @import url('https://fonts.googleapis.com/css2?family=Noto+Sans+KR:wght@300;400;500;700&display=swap');
        
        * {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stMarkdown, .stText, .stSelectbox, .stTextInput, .stButton, .stMetric, .stExpander {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stMarkdown h1, .stMarkdown h2, .stMarkdown h3, .stMarkdown h4, .stMarkdown h5, .stMarkdown h6 {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stTabs [data-baseweb="tab-list"] {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stTabs [data-baseweb="tab"] {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stSelectbox label, .stTextInput label {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stButton > button {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stMetric [data-testid="metric-container"] {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
        
        .stExpander [data-testid="stExpander"] {
            font-family: 'Noto Sans KR', 'Malgun Gothic', 'AppleGothic', sans-serif !important;
        }
    </style>
    """, unsafe_allow_html=True)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'store_code' not in st.session_state:
    st.session_state.store_code = None
if 'is_analyzing' not in st.session_state:
    st.session_state.is_analyzing = False
if 'analysis_complete' not in st.session_state:
    st.session_state.analysis_complete = False
if 'consultation_mode' not in st.session_state:
    st.session_state.consultation_mode = False
if 'messages' not in st.session_state:
    st.session_state.messages = []
if 'analysis_data' not in st.session_state:
    st.session_state.analysis_data = None
if 'final_report_generated' not in st.session_state:
    st.session_state.final_report_generated = False
if 'consultation_chain' not in st.session_state:
    st.session_state.consultation_chain = None
if 'consultation_memory' not in st.session_state:
    st.session_state.consultation_memory = None
if 'merged_data' not in st.session_state:
    st.session_state.merged_data = None
if 'merged_md' not in st.session_state:
    st.session_state.merged_md = None
if 'mcp_search_initialized' not in st.session_state:
    st.session_state.mcp_search_initialized = False
if 'mcp_search_progress' not in st.session_state:
    st.session_state.mcp_search_progress = {
        "total": 0,
        "processed": 0,
        "success": 0,
        "failed": 0
    }

def generate_marketplace_summary_with_gemini(marketplace_data):
    """OpenAIë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒê¶Œ ë¶„ì„ ìš”ì•½ ìƒì„±"""
    try:
        # OpenAI í´ë¼ì´ì–¸íŠ¸ í™•ì¸
        if not OPENAI_AVAILABLE or not openai_client:
            return None
        
        # ìƒê¶Œ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        data_text = json.dumps(marketplace_data, ensure_ascii=False, indent=2)
        
        # OpenAI í”„ë¡¬í”„íŠ¸
        prompt = f"""
ë‹¤ìŒì€ ìƒê¶Œ ë¶„ì„ ë°ì´í„°ì…ë‹ˆë‹¤. ì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ìƒì„¸í•œ ìƒê¶Œ ë¶„ì„ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

ìƒê¶Œ ë°ì´í„°:
{data_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„ ìš”ì•½ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ¬ ìƒê¶Œ ë¶„ì„ ìš”ì•½

### ğŸ“ ìƒê¶Œ ê°œìš”
- ìƒê¶Œëª…: [ìƒê¶Œëª…]
- ìƒê¶Œ ìœ í˜•: [ìœ í˜•]
- ë¶„ì„ ë©´ì : [ë©´ì ]
- ì í¬ìˆ˜: [ì í¬ìˆ˜]

### ğŸ“Š ì£¼ìš” ì§€í‘œ
- ë§¤ì¶œ í˜„í™©: [í˜„ì¬ ë§¤ì¶œì•¡]
- ì„±ì¥ë¥ : [ì „ë…„ ëŒ€ë¹„]
- ìƒê¶Œ í™œì„±ë„: [ì í¬ ì¦ê°]

### ğŸ’¡ í•µì‹¬ ì¸ì‚¬ì´íŠ¸
1. ìƒê¶Œ ê°•ì : [ê°•ì  ë¶„ì„]
2. ìƒê¶Œ ì•½ì : [ì•½ì  ë¶„ì„]
3. ê¸°íšŒ ìš”ì†Œ: [ê¸°íšŒ ë¶„ì„]
4. ìœ„í—˜ ìš”ì†Œ: [ìœ„í—˜ ë¶„ì„]

### ğŸ¯ ì¶”ì²œ ì—…ì¢…
- ì í•©í•œ ì—…ì¢…: [ì—…ì¢… ì¶”ì²œ]
- ì„±ê³µ ìš”ì¸: [ì„±ê³µ ì¡°ê±´]
- ì£¼ì˜ì‚¬í•­: [ì£¼ì˜ì ]

### ğŸ“ˆ ì „ë§ ë° ì œì–¸
- ìƒê¶Œ ì „ë§: [ë¯¸ë˜ ì „ë§]
- ì°½ì—… ì œì–¸: [ì°½ì—… ê°€ì´ë“œ]
- ë§ˆì¼€íŒ… ì „ëµ: [ë§ˆì¼€íŒ… ë°©í–¥]

ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ê´€ì ì—ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
        
        # OpenAI SDKë¡œ Gemini 2.5 Flash í˜¸ì¶œ
        response = openai_client.chat.completions.create(
            model="gemini-2.5-flash",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ìƒê¶Œ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )
        
        if response and response.choices:
            return response.choices[0].message.content
        else:
            return None
            
    except Exception as e:
        print(f"OpenAI ìƒê¶Œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return None

def generate_final_report_with_gemini(analysis_data):
    """OpenAIë¥¼ ì‚¬ìš©í•´ì„œ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±"""
    if not OPENAI_AVAILABLE or not openai_client:
        return None, None
    
    try:
        # ë¶„ì„ ë°ì´í„°ë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜
        analysis_json = json.dumps(analysis_data, ensure_ascii=False, indent=2)
        
        prompt = f"""
ë‹¤ìŒì€ ë§¤ì¥ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ë¶„ì„ ë°ì´í„°:
{analysis_json}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:

# ë§¤ì¥ ë¶„ì„ ìµœì¢… ë¦¬í¬íŠ¸

## 1. ì‹¤í–‰ ìš”ì•½
- í•µì‹¬ ì¸ì‚¬ì´íŠ¸ 3ê°€ì§€
- ì£¼ìš” ë¬¸ì œì  2ê°€ì§€  
- ì¶”ì²œ ì „ëµ 3ê°€ì§€

## 2. ë§¤ì¥ í˜„í™© ë¶„ì„
- ë§¤ì¥ ê¸°ë³¸ ì •ë³´
- ë§¤ì¶œ ë° ê³ ê° ë¶„ì„
- ìƒê¶Œ í™˜ê²½ ë¶„ì„

## 3. ë§ˆì¼€íŒ… ì „ëµ
- íƒ€ê²Ÿ ê³ ê° ë¶„ì„
- ì¶”ì²œ ë§ˆì¼€íŒ… ì „ëµ
- ì‹¤í–‰ ê³„íš

## 4. ê°œì„  ë°©ì•ˆ
- ì¦‰ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„ ì‚¬í•­
- ì¤‘ì¥ê¸° ë°œì „ ë°©í–¥
- ìœ„í—˜ ìš”ì†Œ ë° ëŒ€ì‘ ë°©ì•ˆ

## 5. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­
- ì¢…í•© í‰ê°€
- ìµœìš°ì„  ì‹¤í–‰ ê³¼ì œ
- ì„±ê³µ ì§€í‘œ ì„¤ì •

JSON í˜•ì‹ìœ¼ë¡œë„ ìš”ì•½í•´ì£¼ì„¸ìš”:
{{
  "executive_summary": {{
    "key_insights": ["ì¸ì‚¬ì´íŠ¸1", "ì¸ì‚¬ì´íŠ¸2", "ì¸ì‚¬ì´íŠ¸3"],
    "main_issues": ["ë¬¸ì œ1", "ë¬¸ì œ2"],
    "recommended_strategies": ["ì „ëµ1", "ì „ëµ2", "ì „ëµ3"]
  }},
  "store_analysis": {{
    "performance_score": 85,
    "strengths": ["ê°•ì 1", "ê°•ì 2"],
    "weaknesses": ["ì•½ì 1", "ì•½ì 2"]
  }},
  "marketing_recommendations": {{
    "target_customers": "íƒ€ê²Ÿ ê³ ê° ì„¤ëª…",
    "primary_strategy": "ì£¼ìš” ì „ëµ",
    "implementation_priority": "ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ"
  }},
  "action_plan": {{
    "immediate_actions": ["ì¦‰ì‹œ ì‹¤í–‰1", "ì¦‰ì‹œ ì‹¤í–‰2"],
    "short_term_goals": ["ë‹¨ê¸° ëª©í‘œ1", "ë‹¨ê¸° ëª©í‘œ2"],
    "long_term_vision": "ì¥ê¸° ë¹„ì „"
  }}
}}
"""
        
        response = openai_client.chat.completions.create(
            model="gemini-2.5-flash",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµê³¼ ëª…í™•í•œ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=3000
        )
        
        # MDì™€ JSON ë¶„ë¦¬
        md_content = response.choices[0].message.content
        json_content = None
        
        # JSON ë¶€ë¶„ ì¶”ì¶œ
        if "```json" in md_content:
            json_start = md_content.find("```json") + 7
            json_end = md_content.find("```", json_start)
            if json_end > json_start:
                json_str = md_content[json_start:json_end].strip()
                try:
                    json_content = json.loads(json_str)
                except:
                    json_content = None
        
        return md_content, json_content
        
    except Exception as e:
        print(f"OpenAI ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return None, None

def convert_absolute_to_relative_path(absolute_path: str) -> str:
    """ì ˆëŒ€ ê²½ë¡œë¥¼ ìƒëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
    if not absolute_path:
        return absolute_path
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
    project_root = Path(__file__).parent.parent.parent
    
    try:
        abs_path = Path(absolute_path)
        if abs_path.is_absolute():
            # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ìƒëŒ€ ê²½ë¡œ ê³„ì‚°
            relative_path = abs_path.relative_to(project_root)
            return str(relative_path).replace('\\', '/')  # Windows ê²½ë¡œ êµ¬ë¶„ì í†µì¼
        else:
            return absolute_path
    except ValueError:
        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë°–ì˜ ê²½ë¡œì¸ ê²½ìš° ì›ë³¸ ë°˜í™˜
        return absolute_path


def load_analysis_data_from_output(store_code):
    """output í´ë”ì—ì„œ ì‹¤ì œ ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œ"""
    try:
        output_dir = Path(__file__).parent.parent / "output"
        print(f"[DEBUG] output_dir: {output_dir}")
        print(f"[DEBUG] output_dir exists: {output_dir.exists()}")
        
        # ê°€ì¥ ìµœì‹  ë¶„ì„ í´ë” ì°¾ê¸° (analysis_{store_code}_{timestamp} í˜•ì‹)
        analysis_dirs = list(output_dir.glob(f"analysis_{store_code}_*"))
        print(f"[DEBUG] ì°¾ì€ ë¶„ì„ í´ë”: {analysis_dirs}")
        
        if not analysis_dirs:
            print(f"[ERROR] {store_code}ì— ëŒ€í•œ ë¶„ì„ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return None
        
        # ê°€ì¥ ìµœì‹  í´ë” ì„ íƒ
        latest_dir = max(analysis_dirs, key=os.path.getctime)
        print(f"[INFO] ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ë¡œë“œ: {latest_dir.name}")
        
        # ê° ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        data = {
            "store_code": store_code,
            "analysis_dir": str(latest_dir),
            "is_existing_analysis": True,  # ê¸°ì¡´ ë¶„ì„ì„ì„ í‘œì‹œ
            "timestamp": latest_dir.name.split("_")[-1]
        }
        
        # 1. í†µí•© ë¶„ì„ ê²°ê³¼ (analysis_result.json)
        analysis_file = latest_dir / "analysis_result.json"
        if analysis_file.exists():
            try:
                with open(analysis_file, 'r', encoding='utf-8') as f:
                    data["analysis_result"] = json.load(f)
                print(f"[OK] analysis_result.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] analysis_result.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] analysis_result.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 2. ì¢…í•© ë¶„ì„ ê²°ê³¼ (comprehensive_analysis.json) - ì„ íƒì 
        comprehensive_file = latest_dir / "comprehensive_analysis.json"
        if comprehensive_file.exists():
            try:
                with open(comprehensive_file, 'r', encoding='utf-8') as f:
                    data["comprehensive_analysis"] = json.load(f)
                print(f"[OK] comprehensive_analysis.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] comprehensive_analysis.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] comprehensive_analysis.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 3. Store ë¶„ì„ ê²°ê³¼ - ì„ íƒì 
        store_file = latest_dir / "store_analysis_report.json"
        if store_file.exists():
            try:
                with open(store_file, 'r', encoding='utf-8') as f:
                    data["store_analysis"] = json.load(f)
                print(f"[OK] store_analysis_report.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] store_analysis_report.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] store_analysis_report.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 4. Marketing ë¶„ì„ ê²°ê³¼ - ì„ íƒì 
        marketing_file = latest_dir / "marketing_strategy.json"
        if marketing_file.exists():
            try:
                with open(marketing_file, 'r', encoding='utf-8') as f:
                    data["marketing_analysis"] = json.load(f)
                print(f"[OK] marketing_strategy.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] marketing_strategy.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] marketing_strategy.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 5. Marketplace ë¶„ì„ ê²°ê³¼
        marketplace_file = latest_dir / "marketplace" / "marketplace_data.json"
        if marketplace_file.exists():
            try:
                with open(marketplace_file, 'r', encoding='utf-8') as f:
                    data["marketplace_analysis"] = json.load(f)
                print(f"[OK] marketplace_data.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] marketplace_data.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] marketplace_data.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 6. Panorama ë¶„ì„ ê²°ê³¼
        panorama_file = latest_dir / "panorama" / "analysis_result.json"
        if panorama_file.exists():
            try:
                with open(panorama_file, 'r', encoding='utf-8') as f:
                    data["panorama_analysis"] = json.load(f)
                print(f"[OK] panorama analysis_result.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] panorama analysis_result.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] panorama analysis_result.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 7. Mobility ë¶„ì„ ê²°ê³¼ - ì„ íƒì 
        mobility_file = latest_dir / "mobility_charts" / "mobility_data.json"
        if mobility_file.exists():
            try:
                with open(mobility_file, 'r', encoding='utf-8') as f:
                    data["mobility_analysis"] = json.load(f)
                print(f"[OK] mobility_data.json ë¡œë“œ ì„±ê³µ")
            except PermissionError:
                print(f"[WARN] mobility_data.json ê¶Œí•œ ì˜¤ë¥˜ - ê±´ë„ˆëœ€")
            except Exception as e:
                print(f"[WARN] mobility_data.json ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # 8. ì‹œê°í™” íŒŒì¼ë“¤ ë¡œë“œ
        data["visualizations"] = load_visualization_files(latest_dir)
        
        # ìµœì†Œí•œ í•˜ë‚˜ì˜ ë¶„ì„ ë°ì´í„°ë¼ë„ ìˆìœ¼ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
        loaded_sections = [k for k, v in data.items() if k not in ["store_code", "analysis_dir", "is_existing_analysis", "timestamp"] and v is not None]
        
        if loaded_sections:
            print(f"[OK] ë¶„ì„ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(loaded_sections)}ê°œ ì„¹ì…˜ ({', '.join(loaded_sections)})")
            return data
        else:
            print(f"[ERROR] ë¡œë“œëœ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None
        
    except Exception as e:
        print(f"[ERROR] ë¶„ì„ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def load_visualization_files(analysis_dir):
    """ì‹œê°í™” íŒŒì¼ë“¤ì„ ë¡œë“œ"""
    viz_data = {
        "store_charts": [],
        "mobility_charts": [],
        "panorama_images": [],
        "spatial_files": []
    }
    
    try:
        # Store ì°¨íŠ¸ë“¤
        store_charts_dir = analysis_dir / "store_charts"
        if store_charts_dir.exists():
            for chart_file in store_charts_dir.glob("*.png"):
                viz_data["store_charts"].append({
                    "name": chart_file.stem,
                    "path": str(chart_file),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                    "absolute_path": str(chart_file),
                    "type": "store_chart"
                })
        
        # Mobility ì°¨íŠ¸ë“¤
        mobility_charts_dir = analysis_dir / "mobility_charts"
        if mobility_charts_dir.exists():
            for chart_file in mobility_charts_dir.glob("*.png"):
                viz_data["mobility_charts"].append({
                    "name": chart_file.stem,
                    "path": str(chart_file),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                    "absolute_path": str(chart_file),
                    "type": "mobility_chart"
                })
        
        # Panorama ì´ë¯¸ì§€ë“¤
        panorama_images_dir = analysis_dir / "panorama" / "images"
        if panorama_images_dir.exists():
            for img_file in panorama_images_dir.glob("*.jpg"):
                viz_data["panorama_images"].append({
                    "name": img_file.stem,
                    "path": str(img_file),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                    "absolute_path": str(img_file),
                    "type": "panorama_image"
                })
        
        # Spatial ì‹œê°í™” íŒŒì¼ë“¤
        spatial_map = analysis_dir / "spatial_map.html"
        spatial_chart = analysis_dir / "spatial_analysis.png"
        
        if spatial_map.exists():
            viz_data["spatial_files"].append({
                "name": "ê³µê°„ ë¶„ì„ ì§€ë„",
                "path": str(spatial_map),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                "absolute_path": str(spatial_map),
                "type": "spatial_map"
            })
        
        if spatial_chart.exists():
            viz_data["spatial_files"].append({
                "name": "ê³µê°„ ë¶„ì„ ì°¨íŠ¸",
                "path": str(spatial_chart),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                "absolute_path": str(spatial_chart),
                "type": "spatial_chart"
            })
        
        # Panorama ì§€ë„
        panorama_map = analysis_dir / "panorama" / "analysis_map.html"
        if panorama_map.exists():
            viz_data["spatial_files"].append({
                "name": "íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì§€ë„",
                "path": str(panorama_map),  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                "absolute_path": str(panorama_map),
                "type": "panorama_map"
            })
        
        print(f"[OK] ì‹œê°í™” íŒŒì¼ ë¡œë“œ: Store({len(viz_data['store_charts'])}), Mobility({len(viz_data['mobility_charts'])}), Panorama({len(viz_data['panorama_images'])}), Spatial({len(viz_data['spatial_files'])})")
        
    except Exception as e:
        print(f"[ERROR] ì‹œê°í™” íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    return viz_data

def load_analysis_files_from_actual_locations(store_code):
    """ì‹¤ì œ ì €ì¥ëœ ë¶„ì„ íŒŒì¼ë“¤ì„ ë¡œë“œ (legacy í•¨ìˆ˜ - í˜¸í™˜ì„± ìœ ì§€)"""
    return load_analysis_data_from_output(store_code)

# ê° íƒ­ë³„ í‘œì‹œ í•¨ìˆ˜ë“¤
def display_basic_info(analysis_data):
    """ê¸°ë³¸ ì •ë³´ í‘œì‹œ"""
    st.markdown("### ğŸ“Š ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    
    # Store ë¶„ì„ì—ì„œ ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
    store_data = analysis_data.get("store_analysis", {})
    if store_data and "store_overview" in store_data:
        store_info = store_data["store_overview"]
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ë§¤ì¥ëª…", store_info.get("name", "N/A"))
        with col2:
            st.metric("ì—…ì¢…", store_info.get("industry", "N/A"))
        with col3:
            st.metric("ìƒê¶Œ", store_info.get("commercial_area", "N/A"))
    
    # Spatial ë¶„ì„ì—ì„œ ì£¼ì†Œ ì •ë³´
    comprehensive = analysis_data.get("comprehensive_analysis", {})
    if comprehensive and "spatial_analysis" in comprehensive:
        spatial = comprehensive["spatial_analysis"]
        st.write(f"**ì£¼ì†Œ:** {spatial.get('address', 'N/A')}")
        st.write(f"**í–‰ì •ë™:** {spatial.get('administrative_dong', 'N/A')}")

def display_final_report_button(store_code, analysis_data):
    """ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ í‘œì‹œ"""
    if not st.session_state.final_report_generated:
        if st.button("ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (Gemini)", type="primary"):
            with st.spinner("Geminië¡œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„± ì¤‘..."):
                md_content, json_content = generate_final_report_with_gemini(analysis_data)
                if md_content:
                    report_dir = save_final_reports(store_code, md_content, json_content)
                    if report_dir:
                        st.success(f"ìµœì¢… ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_dir}")
                        st.session_state.final_report_generated = True
                        st.rerun()
                else:
                    st.error("ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    else:
        st.info("âœ… ìµœì¢… ë¦¬í¬íŠ¸ê°€ ì´ë¯¸ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")


def generate_comprehensive_analysis_with_gemini(analysis_data):
    """OpenAI SDK(Gemini 2.5 Flash)ë¥¼ ì‚¬ìš©í•´ì„œ ì „ì²´ ë¶„ì„ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
    try:
        if not OPENAI_AVAILABLE or not openai_client:
            return None
        
        # ë¶„ì„ ë°ì´í„° ìš”ì•½
        store_data = analysis_data.get("store_analysis", {})
        marketing_data = analysis_data.get("marketing_strategy", {})
        panorama_data = analysis_data.get("panorama_analysis", {})
        marketplace_data = analysis_data.get("marketplace_analysis", {})
        mobility_data = analysis_data.get("mobility_analysis", {})
        
        # ë°ì´í„° ìš”ì•½ ìƒì„±
        summary_text = f"""
## ë§¤ì¥ ë¶„ì„ ë°ì´í„° ìš”ì•½

### ğŸª ë§¤ì¥ ê¸°ë³¸ ì •ë³´
- ë§¤ì¥ëª…: {store_data.get('store_overview', {}).get('name', 'N/A')}
- ì—…ì¢…: {store_data.get('store_overview', {}).get('industry', 'N/A')}
- ìƒê¶Œ: {store_data.get('store_overview', {}).get('commercial_area', 'N/A')}
- ìš´ì˜ ê°œì›”: {store_data.get('store_overview', {}).get('operating_months', 'N/A')}ê°œì›”

### ğŸ“ˆ ë§¤ì¶œ ë¶„ì„
- ë§¤ì¶œì•¡ ì¶”ì„¸: {store_data.get('sales_analysis', {}).get('trends', {}).get('sales_amount', {}).get('trend', 'N/A')}
- ë§¤ì¶œê±´ìˆ˜ ì¶”ì„¸: {store_data.get('sales_analysis', {}).get('trends', {}).get('sales_count', {}).get('trend', 'N/A')}
- ê³ ìœ ê³ ê° ì¶”ì„¸: {store_data.get('sales_analysis', {}).get('trends', {}).get('unique_customers', {}).get('trend', 'N/A')}
- í‰ê·  ê±°ë˜ì•¡ ì¶”ì„¸: {store_data.get('sales_analysis', {}).get('trends', {}).get('avg_transaction', {}).get('trend', 'N/A')}

### ğŸ‘¥ ê³ ê° ë¶„ì„
- ì„±ë³„ ë¶„í¬: ë‚¨ì„± {store_data.get('customer_analysis', {}).get('gender_distribution', {}).get('male_ratio', 0):.1f}% / ì—¬ì„± {store_data.get('customer_analysis', {}).get('gender_distribution', {}).get('female_ratio', 0):.1f}%
- ì£¼ìš” ì—°ë ¹ëŒ€: {max(store_data.get('customer_analysis', {}).get('age_group_distribution', {}), key=store_data.get('customer_analysis', {}).get('age_group_distribution', {}).get) if store_data.get('customer_analysis', {}).get('age_group_distribution') else 'N/A'}

### ğŸ¯ ë§ˆì¼€íŒ… ì „ëµ
- ì „ëµ ìˆ˜: {len(marketing_data.get('marketing_strategies', []))}ê°œ
- í˜ë¥´ì†Œë‚˜ ìœ í˜•: {marketing_data.get('persona_analysis', {}).get('persona_type', 'N/A')}

### ğŸŒ† ì§€ì—­ í™˜ê²½ ë¶„ì„
- ì§€ì—­ ìœ í˜•: {panorama_data.get('area_summary', {}).get('dominant_zone_type', 'N/A')}
- ìƒê¶Œ ë¶„ìœ„ê¸°: {panorama_data.get('comprehensive_scores', {}).get('commercial_atmosphere', 'N/A')}/10

### ğŸ¬ ìƒê¶Œ ë¶„ì„
- ìƒê¶Œëª…: {marketplace_data.get('ìƒê¶Œëª…', 'N/A')}
- ì í¬ìˆ˜: {marketplace_data.get('ìƒê¶Œ_ì í¬ìˆ˜', 'N/A')}ê°œ
- ë§¤ì¶œì•¡: {marketplace_data.get('ìƒê¶Œ_ë§¤ì¶œì•¡', 'N/A')}ë§Œì›
        """
        
        prompt = f"""ë‹¤ìŒ ë§¤ì¥ ë¶„ì„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¢…í•©ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ì™€ ì „ëµì  ì œì•ˆì„ ì‘ì„±í•´ì£¼ì„¸ìš”.

{summary_text}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

## ğŸ¯ ì¢…í•© ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ ë¦¬í¬íŠ¸

### ğŸ“Š í•µì‹¬ ì¸ì‚¬ì´íŠ¸
- ë§¤ì¥ì˜ ì£¼ìš” ê°•ì ê³¼ ì•½ì 
- ì‹œì¥ì—ì„œì˜ ìœ„ì¹˜ì™€ ê²½ìŸë ¥
- ì„±ì¥ ì ì¬ë ¥ í‰ê°€

### ğŸ” ìƒì„¸ ë¶„ì„
- ë§¤ì¶œ ë™í–¥ ë¶„ì„ ë° ì „ë§
- ê³ ê°ì¸µ íŠ¹ì„± ë° íƒ€ê²ŸíŒ… ì „ëµ
- ìƒê¶Œ í™˜ê²½ê³¼ì˜ ì í•©ì„±
- ë§ˆì¼€íŒ… ì „ëµì˜ íš¨ê³¼ì„±

### âš ï¸ ìœ„í—˜ ìš”ì†Œ ë° ì£¼ì˜ì‚¬í•­
- ë§¤ì¥ ìš´ì˜ìƒ ì£¼ì˜í•´ì•¼ í•  ì 
- ì‹œì¥ ë³€í™”ì— ë”°ë¥¸ ë¦¬ìŠ¤í¬
- ê²½ìŸ í™˜ê²½ ë³€í™” ëŒ€ì‘ ë°©ì•ˆ

### ğŸš€ ì„±ì¥ ì „ëµ ì œì•ˆ
- ë§¤ì¶œ ì¦ëŒ€ë¥¼ ìœ„í•œ êµ¬ì²´ì  ë°©ì•ˆ
- ê³ ê° ìœ ì¹˜ ë° ë¦¬í…ì…˜ ì „ëµ
- ìƒê¶Œ íŠ¹ì„±ì„ í™œìš©í•œ ì°¨ë³„í™” ë°©ì•ˆ
- ë§ˆì¼€íŒ… ì „ëµ ê°œì„  ì œì•ˆ

### ğŸ’¡ ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ í”Œëœ
- ë‹¨ê¸° (1-3ê°œì›”) ì‹¤í–‰ ê³„íš
- ì¤‘ê¸° (3-6ê°œì›”) ì‹¤í–‰ ê³„íš
- ì¥ê¸° (6-12ê°œì›”) ì‹¤í–‰ ê³„íš

ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ë¶„ì„ì„ ì œê³µí•´ì£¼ì„¸ìš”."""
        
        response = openai_client.chat.completions.create(
            model="gemini-2.5-flash",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë¶„ì„ê°€ì´ì ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ì „ëµì  ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=3000
        )
        
        return response.choices[0].message.content.strip()
        
    except Exception as e:
        print(f"[ERROR] OpenAI(Gemini) ì¢…í•© ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}")
        return None


def display_store_overview(analysis_data):
    """ë§¤ì¥ ê°œìš” íƒ­ - ê°„ë‹¨í•˜ê³  í•µì‹¬ì ì¸ ê°œìš”"""
    st.markdown("### ğŸª ë§¤ì¥ ê°œìš”")
    
    store_data = analysis_data.get("store_analysis", {})
    if not store_data:
        st.info("ë§¤ì¥ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    store_info = store_data.get("store_overview", {})
    sales_data = store_data.get("sales_analysis", {})
    customer_data = store_data.get("customer_analysis", {})
    marketing = analysis_data.get("marketing_strategy", {})
    marketplace = analysis_data.get("marketplace_analysis", {})
    
    # í•µì‹¬ ì •ë³´ë§Œ ê°„ë‹¨í•˜ê²Œ í‘œì‹œ
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("#### ğŸª ê¸°ë³¸ ì •ë³´")
        st.write(f"**ë§¤ì¥ëª…:** {store_info.get('name', 'N/A')}")
        st.write(f"**ì—…ì¢…:** {store_info.get('industry', 'N/A')}")
        st.write(f"**ìƒê¶Œ:** {store_info.get('commercial_area', 'N/A')}")
        st.write(f"**ìš´ì˜ê¸°ê°„:** {store_info.get('operating_months', 0):.1f}ê°œì›”")
    
    with col2:
        st.markdown("#### ğŸ“ˆ í•µì‹¬ ì§€í‘œ")
        # ë§¤ì¶œ ì¶”ì„¸
        sales_trend = sales_data.get("trends", {}).get("sales_amount", {}).get("trend", "N/A")
        trend_icon = "ğŸ“ˆ" if "ìƒìŠ¹" in sales_trend else "ğŸ“‰" if "í•˜ë½" in sales_trend else "â¡ï¸"
        st.write(f"**ë§¤ì¶œ ì¶”ì„¸:** {trend_icon} {sales_trend}")
        
        # ê³ ê° ì¶”ì„¸
        customer_trend = sales_data.get("trends", {}).get("unique_customers", {}).get("trend", "N/A")
        trend_icon = "ğŸ“ˆ" if "ìƒìŠ¹" in customer_trend else "ğŸ“‰" if "í•˜ë½" in customer_trend else "â¡ï¸"
        st.write(f"**ê³ ê° ì¶”ì„¸:** {trend_icon} {customer_trend}")
        
        # ìˆœìœ„
        industry_rank = sales_data.get("rankings", {}).get("industry_rank", {}).get("average", "N/A")
        st.write(f"**ë™ì¢…ì—…ê³„ ìˆœìœ„:** {industry_rank}ìœ„")
        
        # í’ˆì§ˆ ì ìˆ˜
        quality_score = store_data.get("report_metadata", {}).get("quality_score", 0)
        st.write(f"**ë¶„ì„ í’ˆì§ˆ:** {quality_score:.1%}")
    
    with col3:
        st.markdown("#### ğŸ‘¥ ê³ ê° íŠ¹ì„±")
        # ì„±ë³„
        male_ratio = customer_data.get("gender_distribution", {}).get("male_ratio", 0)
        female_ratio = customer_data.get("gender_distribution", {}).get("female_ratio", 0)
        st.write(f"**ì„±ë³„:** ë‚¨ì„± {male_ratio:.1f}% / ì—¬ì„± {female_ratio:.1f}%")
        
        # ì£¼ìš” ì—°ë ¹ëŒ€
        age_dist = customer_data.get("age_group_distribution", {})
        main_age = max(age_dist, key=age_dist.get) if age_dist else "N/A"
        main_ratio = age_dist.get(main_age, 0) if age_dist else 0
        st.write(f"**ì£¼ìš” ì—°ë ¹ëŒ€:** {main_age} ({main_ratio:.1f}%)")
        
        # ê³ ê° ìœ í˜•
        customer_dist = customer_data.get("customer_type_analysis", {}).get("customer_distribution", {})
        floating_ratio = customer_dist.get("floating", 0)
        st.write(f"**ê³ ê° ìœ í˜•:** ìœ ë™ {floating_ratio:.1f}%")
        
        # ë§ˆì¼€íŒ… ì „ëµ ìˆ˜
        strategy_count = len(marketing.get("marketing_strategies", []))
        st.write(f"**ë§ˆì¼€íŒ… ì „ëµ:** {strategy_count}ê°œ")
    
    # ìƒê¶Œ ì •ë³´ (ê°„ë‹¨í•˜ê²Œ)
    if marketplace:
        st.markdown("#### ğŸ˜ï¸ ìƒê¶Œ ì •ë³´")
        col1, col2 = st.columns(2)
        with col1:
            st.write(f"**ìƒê¶Œëª…:** {marketplace.get('ìƒê¶Œëª…', 'N/A')}")
        with col2:
            store_count = marketplace.get("ìƒê¶Œ_ì í¬ìˆ˜", "N/A")
            st.write(f"**ì í¬ìˆ˜:** {store_count}ê°œ")
    
    # MCP êµ¬ê¸€ë§µ ê²€ìƒ‰ ê²°ê³¼ (ìˆìœ¼ë©´ í‘œì‹œ)
    mcp_result = analysis_data.get("mcp_search_result", {})
    if mcp_result.get("success") and mcp_result.get("file"):
        st.markdown("---")
        st.markdown("#### ğŸ—ºï¸ Google Maps ì •ë³´")
        
        # txt íŒŒì¼ ì½ê¸°
        try:
            mcp_file_path = Path(mcp_result["file"])
            if mcp_file_path.exists():
                with open(mcp_file_path, 'r', encoding='utf-8') as f:
                    mcp_content = f.read()
                
                # expanderë¡œ ì¶•ì•½í•´ì„œ í‘œì‹œ
                with st.expander("ğŸ“ Google Maps ê²€ìƒ‰ ê²°ê³¼ ë³´ê¸°", expanded=False):
                    st.text(mcp_content)
        except Exception as e:
            st.warning(f"MCP ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # AI ì¢…í•© ë¶„ì„ ë²„íŠ¼
    st.markdown("---")
    st.markdown("#### ğŸ¤– AI ì¢…í•© ë¶„ì„")
    if st.button("ğŸ” ì¢…í•© ë¶„ì„ ìƒì„±", type="primary", help="ëª¨ë“  ë¶„ì„ ë°ì´í„°ë¥¼ ì¢…í•©í•˜ì—¬ AIê°€ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤"):
        with st.spinner("AIê°€ ì¢…í•© ë¶„ì„ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤..."):
            comprehensive_analysis = generate_comprehensive_analysis_with_gemini(analysis_data)
            if comprehensive_analysis:
                st.markdown("##### ğŸ“‹ AI ì¢…í•© ë¶„ì„ ê²°ê³¼")
                st.write(comprehensive_analysis)
            else:
                st.error("ì¢…í•© ë¶„ì„ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

def display_customer_analysis(analysis_data):
    """ê³ ê° ë¶„ì„ íƒ­ + ì‹œê°í™” - JSON ë°ì´í„° ê¸°ë°˜ ì²´ê³„ì  ë¶„ì„"""
    st.markdown("### ğŸ‘¥ ê³ ê° ë¶„ì„")
    
    store_data = analysis_data.get("store_analysis", {})
    if not store_data:
        st.info("ë§¤ì¥ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    customer_data = store_data.get("customer_analysis", {})
    if not customer_data:
        st.info("ê³ ê° ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 1. ì„±ë³„ ë¶„í¬ (ìƒì„¸ ë¶„ì„)
    gender_data = customer_data.get("gender_distribution", {})
    if gender_data:
        st.markdown("#### ğŸ“Š ì„±ë³„ ë¶„í¬")
        col1, col2, col3 = st.columns([1, 1, 2])
        
        with col1:
            male_ratio = gender_data.get("male_ratio", 0)
            st.metric("ë‚¨ì„±", f"{male_ratio:.1f}%", help="ì „ì²´ ê³ ê° ì¤‘ ë‚¨ì„± ë¹„ìœ¨")
        
        with col2:
            female_ratio = gender_data.get("female_ratio", 0)
            st.metric("ì—¬ì„±", f"{female_ratio:.1f}%", help="ì „ì²´ ê³ ê° ì¤‘ ì—¬ì„± ë¹„ìœ¨")
        
        with col3:
            # ì„±ë³„ ë¹„ìœ¨ ì°¨ì´ ë¶„ì„
            gender_diff = abs(male_ratio - female_ratio)
            if gender_diff > 30:
                st.warning(f"ì„±ë³„ í¸ì¤‘ì´ ì‹¬í•©ë‹ˆë‹¤ (ì°¨ì´: {gender_diff:.1f}%)")
            elif gender_diff > 15:
                st.info(f"ì„±ë³„ í¸ì¤‘ì´ ìˆìŠµë‹ˆë‹¤ (ì°¨ì´: {gender_diff:.1f}%)")
            else:
                st.success("ì„±ë³„ ë¶„í¬ê°€ ê· í˜•ì ì…ë‹ˆë‹¤")
    
    # 2. ì—°ë ¹ëŒ€ë³„ ë¶„í¬ (ìƒì„¸ ë¶„ì„)
    age_data = customer_data.get("age_group_distribution", {})
    if age_data:
        st.markdown("#### ğŸ‚ ì—°ë ¹ëŒ€ë³„ ê³ ê° ë¶„í¬")
        
        # ì—°ë ¹ëŒ€ë³„ ì¹´ë“œ í‘œì‹œ
        age_cols = st.columns(5)
        age_groups = ["20ëŒ€ ì´í•˜", "30ëŒ€", "40ëŒ€", "50ëŒ€", "60ëŒ€ ì´ìƒ"]
        
        for i, age_group in enumerate(age_groups):
            with age_cols[i]:
                ratio = age_data.get(age_group, 0)
                st.metric(age_group, f"{ratio:.1f}%")
        
        # ì£¼ìš” ì—°ë ¹ëŒ€ ë¶„ì„
        max_age = max(age_data.items(), key=lambda x: x[1])
        st.info(f"**ì£¼ìš” ê³ ê°ì¸µ:** {max_age[0]} ({max_age[1]:.1f}%)")
    
    # 3. ìƒì„¸ ê³ ê° ë¹„ìœ¨ (ì„±ë³„+ì—°ë ¹ëŒ€ ì¡°í•©)
    detailed_ratios = customer_data.get("detailed_customer_ratios", {})
    if detailed_ratios:
        st.markdown("#### ğŸ” ìƒì„¸ ê³ ê° ë¹„ìœ¨ (ì„±ë³„+ì—°ë ¹ëŒ€)")
        
        # ìƒìœ„ 5ê°œ ê³ ê° ì„¸ê·¸ë¨¼íŠ¸ í‘œì‹œ
        top_segments = sorted(detailed_ratios.items(), key=lambda x: x[1], reverse=True)[:5]
        
        for i, (segment, ratio) in enumerate(top_segments, 1):
            col1, col2 = st.columns([1, 4])
            with col1:
                st.write(f"**{i}ìœ„**")
            with col2:
                st.write(f"{segment}: {ratio:.1f}%")
                # ì§„í–‰ë¥  ë°”
                st.progress(ratio / 100)
    
    # 4. ê³ ê° ìœ í˜• ë¶„ì„ (ìˆ˜ì •ëœ í™”ì‚´í‘œ ë°©í–¥)
    customer_type = customer_data.get("customer_type_analysis", {})
    if customer_type:
        st.markdown("#### ğŸ”„ ê³ ê° ìœ í˜• ë¶„ì„")
        
        new_customers = customer_type.get("new_customers", {})
        returning_customers = customer_type.get("returning_customers", {})
        
        col1, col2 = st.columns(2)
        
        with col1:
            new_ratio = new_customers.get("ratio", 0)
            new_trend = new_customers.get("trend", "N/A")
            
            # í™”ì‚´í‘œ ë°©í–¥ ìˆ˜ì •
            if "ìƒìŠ¹" in new_trend or "ì¦ê°€" in new_trend:
                delta_icon = "ğŸ“ˆ"
            elif "í•˜ë½" in new_trend or "ê°ì†Œ" in new_trend:
                delta_icon = "ğŸ“‰"
            else:
                delta_icon = "â¡ï¸"
            
            st.metric("ì‹ ê·œ ê³ ê°", f"{new_ratio:.1f}%", delta=f"{delta_icon} {new_trend}")
        
        with col2:
            return_ratio = returning_customers.get("ratio", 0)
            return_trend = returning_customers.get("trend", "N/A")
            
            # í™”ì‚´í‘œ ë°©í–¥ ìˆ˜ì •
            if "ìƒìŠ¹" in return_trend or "ì¦ê°€" in return_trend:
                delta_icon = "ğŸ“ˆ"
            elif "í•˜ë½" in return_trend or "ê°ì†Œ" in return_trend:
                delta_icon = "ğŸ“‰"
            else:
                delta_icon = "â¡ï¸"
            
            st.metric("ì¬ë°©ë¬¸ ê³ ê°", f"{return_ratio:.1f}%", delta=f"{delta_icon} {return_trend}")
        
        # ê³ ê° ë¶„í¬ (ìƒì„¸ ë¶„ì„)
        distribution = customer_type.get("customer_distribution", {})
        if distribution:
            st.markdown("#### ğŸ  ê³ ê° ë¶„í¬ ìœ í˜•")
            
            dist_cols = st.columns(3)
            dist_types = [
                ("ì£¼ê±°í˜•", "residential", "ğŸ ", "ì§€ì—­ ì£¼ë¯¼"),
                ("ì§ì¥í˜•", "workplace", "ğŸ¢", "ì§ì¥ì¸"),
                ("ìœ ë™í˜•", "floating", "ğŸš¶", "ìœ ë™ì¸êµ¬")
            ]
            
            for i, (name, key, icon, desc) in enumerate(dist_types):
                with dist_cols[i]:
                    ratio = distribution.get(key, 0)
                    st.metric(f"{icon} {name}", f"{ratio:.1f}%", help=desc)
            
            # ì£¼ìš” ê³ ê° ìœ í˜• ë¶„ì„
            max_type = max(distribution.items(), key=lambda x: x[1])
            type_names = {"residential": "ì£¼ê±°í˜•", "workplace": "ì§ì¥í˜•", "floating": "ìœ ë™í˜•"}
            st.info(f"**ì£¼ìš” ê³ ê° ìœ í˜•:** {type_names.get(max_type[0], max_type[0])} ({max_type[1]:.1f}%)")
    
    # 5. ê³ ê° ë¶„ì„ ìš”ì•½
    st.markdown("#### ğŸ“‹ ê³ ê° ë¶„ì„ ìš”ì•½")
    
    # ì£¼ìš” ì¸ì‚¬ì´íŠ¸ ìƒì„±
    insights = []
    
    if gender_data:
        male_ratio = gender_data.get("male_ratio", 0)
        if male_ratio > 60:
            insights.append(f"ë‚¨ì„± ê³ ê°ì´ {male_ratio:.1f}%ë¡œ ì••ë„ì ")
        elif male_ratio < 40:
            insights.append(f"ì—¬ì„± ê³ ê°ì´ {100-male_ratio:.1f}%ë¡œ ë§ìŒ")
        else:
            insights.append("ì„±ë³„ ë¶„í¬ê°€ ê· í˜•ì ")
    
    if age_data:
        max_age = max(age_data.items(), key=lambda x: x[1])
        insights.append(f"{max_age[0]} ê³ ê°ì¸µì´ {max_age[1]:.1f}%ë¡œ ì£¼ë ¥")
    
    if customer_type:
        new_ratio = customer_type.get("new_customers", {}).get("ratio", 0)
        return_ratio = customer_type.get("returning_customers", {}).get("ratio", 0)
        if return_ratio > new_ratio:
            insights.append(f"ì¬ë°©ë¬¸ ê³ ê°({return_ratio:.1f}%)ì´ ì‹ ê·œ ê³ ê°({new_ratio:.1f}%)ë³´ë‹¤ ë§ìŒ")
        else:
            insights.append(f"ì‹ ê·œ ê³ ê°({new_ratio:.1f}%)ì´ ì¬ë°©ë¬¸ ê³ ê°({return_ratio:.1f}%)ë³´ë‹¤ ë§ìŒ")
    
    if insights:
        for i, insight in enumerate(insights, 1):
            st.write(f"{i}. {insight}")
    
    # ===== ì‹œê°í™” ì¶”ê°€ =====
    visualizations = analysis_data.get("visualizations", {})
    store_charts = visualizations.get("store_charts", [])
    
    if store_charts:
        st.markdown("---")
        st.markdown("#### ğŸ“Š ê³ ê° ë¶„ì„ ì°¨íŠ¸")
        
        # ê³ ê° ê´€ë ¨ ì°¨íŠ¸ í•„í„°ë§
        customer_charts = [c for c in store_charts if any(keyword in c.get("name", "").lower() 
                          for keyword in ["age", "gender", "customer", "ì—°ë ¹", "ì„±ë³„", "ê³ ê°"])]
        
        if customer_charts:
            cols = st.columns(2)
            for idx, chart_info in enumerate(customer_charts[:6]):  # ìµœëŒ€ 6ê°œ
                col_idx = idx % 2
                with cols[col_idx]:
                    chart_path = chart_info.get("path")
                    chart_name = chart_info.get("name", f"Chart {idx+1}")
                    
                    if chart_path and Path(chart_path).exists():
                        try:
                            st.image(chart_path, caption=chart_name, use_column_width=True)
                        except Exception as e:
                            st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name}")
        else:
            st.info("ê³ ê° ê´€ë ¨ ì°¨íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

def display_mobility_analysis(analysis_data):
    """ì´ë™ íŒ¨í„´ ë¶„ì„ íƒ­ - JSON ë°ì´í„° ê¸°ë°˜ ì²´ê³„ì  ë¶„ì„"""
    st.markdown("### ğŸš¶ ì´ë™ íŒ¨í„´ ë¶„ì„")
    
    mobility_data = analysis_data.get("mobility_analysis", {})
    if not mobility_data:
        st.info("ì´ë™ íŒ¨í„´ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    analysis = mobility_data.get("analysis", {})
    if not analysis:
        st.info("ì´ë™ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 1. ê¸°ë³¸ ì •ë³´
    st.markdown("#### ğŸ“ ë¶„ì„ ê¸°ë³¸ ì •ë³´")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**ë¶„ì„ ëŒ€ìƒ:** {mobility_data.get('target_dong', 'N/A')}")
        st.write(f"**ë¶„ì„ ì‹œì :** {mobility_data.get('timestamp', 'N/A')}")
    
    with col2:
        total_moves = sum(analysis.get("part1_move_types", {}).values())
        st.write(f"**ì´ ì´ë™ëŸ‰:** {total_moves:,}ëª…")
    
    # 2. ì´ë™ ìœ í˜• ë¶„ì„ (ìƒì„¸)
    move_types = analysis.get("part1_move_types", {})
    if move_types:
        st.markdown("#### ğŸ”„ ì´ë™ ìœ í˜• ë¶„ì„")
        
        inflow = move_types.get('ìœ ì…', 0)
        outflow = move_types.get('ìœ ì¶œ', 0)
        internal = move_types.get('ë‚´ë¶€ì´ë™', 0)
        total = inflow + outflow + internal
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            inflow_ratio = (inflow / total * 100) if total > 0 else 0
            st.metric("ìœ ì…", f"{inflow:,}ëª…", f"{inflow_ratio:.1f}%")
        
        with col2:
            outflow_ratio = (outflow / total * 100) if total > 0 else 0
            st.metric("ìœ ì¶œ", f"{outflow:,}ëª…", f"{outflow_ratio:.1f}%")
        
        with col3:
            internal_ratio = (internal / total * 100) if total > 0 else 0
            st.metric("ë‚´ë¶€ì´ë™", f"{internal:,}ëª…", f"{internal_ratio:.1f}%")
        
        # ì´ë™ ìœ í˜• ë¶„ì„
        if outflow > inflow:
            st.warning("ìœ ì¶œì´ ìœ ì…ë³´ë‹¤ ë§ì•„ ì¸êµ¬ ê°ì†Œ ì¶”ì„¸ì…ë‹ˆë‹¤")
        elif inflow > outflow:
            st.success("ìœ ì…ì´ ìœ ì¶œë³´ë‹¤ ë§ì•„ ì¸êµ¬ ì¦ê°€ ì¶”ì„¸ì…ë‹ˆë‹¤")
        else:
            st.info("ìœ ì…ê³¼ ìœ ì¶œì´ ê· í˜•ì„ ì´ë£¨ê³  ìˆìŠµë‹ˆë‹¤")
    
    # 3. ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„ (ìƒì„¸)
    time_pattern = analysis.get("part2_time_pattern", {})
    if time_pattern:
        st.markdown("#### â° ì‹œê°„ëŒ€ë³„ ì´ë™ íŒ¨í„´")
        
        # ìµœëŒ€ ì´ë™ ì‹œê°„
        peak_hour = max(time_pattern.items(), key=lambda x: x[1])
        st.write(f"**ìµœëŒ€ ì´ë™ ì‹œê°„:** {peak_hour[0]}ì‹œ ({peak_hour[1]:,}ëª…)")
        
        # ì‹œê°„ëŒ€ë³„ ë¶„ë¥˜
        morning_hours = {k: v for k, v in time_pattern.items() if 6 <= int(k) <= 9}
        afternoon_hours = {k: v for k, v in time_pattern.items() if 10 <= int(k) <= 17}
        evening_hours = {k: v for k, v in time_pattern.items() if 18 <= int(k) <= 22}
        night_hours = {k: v for k, v in time_pattern.items() if 23 <= int(k) or int(k) <= 5}
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            morning_total = sum(morning_hours.values())
            st.metric("ì˜¤ì „ (6-9ì‹œ)", f"{morning_total:,}ëª…")
        
        with col2:
            afternoon_total = sum(afternoon_hours.values())
            st.metric("ì˜¤í›„ (10-17ì‹œ)", f"{afternoon_total:,}ëª…")
        
        with col3:
            evening_total = sum(evening_hours.values())
            st.metric("ì €ë… (18-22ì‹œ)", f"{evening_total:,}ëª…")
        
        with col4:
            night_total = sum(night_hours.values())
            st.metric("ì•¼ê°„ (23-5ì‹œ)", f"{night_total:,}ëª…")
        
        # ìƒìœ„ 5ê°œ ì‹œê°„ëŒ€
        top_hours = sorted(time_pattern.items(), key=lambda x: x[1], reverse=True)[:5]
        st.write("**ìƒìœ„ ì´ë™ ì‹œê°„ëŒ€:**")
        for i, (hour, count) in enumerate(top_hours, 1):
            st.write(f"{i}. {hour}ì‹œ: {count:,}ëª…")
    
    # 4. ëª©ì ë³„ ë¶„ì„ (ìƒì„¸)
    purpose_data = analysis.get("part3_purpose", {})
    if purpose_data:
        st.markdown("#### ğŸ¯ ëª©ì ë³„ ì´ë™ ë¶„ì„")
        
        total_purpose = sum(purpose_data.values())
        top_purposes = sorted(purpose_data.items(), key=lambda x: x[1], reverse=True)[:5]
        
        for i, (purpose, count) in enumerate(top_purposes, 1):
            percentage = (count / total_purpose * 100) if total_purpose > 0 else 0
            col1, col2 = st.columns([1, 3])
            
            with col1:
                st.write(f"**{i}ìœ„**")
            with col2:
                st.write(f"{purpose}: {count:,}ëª… ({percentage:.1f}%)")
                st.progress(percentage / 100)
    
    # 5. êµí†µìˆ˜ë‹¨ë³„ ë¶„ì„ (ìƒì„¸)
    transport_data = analysis.get("part4_transport", {})
    if transport_data:
        st.markdown("#### ğŸš— êµí†µìˆ˜ë‹¨ë³„ ì´ìš© ë¶„ì„")
        
        total_transport = sum(transport_data.values())
        
        # ì£¼ìš” êµí†µìˆ˜ë‹¨
        main_transports = {
            "ì°¨ëŸ‰": transport_data.get('ì°¨ëŸ‰', 0),
            "ì§€í•˜ì² ": transport_data.get('ì§€í•˜ì² ', 0),
            "ë„ë³´": transport_data.get('ë„ë³´', 0),
            "ë²„ìŠ¤": transport_data.get('ì¼ë°˜ë²„ìŠ¤', 0) + transport_data.get('ê´‘ì—­ë²„ìŠ¤', 0),
            "ê¸°íƒ€": transport_data.get('ê¸°íƒ€', 0)
        }
        
        col1, col2 = st.columns(2)
        
        with col1:
            for transport, count in list(main_transports.items())[:3]:
                percentage = (count / total_transport * 100) if total_transport > 0 else 0
                st.metric(transport, f"{count:,}ëª…", f"{percentage:.1f}%")
        
        with col2:
            for transport, count in list(main_transports.items())[3:]:
                percentage = (count / total_transport * 100) if total_transport > 0 else 0
                st.metric(transport, f"{count:,}ëª…", f"{percentage:.1f}%")
    
    # 6. ì—°ë ¹ëŒ€ë³„ ë¶„ì„ (ìƒì„¸)
    age_data = analysis.get("part5_age", {})
    if age_data:
        st.markdown("#### ğŸ‘¥ ì—°ë ¹ëŒ€ë³„ ì´ë™ ë¶„ì„")
        
        total_age = sum(age_data.values())
        age_groups = {
            "10ëŒ€ ì´í•˜": age_data.get("00ëŒ€", 0) + age_data.get("10ëŒ€", 0),
            "20-30ëŒ€": age_data.get("20ëŒ€", 0) + age_data.get("30ëŒ€", 0),
            "40-50ëŒ€": age_data.get("40ëŒ€", 0) + age_data.get("50ëŒ€", 0),
            "60ëŒ€ ì´ìƒ": age_data.get("60ëŒ€", 0) + age_data.get("70ëŒ€ ì´ìƒ", 0)
        }
        
        age_cols = st.columns(4)
        for i, (age_group, count) in enumerate(age_groups.items()):
            with age_cols[i]:
                percentage = (count / total_age * 100) if total_age > 0 else 0
                st.metric(age_group, f"{count:,}ëª…", f"{percentage:.1f}%")
    
    # 7. ì—°ë ¹ëŒ€ë³„ ëª©ì  ë¶„ì„
    age_purpose_data = analysis.get("part5_2_age_purpose", {})
    if age_purpose_data:
        st.markdown("#### ğŸ¯ ì—°ë ¹ëŒ€ë³„ ì£¼ìš” ëª©ì ")
        
        for age_group, data in age_purpose_data.items():
            if isinstance(data, dict):
                purpose = data.get("top_purpose", "N/A")
                percentage = data.get("percentage", 0)
                st.write(f"**{age_group}:** {purpose} ({percentage:.1f}%)")
    
    # 8. ì´ë™ íŒ¨í„´ ìš”ì•½
    st.markdown("#### ğŸ“‹ ì´ë™ íŒ¨í„´ ìš”ì•½")
    
    insights = []
    
    if move_types:
        inflow = move_types.get('ìœ ì…', 0)
        outflow = move_types.get('ìœ ì¶œ', 0)
        if outflow > inflow:
            insights.append(f"ìœ ì¶œ({outflow:,}ëª…)ì´ ìœ ì…({inflow:,}ëª…)ë³´ë‹¤ ë§ì•„ ì¸êµ¬ ê°ì†Œ ì¶”ì„¸")
        else:
            insights.append(f"ìœ ì…({inflow:,}ëª…)ì´ ìœ ì¶œ({outflow:,}ëª…)ë³´ë‹¤ ë§ì•„ ì¸êµ¬ ì¦ê°€ ì¶”ì„¸")
    
    if time_pattern:
        peak_hour = max(time_pattern.items(), key=lambda x: x[1])
        insights.append(f"{peak_hour[0]}ì‹œì— ìµœëŒ€ ì´ë™ëŸ‰({peak_hour[1]:,}ëª…) ë°œìƒ")
    
    if purpose_data:
        top_purpose = max(purpose_data.items(), key=lambda x: x[1])
        insights.append(f"ì£¼ìš” ì´ë™ ëª©ì : {top_purpose[0]}({top_purpose[1]:,}ëª…)")
    
    if transport_data:
        top_transport = max(transport_data.items(), key=lambda x: x[1])
        insights.append(f"ì£¼ìš” êµí†µìˆ˜ë‹¨: {top_transport[0]}({top_transport[1]:,}ëª…)")
    
    if insights:
        for i, insight in enumerate(insights, 1):
            st.write(f"{i}. {insight}")
    
    # 9. ì‹œê°í™” (ê¸°ì¡´ ì°¨íŠ¸ í‘œì‹œ)
    visualizations = analysis_data.get("visualizations", {})
    mobility_charts = visualizations.get("mobility_charts", [])
    
    if mobility_charts:
        st.markdown("---")
        st.markdown("#### ğŸ“Š ì´ë™ íŒ¨í„´ ì°¨íŠ¸")
        
        cols = st.columns(2)
        for idx, chart_info in enumerate(mobility_charts[:6]):  # ìµœëŒ€ 6ê°œ
            col_idx = idx % 2
            with cols[col_idx]:
                chart_path = chart_info.get("path")
                chart_name = chart_info.get("name", f"Chart {idx+1}")
                
                if chart_path and Path(chart_path).exists():
                    try:
                        st.image(chart_path, caption=chart_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name}")
    else:
        st.info("ì´ë™ íŒ¨í„´ ì°¨íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

def display_panorama_analysis(analysis_data):
    """ì§€ì—­ ë¶„ì„ íƒ­"""
    st.markdown("### ğŸ˜ï¸ ì§€ì—­ ë¶„ì„ (íŒŒë…¸ë¼ë§ˆ)")
    
    panorama_data = analysis_data.get("panorama_analysis", {})
    if not panorama_data:
        st.info("íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    metadata = panorama_data.get("metadata", {})
    if metadata:
        st.write(f"**ë¶„ì„ ì£¼ì†Œ:** {metadata.get('input_address', 'N/A')}")
        st.write(f"**ë¶„ì„ ë°˜ê²½:** {metadata.get('buffer_meters', 'N/A')}m")
        st.write(f"**ë¶„ì„ ì´ë¯¸ì§€:** {metadata.get('images_analyzed', 0)}ê°œ")
    
    # ì¢…í•© ë¶„ì„ ê²°ê³¼
    synthesis = panorama_data.get("synthesis", {})
    if synthesis:
        st.markdown("#### ì¢…í•© ë¶„ì„ ê²°ê³¼")
        
        area_summary = synthesis.get("area_summary", {})
        if area_summary:
            st.write(f"**ì§€ì—­ íŠ¹ì„±:** {area_summary.get('overall_character', 'N/A')}")
            st.write(f"**ìƒê¶Œ ìœ í˜•:** {area_summary.get('primary_commercial_type', 'N/A')}")
        
        scores = synthesis.get("comprehensive_scores", {})
        if scores:
            st.markdown("#### ì§€ì—­ ì ìˆ˜")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("ìƒê¶Œ í™œë ¥", f"{scores.get('commercial_atmosphere', 0)}/10")
                st.metric("ê±°ë¦¬ ë¶„ìœ„ê¸°", f"{scores.get('street_atmosphere', 0)}/10")
            with col2:
                st.metric("ì²­ê²°ë„", f"{scores.get('cleanliness', 0)}/10")
                st.metric("ìœ ì§€ë³´ìˆ˜", f"{scores.get('maintenance', 0)}/10")
            with col3:
                st.metric("ë³´í–‰ì„±", f"{scores.get('walkability', 0)}/10")
                st.metric("ì•ˆì „ê°", f"{scores.get('safety_perception', 0)}/10")
        
        detailed_assessment = synthesis.get("detailed_assessment", {})
        if detailed_assessment:
            strengths = detailed_assessment.get("strengths", [])
            weaknesses = detailed_assessment.get("weaknesses", [])
            
            if strengths:
                st.markdown("#### ê°•ì ")
                for strength in strengths:
                    st.write(f"âœ… {strength}")
            
            if weaknesses:
                st.markdown("#### ì•½ì ")
                for weakness in weaknesses:
                    st.write(f"âŒ {weakness}")
            
            expert_opinion = detailed_assessment.get("expert_opinion")
            if expert_opinion:
                st.markdown("#### ì „ë¬¸ê°€ ì˜ê²¬")
                st.write(expert_opinion)
    
    # ===== ì‹œê°í™” ì¶”ê°€ =====
    visualizations = analysis_data.get("visualizations", {})
    panorama_images = visualizations.get("panorama_images", [])
    
    if panorama_images:
        st.markdown("---")
        st.markdown("#### ğŸ“· íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€")
        cols = st.columns(2)
        for idx, img_info in enumerate(panorama_images[:6]):  # ìµœëŒ€ 6ê°œ
            col_idx = idx % 2
            with cols[col_idx]:
                img_path = img_info.get("path")
                img_name = img_info.get("name", f"Image {idx+1}")
                
                if img_path and Path(img_path).exists():
                    try:
                        st.image(img_path, caption=img_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {img_name}")
    
    # ê³µê°„ ë¶„ì„ ì§€ë„
    spatial_files = visualizations.get("spatial_files", [])
    if spatial_files:
        st.markdown("---")
        st.markdown("#### ğŸ—ºï¸ ê³µê°„ ë¶„ì„")
        for file_info in spatial_files:
            file_path = file_info.get("path")
            file_name = file_info.get("name", "Unknown")
            
            if file_path and Path(file_path).exists():
                if ".png" in str(file_path):
                    try:
                        st.image(file_path, caption=file_name, use_column_width=True)
                    except:
                        pass
                elif ".html" in str(file_path):
                    st.markdown(f"**{file_name}:**")
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            html_content = f.read()
                        st.components.v1.html(html_content, height=600)
                    except Exception as e:
                        st.error(f"ì§€ë„ ë¡œë”© ì‹¤íŒ¨: {e}")
                        st.markdown(f"[ì§€ë„ ë³´ê¸°]({file_path})")

def display_marketplace_analysis(analysis_data):
    """ìƒê¶Œ ë¶„ì„ íƒ­ - JSON ë°ì´í„° ê¸°ë°˜ ì²´ê³„ì  ë¶„ì„"""
    st.markdown("### ğŸ¬ ìƒê¶Œ ë¶„ì„")
    
    marketplace_data = analysis_data.get("marketplace_analysis", {})
    if not marketplace_data:
        st.info("ìƒê¶Œ ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # 1. ìƒê¶Œ ê¸°ë³¸ ì •ë³´
    st.markdown("#### ğŸ“ ìƒê¶Œ ê¸°ë³¸ ì •ë³´")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**ìƒê¶Œëª…:** {marketplace_data.get('ìƒê¶Œëª…', 'N/A')}")
        st.write(f"**ë¶„ì„ì¼ì‹œ:** {marketplace_data.get('ë¶„ì„ì¼ì‹œ', 'N/A')}")
    
    with col2:
        st.write(f"**ì´ í˜ì´ì§€:** {marketplace_data.get('ì´_í˜ì´ì§€', 'N/A')}í˜ì´ì§€")
        st.write(f"**ì¶”ì¶œ í˜ì´ì§€:** {marketplace_data.get('ì¶”ì¶œ_í˜ì´ì§€', 'N/A')}í˜ì´ì§€")
    
    # 2. ì¢…í•©ì˜ê²¬ ì„¹ì…˜ ë¶„ì„
    data_section = marketplace_data.get("ë°ì´í„°", [])
    if data_section and len(data_section) > 0:
        # ì¢…í•©ì˜ê²¬ ë°ì´í„° ì°¾ê¸°
        comprehensive_data = None
        for data_item in data_section:
            if data_item.get("ìœ í˜•") == "ì¢…í•©ì˜ê²¬":
                comprehensive_data = data_item
                break
        
        if comprehensive_data:
            st.markdown("#### ğŸ“‹ ì¢…í•©ì˜ê²¬")
            
            # ë©´ì  ì •ë³´
            area_info = comprehensive_data.get("ë©´ì ", {})
            if area_info:
                st.write(f"**ë¶„ì„ ë©´ì :** {area_info.get('ë¶„ì„', 'N/A')} {area_info.get('ë‹¨ìœ„', '')}")
            
            # ì í¬ìˆ˜ ì •ë³´
            store_count = comprehensive_data.get("ì í¬ìˆ˜", {})
            if store_count:
                current_info = store_count.get("í˜„ì¬", {})
                st.write(f"**í˜„ì¬ ì í¬ìˆ˜:** {current_info.get('ê°’', 'N/A')} {current_info.get('ë‹¨ìœ„', '')} ({current_info.get('ê¸°ì¤€', '')})")
                
                # ë³€í™”ëŸ‰ í‘œì‹œ
                col1, col2 = st.columns(2)
                with col1:
                    prev_quarter = store_count.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                    if prev_quarter:
                        change = prev_quarter.get("ë³€í™”", 0)
                        st.metric("ì „ë¶„ê¸° ëŒ€ë¹„", f"{change:+d}ê°œ", delta=f"{change:+d}ê°œ")
                
                with col2:
                    prev_year = store_count.get("ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„", {})
                    if prev_year:
                        change = prev_year.get("ë³€í™”", 0)
                        st.metric("ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„", f"{change:+d}ê°œ", delta=f"{change:+d}ê°œ")
            
            # ë§¤ì¶œì•¡ ì •ë³´
            sales_info = comprehensive_data.get("ë§¤ì¶œì•¡", {})
            if sales_info:
                current_sales = sales_info.get("í˜„ì¬", {})
                st.write(f"**í˜„ì¬ ë§¤ì¶œì•¡:** {current_sales.get('ê°’', 'N/A')} {current_sales.get('ë‹¨ìœ„', '')} ({current_sales.get('ê¸°ì¤€', '')})")
                
                # ë§¤ì¶œ ë³€í™”ëŸ‰ í‘œì‹œ
                col1, col2 = st.columns(2)
                with col1:
                    prev_quarter_sales = sales_info.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                    if prev_quarter_sales:
                        change = prev_quarter_sales.get("ë³€í™”", 0)
                        st.metric("ì „ë¶„ê¸° ëŒ€ë¹„ ë§¤ì¶œ", f"{change:+d}ë§Œì›", delta=f"{change:+d}ë§Œì›")
                
                with col2:
                    prev_year_sales = sales_info.get("ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„", {})
                    if prev_year_sales:
                        change = prev_year_sales.get("ë³€í™”", 0)
                        st.metric("ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„ ë§¤ì¶œ", f"{change:+d}ë§Œì›", delta=f"{change:+d}ë§Œì›")
            
            # ìœ ë™ì¸êµ¬ ì •ë³´
            population_info = comprehensive_data.get("ìœ ë™ì¸êµ¬", {})
            if population_info:
                current_pop = population_info.get("í˜„ì¬", {})
                st.write(f"**í˜„ì¬ ìœ ë™ì¸êµ¬:** {current_pop.get('ê°’', 'N/A')} {current_pop.get('ë‹¨ìœ„', '')} ({current_pop.get('ê¸°ì¤€', '')})")
                
                # ìœ ë™ì¸êµ¬ ë³€í™”ëŸ‰ í‘œì‹œ
                col1, col2 = st.columns(2)
                with col1:
                    prev_quarter_pop = population_info.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                    if prev_quarter_pop:
                        change = prev_quarter_pop.get("ë³€í™”", 0)
                        st.metric("ì „ë¶„ê¸° ëŒ€ë¹„ ìœ ë™ì¸êµ¬", f"{change:+d}ëª…", delta=f"{change:+d}ëª…")
                
                with col2:
                    prev_year_pop = population_info.get("ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„", {})
                    if prev_year_pop:
                        change = prev_year_pop.get("ë³€í™”", 0)
                        st.metric("ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„ ìœ ë™ì¸êµ¬", f"{change:+d}ëª…", delta=f"{change:+d}ëª…")
    
    # 3. ìƒì„¸ ë¶„ì„ ë°ì´í„°
    st.markdown("#### ğŸ“Š ìƒì„¸ ë¶„ì„ ë°ì´í„°")
    
    # ê° í˜ì´ì§€ë³„ ë¶„ì„ ê²°ê³¼ í‘œì‹œ
    for data_item in data_section:
        page_num = data_item.get("í˜ì´ì§€", 0)
        page_title = data_item.get("ì œëª©", "")
        page_type = data_item.get("ìœ í˜•", "")
        
        if page_title or page_type:
            with st.expander(f"í˜ì´ì§€ {page_num}: {page_title or page_type}", expanded=(page_num <= 3)):
                
                # ì í¬ìˆ˜ ë¶„ì„
                if page_title == "ì í¬ìˆ˜":
                    store_count = data_item.get("ì í¬ìˆ˜", {})
                    if store_count:
                        st.write(f"**ì í¬ìˆ˜:** {store_count.get('ê°’', 'N/A')} {store_count.get('ë‹¨ìœ„', '')}")
                    
                    comparisons = data_item.get("ë¹„êµ", [])
                    if comparisons:
                        st.write("**ë¹„êµ ë¶„ì„:**")
                        for comp in comparisons:
                            st.write(f"- {comp.get('ê¸°ì¤€', '')}: {comp.get('ë³€í™”', '')} {comp.get('ë‹¨ìœ„', '')}")
                    
                    descriptions = data_item.get("ì„¤ëª…", [])
                    if descriptions:
                        st.write("**ë¶„ì„ ì˜ê²¬:**")
                        for desc in descriptions:
                            st.write(f"- {desc}")
                
                # ì‹ ìƒê¸°ì—…ìƒì¡´ìœ¨ ë¶„ì„
                elif page_title == "ì‹ ìƒê¸°ì—…ìƒì¡´ìœ¨(3ë…„)":
                    comparisons = data_item.get("ë¹„êµ", [])
                    if comparisons:
                        st.write("**ìƒì¡´ìœ¨ ë¹„êµ:**")
                        for comp in comparisons:
                            change = comp.get("ë³€í™”", 0)
                            if isinstance(change, str):
                                try:
                                    change = float(change)
                                except:
                                    change = 0
                            st.metric(comp.get("ê¸°ì¤€", ""), f"{change:+.2f}%", delta=f"{change:+.2f}%")
                    
                    descriptions = data_item.get("ì„¤ëª…", [])
                    if descriptions:
                        st.write("**ë¶„ì„ ì˜ê²¬:**")
                        for desc in descriptions:
                            st.write(f"- {desc}")
                
                # ê°œì—…í˜„í™© ë¶„ì„
                elif page_title == "ê°œì—…í˜„í™©":
                    new_stores = data_item.get("í˜ì—…ìˆ˜", {})
                    if new_stores:
                        st.write(f"**ì‹ ê·œ ê°œì—…:** {new_stores.get('ê°’', 'N/A')} {new_stores.get('ë‹¨ìœ„', '')}")
                    
                    comparisons = data_item.get("ë¹„êµ", [])
                    if comparisons:
                        st.write("**ê°œì—…/íì—… ë¹„êµ:**")
                        for comp in comparisons:
                            st.write(f"- {comp.get('ê¸°ì¤€', '')}: {comp.get('ë³€í™”', '')} {comp.get('ë‹¨ìœ„', '')}")
                    
                    descriptions = data_item.get("ì„¤ëª…", [])
                    if descriptions:
                        st.write("**ë¶„ì„ ì˜ê²¬:**")
                        for desc in descriptions:
                            st.write(f"- {desc}")
                
                # ë§¤ì¶œì•¡ ë¶„ì„
                elif page_title == "ë§¤ì¶œì•¡":
                    monthly_sales = data_item.get("ì í¬ë‹¹ì›”í‰ê· ë§¤ì¶œê±´ìˆ˜", {})
                    if monthly_sales:
                        st.write(f"**ì í¬ë‹¹ ì›”í‰ê·  ë§¤ì¶œê±´ìˆ˜:** {monthly_sales.get('ê°’', 'N/A')} {monthly_sales.get('ë‹¨ìœ„', '')}")
                    
                    comparisons = data_item.get("ë¹„êµ", [])
                    if comparisons:
                        st.write("**ë§¤ì¶œ ë³€í™”:**")
                        for comp in comparisons:
                            change = comp.get("ë³€í™”", 0)
                            if isinstance(change, str):
                                try:
                                    change = float(change)
                                except:
                                    change = 0
                            st.metric(comp.get("ê¸°ì¤€", ""), f"{change:+.0f}ë§Œì›", delta=f"{change:+.0f}ë§Œì›")
                
                # ìš”ì¼ë³„/ì„±ë³„/ì—°ë ¹ëŒ€ë³„ ë§¤ì¶œ ë¶„ì„
                elif page_title in ["ìš”ì¼ë³„ë§¤ì¶œ", "ì„±ë³„ë§¤ì¶œ", "ì—°ë ¹ëŒ€ë³„ë§¤ì¶œ"]:
                    descriptions = data_item.get("ì„¤ëª…", [])
                    if descriptions:
                        st.write("**ë¶„ì„ ì˜ê²¬:**")
                        for desc in descriptions:
                            st.write(f"- {desc}")
    
    # 4. PDF ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì¶”ê°€
    st.markdown("#### ğŸ“„ ë³´ê³ ì„œ ë‹¤ìš´ë¡œë“œ")
    
    # PDF íŒŒì¼ ê²½ë¡œ ìƒì„± (JSONê³¼ ë™ì¼í•œ ì´ë¦„ì˜ PDF ì°¾ê¸°)
    store_code = analysis_data.get("store_code", "")
    if store_code:
        # ìƒê¶Œëª…ìœ¼ë¡œ PDF íŒŒì¼ ì°¾ê¸°
        marketplace_name = marketplace_data.get("ìƒê¶Œëª…", "")
        if marketplace_name:
            # PDF íŒŒì¼ ê²½ë¡œë“¤ ì‹œë„ (ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤_ê²°ê³¼ í´ë”ì—ì„œ)
            possible_pdf_paths = [
                f"agents_new/data outputs/ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤_ê²°ê³¼/{marketplace_name}.pdf",
                f"agents_new/data outputs/ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤_ê²°ê³¼/{marketplace_name} 3ë²ˆ.pdf",
                f"agents_new/data outputs/ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤_ê²°ê³¼/{marketplace_name} 4ë²ˆ.pdf",
                f"agents_new/data outputs/ìƒê¶Œë¶„ì„ì„œë¹„ìŠ¤_ê²°ê³¼/{marketplace_name}.md"  # MD íŒŒì¼ë„ ì‹œë„
            ]
            
            pdf_found = False
            for pdf_path in possible_pdf_paths:
                if Path(pdf_path).exists():
                    with open(pdf_path, "rb") as pdf_file:
                        pdf_bytes = pdf_file.read()
                        st.download_button(
                            label=f"ğŸ“„ {marketplace_name} ìƒê¶Œë¶„ì„ PDF ë‹¤ìš´ë¡œë“œ",
                            data=pdf_bytes,
                            file_name=f"{marketplace_name}_ìƒê¶Œë¶„ì„.pdf",
                            mime="application/pdf"
                        )
                        pdf_found = True
                        break
            
            if not pdf_found:
                st.info("PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # 5. Gemini ìš”ì•½ (ê¸°ì¡´ ê¸°ëŠ¥ ìœ ì§€)
    try:
        with st.spinner("Geminië¡œ ìƒê¶Œ ë¶„ì„ ìš”ì•½ ìƒì„± ì¤‘..."):
            summary = generate_marketplace_summary_with_gemini(marketplace_data)
            if summary:
                st.markdown("#### ğŸ¤– AI ë¶„ì„ ìš”ì•½")
                st.write(summary)
    except Exception as e:
        st.warning(f"AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {e}")
    
    # ì›ë³¸ JSON ë°ì´í„° í‘œì‹œ (ì ‘ì„ ìˆ˜ ìˆê²Œ)
    with st.expander("ğŸ“„ ì›ë³¸ JSON ë°ì´í„° ë³´ê¸°"):
        st.json(marketplace_data)

def display_marketing_analysis(analysis_data):
    """ë§ˆì¼€íŒ… ë¶„ì„ íƒ­ - formatted_output ìš°ì„  í‘œì‹œ"""
    
    marketing_data = analysis_data.get("marketing_analysis", {})
    if not marketing_data:
        st.info("ë§ˆì¼€íŒ… ë¶„ì„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # formatted_outputì´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ í‘œì‹œ (ìµœìš°ì„ !)
    formatted_output = marketing_data.get("formatted_output")
    if formatted_output:
        st.markdown(formatted_output)
        st.markdown("---")
        st.caption("ğŸ’¡ ìƒì„¸ ë°ì´í„°ëŠ” ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return
    
    # formatted_outputì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í‘œì‹œ
    st.markdown("### ğŸ“ˆ ë§ˆì¼€íŒ… ì „ëµ")
    st.warning("âš ï¸ ì´ ë¶„ì„ì€ êµ¬ë²„ì „ì…ë‹ˆë‹¤. ìƒˆë¡œ ë¶„ì„í•˜ë©´ ë” ìƒì„¸í•œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.")
    
    # í˜ë¥´ì†Œë‚˜ ë° ê¸°ë³¸ ì •ë³´
    persona_analysis = marketing_data.get("persona_analysis", {})
    risk_analysis = marketing_data.get("risk_analysis", {})
    strategies = marketing_data.get("marketing_strategies", [])
    campaign = marketing_data.get("campaign_plan", {})
    
    # 1. í˜„í™© ë¶„ì„ (í˜ë¥´ì†Œë‚˜ ìœ í˜•)
    st.markdown("## ğŸ“Š í˜„í™© ë¶„ì„")
    
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.markdown("### ğŸ¯ í˜ë¥´ì†Œë‚˜ ìœ í˜•")
        st.info(f"**{persona_analysis.get('persona_type', 'N/A')}**")
        st.write(persona_analysis.get('persona_description', ''))
        
        # ë§¤ì¥ íŠ¹ì„±
        components = persona_analysis.get("components", {})
        if components:
            st.markdown("**ğŸ“‹ ë§¤ì¥ íŠ¹ì„±:**")
            st.write(f"- **ì—…ì¢…:** {components.get('industry', 'N/A')}")
            st.write(f"- **ìƒê¶Œ:** {components.get('commercial_zone', 'N/A')}")
            st.write(f"- **ë§¤ì¥ ì—°ë ¹:** {components.get('store_age', 'N/A')}")
            customer_demo = components.get('customer_demographics', {})
            st.write(f"- **ì£¼ìš” ê³ ê°:** {customer_demo.get('gender', 'N/A')} {customer_demo.get('age', 'N/A')}")
            st.write(f"- **ê³ ê° ìœ í˜•:** {components.get('customer_type', 'N/A')}")
            st.write(f"- **ë°°ë‹¬ ë¹„ì¤‘:** {components.get('delivery_ratio', 'N/A')}")
    
    with col2:
        st.markdown("### âš ï¸ ìœ„í—˜ ë¶„ì„")
        risk_level = risk_analysis.get('overall_risk_level', 'N/A')
        if risk_level == "HIGH":
            st.error(f"**ìœ„í—˜ ìˆ˜ì¤€:** {risk_level} ğŸ”´")
        elif risk_level == "MEDIUM":
            st.warning(f"**ìœ„í—˜ ìˆ˜ì¤€:** {risk_level} ğŸŸ¡")
        else:
            st.success(f"**ìœ„í—˜ ìˆ˜ì¤€:** {risk_level} ğŸŸ¢")
        
        detected_risks = risk_analysis.get("detected_risks", [])
        if detected_risks:
            st.markdown("**ê°ì§€ëœ ìœ„í—˜ ìš”ì†Œ:**")
            for risk in detected_risks[:3]:
                st.write(f"- **{risk.get('name', 'N/A')}**")
                st.caption(f"  {risk.get('description', 'N/A')} (ìš°ì„ ìˆœìœ„: {risk.get('priority', 'N/A')})")
        else:
            st.success("âœ… íŠ¹ë³„í•œ ìœ„í—˜ ìš”ì†Œê°€ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    st.markdown("---")
    
    # 2. íƒ€ê²Ÿ ì „ëµ
    st.markdown("## ğŸ¯ íƒ€ê²Ÿ ì „ëµ")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### 1. ì£¼ íƒ€ê²Ÿ ê³ ê°ì¸µ")
        components = persona_analysis.get("components", {})
        customer_demo = components.get('customer_demographics', {})
        st.markdown(f"""
        - **ì„±ë³„:** {customer_demo.get('gender', 'N/A')}
        - **ì—°ë ¹ëŒ€:** {customer_demo.get('age', 'N/A')}
        - **íŠ¹ì„±:** {components.get('customer_type', 'N/A')}
        """)
    
    with col2:
        st.markdown("### 2. ë³´ì¡° íƒ€ê²Ÿ ê³ ê°ì¸µ ë° í™•ì¥ ì „ëµ")
        st.markdown("""
        - **ì—°ë ¹ëŒ€:** ì£¼ íƒ€ê²Ÿ ì¸ì ‘ ì—°ë ¹ëŒ€ (Â±10ì„¸)
        - **íŠ¹ì„±:** ìœ ì‚¬í•œ ì†Œë¹„ íŒ¨í„´ì„ ê°€ì§„ ê³ ê°ì¸µ
        - **í™•ì¥ ì „ëµ:** ì£¼ íƒ€ê²Ÿì—ì„œ ê²€ì¦ëœ ì „ëµì„ ì ì§„ì ìœ¼ë¡œ í™•ëŒ€
        """)
    
    st.markdown("---")
    
    # 3. í™ë³´ ì•„ì´ë””ì–´
    st.markdown("## ğŸ“¢ í™ë³´ ì•„ì´ë””ì–´")
    
    # SNS ì½˜í…ì¸ ê°€ ìˆìœ¼ë©´ í‘œì‹œ
    social_content = marketing_data.get("social_content", {})
    if social_content:
        cols = st.columns(3)
        
        # ì¸ìŠ¤íƒ€ê·¸ë¨ í¬ìŠ¤íŠ¸
        instagram_posts = social_content.get("instagram_posts", [])
        if instagram_posts and len(instagram_posts) > 0:
            with cols[0]:
                st.markdown("### ğŸ“± ì¸ìŠ¤íƒ€ê·¸ë¨")
                post = instagram_posts[0]
                st.markdown(f"**{post.get('title', '')}**")
                st.caption(post.get('content', ''))
                hashtags = post.get('hashtags', [])
                if hashtags:
                    st.caption(" ".join(hashtags[:5]))
        
        # í”„ë¡œëª¨ì…˜
        promotions = social_content.get("promotions", [])
        if promotions and len(promotions) > 0:
            with cols[1]:
                st.markdown("### ğŸ í”„ë¡œëª¨ì…˜")
                promo = promotions[0]
                st.markdown(f"**{promo.get('title', '')}**")
                st.caption(promo.get('content', ''))
        
        # ì´ë²¤íŠ¸
        with cols[2]:
            st.markdown("### ğŸ‰ ì´ë²¤íŠ¸")
            st.markdown("**ê³ ê° ë¦¬ë·° ì´ë²¤íŠ¸**")
            st.caption("ë¦¬ë·° ì‘ì„± ì‹œ ë‹¤ìŒ ë°©ë¬¸ 10% í• ì¸ ì¿ í° ì œê³µ")
    
    # 6ê°€ì§€ í™ë³´ ì•„ì´ë””ì–´ (ì „ëµì—ì„œ ì¶”ì¶œ)
    if strategies:
        st.markdown("### ï¿½ êµ¬ì²´ì  ì‹¤í–‰ ì•„ì´ë””ì–´")
        ideas_count = 0
        for strategy in strategies[:3]:  # ìƒìœ„ 3ê°œ ì „ëµì—ì„œ ì¶”ì¶œ
            tactics = strategy.get("tactics", [])
            for tactic in tactics[:2]:  # ê° ì „ëµì—ì„œ 2ê°œì”©
                ideas_count += 1
                st.markdown(f"**{ideas_count}. {tactic}**")
                if ideas_count >= 6:
                    break
            if ideas_count >= 6:
                break
    
    st.markdown("---")
    
    # 4. í•µì‹¬ ì¸ì‚¬ì´íŠ¸ (ê°„ëµí•˜ê²Œ)
    st.markdown("## ğŸ“Š í•µì‹¬ ì¸ì‚¬ì´íŠ¸")
    
    insights_text = []
    if detected_risks:
        insights_text.append(f"âš ï¸ ì£¼ìš” ìœ„í—˜: {', '.join([r.get('name', '') for r in detected_risks[:2]])}")
    if strategies:
        insights_text.append(f"ğŸ’¡ ì¶”ì²œ ì „ëµ ìˆ˜: {len(strategies)}ê°œ")
    if campaign:
        insights_text.append(f"ğŸ¯ ìº í˜ì¸ ê¸°ê°„: {campaign.get('duration', 'N/A')}")
    
    if insights_text:
        for insight in insights_text:
            st.markdown(f"- {insight}")
    
    st.markdown("---")
    
    # 5. ì¶”ì²œ ë§ˆì¼€íŒ… ì „ëµ (ìƒì„¸)
    st.markdown("## ğŸ’¡ ì¶”ì²œ ë§ˆì¼€íŒ… ì „ëµ")
    
    _display_marketing_strategies_detailed(strategies)
    
    st.markdown("---")
    
    # 6. ì¢…í•© ê²°ë¡ 
    st.markdown("## ğŸ“‹ ì¢…í•© ê²°ë¡ ")
    
    conclusion_text = f"""
{persona_analysis.get('persona_type', 'ë§¤ì¥')}ì€ {components.get('commercial_zone', 'ìƒì—…ì§€ì—­')}ì— ìœ„ì¹˜í•˜ë©°, 
{customer_demo.get('gender', '')} {customer_demo.get('age', '')}ë¥¼ ì£¼ íƒ€ê²Ÿìœ¼ë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.

**ì„±ê³µì ì¸ ë§ˆì¼€íŒ…ì„ ìœ„í•´ì„œëŠ” ë‹¤ìŒ ì „ëµì´ í•„ìˆ˜ì ì…ë‹ˆë‹¤:**
"""
    st.markdown(conclusion_text)
    
    for i, strategy in enumerate(strategies[:3], 1):
        st.markdown(f"{i}. **{strategy.get('name', 'N/A')}:** {strategy.get('expected_impact', 'N/A')}")
    
    st.markdown("---")
    
    # 7. SWOT ë¶„ì„ í˜•íƒœë¡œ ê°•ì /ì•½ì /ê¸°íšŒ/ìœ„í˜‘
    st.markdown("## ğŸ“Š SWOT ë¶„ì„")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("### ğŸ’ª ê°•ì ")
        st.markdown("""
        - í™•ê³ í•œ í•µì‹¬ ê³ ê°ì¸µ ë³´ìœ 
        - ëª…í™•í•œ í˜ë¥´ì†Œë‚˜ ì •ì˜
        - ì „ëµì  ê°œì„  ë°©í–¥ì„± í™•ë³´
        """)
        
        st.markdown("### ğŸš€ ê¸°íšŒìš”ì¸")
        st.markdown(f"""
        - {len(strategies)}ê°œì˜ êµ¬ì²´ì  ë§ˆì¼€íŒ… ì „ëµ í™•ë³´
        - íƒ€ê²Ÿ ê³ ê°ì¸µ í™•ëŒ€ ê°€ëŠ¥ì„±
        - ë””ì§€í„¸ ë§ˆì¼€íŒ… ê°•í™” ê¸°íšŒ
        """)
    
    with col2:
        st.markdown("### âš ï¸ ì•½ì ")
        if detected_risks:
            for risk in detected_risks[:3]:
                st.markdown(f"- {risk.get('name', 'N/A')}")
        else:
            st.markdown("- íŠ¹ë³„í•œ ì•½ì  ë°œê²¬ë˜ì§€ ì•ŠìŒ")
        
        st.markdown("### âš ï¸ ìœ„ê¸°ìš”ì¸")
        st.markdown(f"""
        - ê²½ìŸ ì‹¬í™” ê°€ëŠ¥ì„±
        - ì‹œì¥ íŠ¸ë Œë“œ ë³€í™” ëŒ€ì‘ í•„ìš”
        - ê³ ê° ì´íƒˆ ë°©ì§€ í•„ìš”
        """)

def _display_marketing_strategies_detailed(strategies):
    """ë§ˆì¼€íŒ… ì „ëµ ìƒì„¸ í‘œì‹œ - expander ì¤‘ì²© ì—†ì´"""
    if not strategies:
        st.info("ìƒì„±ëœ ë§ˆì¼€íŒ… ì „ëµì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    for i, strategy in enumerate(strategies, 1):
        # Expander ëŒ€ì‹  êµ¬ë¶„ì„ ê³¼ ì„¹ì…˜ìœ¼ë¡œ í‘œì‹œ
        st.markdown(f"### ì „ëµ {i}: {strategy.get('name', 'N/A')}")
        
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            st.markdown(f"**ğŸ“‹ ì„¤ëª…:** {strategy.get('description', 'N/A')}")
        
        with col2:
            st.metric("â±ï¸ êµ¬í˜„ ê¸°ê°„", strategy.get('implementation_time', 'N/A'))
        
        with col3:
            st.metric("ğŸ’° ì˜ˆì‚°", strategy.get('budget_estimate', 'N/A'))
        
        # ì±„ë„ ì •ë³´
        channel = strategy.get("channel", "N/A")
        if channel != "N/A":
            try:
                import sys
                from pathlib import Path
                agents_path = Path(__file__).parent.parent.parent / "agents_new"
                if str(agents_path) not in sys.path:
                    sys.path.insert(0, str(agents_path))
                
                from marketing_agent.strategy_generator import StrategyGenerator  # type: ignore
                
                sg = StrategyGenerator()
                expanded = sg.expand_channel_details(channel)
                
                # ì˜¨ë¼ì¸ ì±„ë„
                if expanded.get("online_channels"):
                    online_list = []
                    for ch in expanded["online_channels"]:
                        if ch == "ì¸ìŠ¤íƒ€ê·¸ë¨":
                            online_list.append("ì¸ìŠ¤íƒ€ê·¸ë¨ (ë¦´ìŠ¤/í”¼ë“œ/ìŠ¤í† ë¦¬)")
                        elif ch == "ë„¤ì´ë²„ì§€ë„":
                            online_list.append("ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤")
                        elif ch == "ë„¤ì´ë²„í”Œë ˆì´ìŠ¤":
                            online_list.append("ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤")
                        elif ch == "ì¹´ì¹´ì˜¤ë§µ":
                            online_list.append("ì¹´ì¹´ì˜¤ë§µ")
                        elif ch == "ë°°ë‹¬ì•±":
                            online_list.append("ë°°ë‹¬ì•± (ë°°ë¯¼/ì¿ íŒ¡ì´ì¸ )")
                        else:
                            online_list.append(ch)
                    st.markdown(f"**ğŸ“± ì˜¨ë¼ì¸ ì±„ë„:** {', '.join(online_list)}")
                
                # ì˜¤í”„ë¼ì¸ ì±„ë„
                if expanded.get("offline_channels"):
                    offline_list = []
                    for ch in expanded["offline_channels"]:
                        details = expanded["details"].get(ch, {})
                        tactics_list = details.get("promotion_strategy", [])
                        if tactics_list:
                            offline_list.append(f"{', '.join(tactics_list[:3])}")
                        else:
                            offline_list.append(ch)
                    st.markdown(f"**ğŸª ì˜¤í”„ë¼ì¸ ì±„ë„:** {', '.join(offline_list)}")
            except:
                st.markdown(f"**ğŸ“± ë§ˆì¼€íŒ… ì±„ë„:** {channel}")
        
        # ì£¼ìš” ì „ìˆ 
        tactics = strategy.get("tactics", [])
        if tactics:
            st.markdown("**âš¡ ì£¼ìš” ì „ìˆ :**")
            for j, tactic in enumerate(tactics, 1):
                st.markdown(f"  {j}. {tactic}")
        
        # ì˜ˆìƒ íš¨ê³¼ ë° ì„±ê³µ ì§€í‘œ
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown(f"**ğŸ¯ ì˜ˆìƒ íš¨ê³¼:**")
            st.info(strategy.get('expected_impact', 'N/A'))
        
        with col2:
            success_metrics = strategy.get("success_metrics", [])
            if success_metrics:
                st.markdown("**ğŸ“Š ì„±ê³µ ì§€í‘œ:**")
                for metric in success_metrics:
                    st.markdown(f"  âœ“ {metric}")
        
        st.markdown("---")

def _display_marketing_details(marketing_data):
    """ë§ˆì¼€íŒ… ë¶„ì„ ìƒì„¸ ì •ë³´ í‘œì‹œ (ë‚´ë¶€ í•¨ìˆ˜) - ì‚¬ìš© ì•ˆí•¨"""
    # í˜ë¥´ì†Œë‚˜ ë¶„ì„
    persona_analysis = marketing_data.get("persona_analysis", {})
    if persona_analysis:
        st.markdown("#### í˜ë¥´ì†Œë‚˜ ë¶„ì„")
        st.write(f"**í˜ë¥´ì†Œë‚˜ ìœ í˜•:** {persona_analysis.get('persona_type', 'N/A')}")
        st.write(f"**í˜ë¥´ì†Œë‚˜ ì„¤ëª…:** {persona_analysis.get('persona_description', 'N/A')}")
        
        # ë§ˆì¼€íŒ… í†¤
        marketing_tone = persona_analysis.get("marketing_tone", "")
        if marketing_tone:
            st.write(f"**ë§ˆì¼€íŒ… í†¤:** {marketing_tone}")
        
        # í•µì‹¬ ì±„ë„
        key_channels = persona_analysis.get("key_channels", [])
        if key_channels:
            st.markdown("#### í•µì‹¬ ë§ˆì¼€íŒ… ì±„ë„")
            for i, channel in enumerate(key_channels[:5], 1):
                st.write(f"{i}. {channel}")
    
    # ìœ„í—˜ ë¶„ì„
    risk_analysis = marketing_data.get("risk_analysis", {})
    if risk_analysis:
        st.markdown("#### ìœ„í—˜ ë¶„ì„")
        st.write(f"**ì „ì²´ ìœ„í—˜ë„:** {risk_analysis.get('overall_risk_level', 'N/A')}")
        
        detected_risks = risk_analysis.get("detected_risks", [])
        if detected_risks:
            st.write("**ê°ì§€ëœ ìœ„í—˜ ìš”ì†Œ:**")
            for risk in detected_risks[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                st.write(f"- **{risk.get('name', 'N/A')}:** {risk.get('description', 'N/A')} (ìš°ì„ ìˆœìœ„: {risk.get('priority', 'N/A')})")
    
    # ë§ˆì¼€íŒ… ì „ëµ
    strategies = marketing_data.get("marketing_strategies", [])
    if strategies:
        st.markdown("#### ğŸ“ˆ ë§ˆì¼€íŒ… ì „ëµ")
        for i, strategy in enumerate(strategies[:6], 1):  # ìƒìœ„ 6ê°œ í‘œì‹œ
            with st.expander(f"**{i}. {strategy.get('name', 'N/A')}**", expanded=(i==1)):
                st.markdown(f"**ğŸ“‹ ì „ëµ ì„¤ëª…:**")
                st.write(strategy.get('description', 'N/A'))
                
                st.markdown(f"**ğŸ¯ ì˜ˆìƒ íš¨ê³¼:** {strategy.get('expected_impact', 'N/A')}")
                
                # ì „ìˆ  ìƒì„¸ í‘œì‹œ
                tactics = strategy.get("tactics", [])
                if tactics:
                    st.markdown("**âš¡ ì£¼ìš” ì „ìˆ :**")
                    for tactic in tactics:
                        st.write(f"  â€¢ {tactic}")
                
                # ì±„ë„ ì •ë³´ (êµ¬ì²´ì ìœ¼ë¡œ í‘œì‹œ)
                channel = strategy.get("channel", "N/A")
                if channel != "N/A":
                    # StrategyGeneratorë¥¼ importí•˜ì—¬ ì±„ë„ ìƒì„¸ ì •ë³´ í™•ì¥
                    try:
                        import sys
                        from pathlib import Path
                        # agents_new ê²½ë¡œ ì¶”ê°€
                        agents_path = Path(__file__).parent.parent.parent / "agents_new"
                        if str(agents_path) not in sys.path:
                            sys.path.insert(0, str(agents_path))
                        
                        # Import StrategyGenerator (IDE ê²½ê³  ë¬´ì‹œ - ëŸ°íƒ€ì„ì— ì •ìƒ ì‘ë™)
                        from marketing_agent.strategy_generator import StrategyGenerator  # type: ignore
                        
                        # ì±„ë„ ìƒì„¸ ì •ë³´ í™•ì¥
                        sg = StrategyGenerator()
                        expanded = sg.expand_channel_details(channel)
                        
                        # ì˜¨ë¼ì¸ ì±„ë„
                        if expanded.get("online_channels"):
                            online_list = []
                            for ch in expanded["online_channels"]:
                                details = expanded["details"].get(ch, {})
                                if ch == "ì¸ìŠ¤íƒ€ê·¸ë¨":
                                    online_list.append("ì¸ìŠ¤íƒ€ê·¸ë¨ (ë¦´ìŠ¤/í”¼ë“œ/ìŠ¤í† ë¦¬)")
                                elif ch == "ë„¤ì´ë²„ì§€ë„":
                                    online_list.append("ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤/ì§€ë„")
                                elif ch == "ë„¤ì´ë²„í”Œë ˆì´ìŠ¤":
                                    online_list.append("ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤")
                                elif ch == "ì¹´ì¹´ì˜¤ë§µ":
                                    online_list.append("ì¹´ì¹´ì˜¤ë§µ/ì¹´ì¹´ì˜¤í†¡ ì±„ë„")
                                elif ch == "ë°°ë‹¬ì•±":
                                    online_list.append("ë°°ë‹¬ì•± (ë°°ë¯¼/ì¿ íŒ¡ì´ì¸ /ìš”ê¸°ìš”)")
                                else:
                                    online_list.append(ch)
                            st.markdown(f"**ğŸ“± ì˜¨ë¼ì¸:** {', '.join(online_list)}")
                        
                        # ì˜¤í”„ë¼ì¸ ì±„ë„
                        if expanded.get("offline_channels"):
                            offline_list = []
                            for ch in expanded["offline_channels"]:
                                details = expanded["details"].get(ch, {})
                                tactics = details.get("promotion_strategy", [])
                                if tactics:
                                    offline_list.append(f"{ch} ({', '.join(tactics[:3])})")
                                else:
                                    offline_list.append(ch)
                            st.markdown(f"**ğŸª ì˜¤í”„ë¼ì¸:** {', '.join(offline_list)}")
                        
                        # ì±„ë„ë³„ êµ¬ì²´ì ì¸ ì‹¤í–‰ ì „ëµ
                        with st.expander("ğŸ“‹ ì±„ë„ë³„ ì„¸ë¶€ ì‹¤í–‰ ì „ëµ", expanded=False):
                            for ch_name, ch_details in expanded["details"].items():
                                st.markdown(f"**{ch_name}**")
                                for key, value in ch_details.items():
                                    if isinstance(value, list):
                                        st.write(f"  â€¢ {key}: {', '.join(value)}")
                                    else:
                                        st.write(f"  â€¢ {key}: {value}")
                                st.markdown("")
                    except Exception as e:
                        # ì—ëŸ¬ ì‹œ ê¸°ë³¸ ì¶œë ¥
                        st.markdown(f"**ğŸ“± ë§ˆì¼€íŒ… ì±„ë„:** {channel}")
                        print(f"[WARNING] ì±„ë„ ìƒì„¸ ì •ë³´ í™•ì¥ ì‹¤íŒ¨: {e}")
                
                # êµ¬í˜„ ì •ë³´
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("â±ï¸ êµ¬í˜„ ê¸°ê°„", strategy.get('implementation_time', 'N/A'))
                with col2:
                    st.metric("ğŸ’° ì˜ˆì‚°", strategy.get('budget_estimate', 'N/A'))
                with col3:
                    st.metric("â­ ìš°ì„ ìˆœìœ„", f"{strategy.get('priority', 'N/A')}")
                
                # ì„±ê³µ ì§€í‘œ
                success_metrics = strategy.get("success_metrics", [])
                if success_metrics:
                    st.markdown("**ğŸ“Š ì„±ê³µ ì§€í‘œ:**")
                    for metric in success_metrics:
                        st.write(f"  âœ“ {metric}")
                
                st.markdown("---")
    
    # ìº í˜ì¸ ê³„íš
    campaign_plan = marketing_data.get("campaign_plan", {})
    if campaign_plan:
        st.markdown("#### ìº í˜ì¸ ê³„íš")
        st.write(f"**ìº í˜ì¸ëª…:** {campaign_plan.get('name', 'N/A')}")
        st.write(f"**ê¸°ê°„:** {campaign_plan.get('duration', 'N/A')}")
        
        expected_kpis = campaign_plan.get("expected_kpis", {})
        if expected_kpis:
            st.write("**ì˜ˆìƒ KPI:**")
            for kpi, value in expected_kpis.items():
                st.write(f"- {kpi}: {value}")

def display_new_product_recommendations(analysis_data):
    """ì‹ ë©”ë‰´ ì¶”ì²œ íƒ­ - New Product Agent ê²°ê³¼ í‘œì‹œ"""
    st.markdown("### ğŸ° ì‹ ë©”ë‰´ ì¶”ì²œ")
    
    new_product_data = analysis_data.get("new_product_result", {})
    if not new_product_data:
        st.info("ì‹ ë©”ë‰´ ì¶”ì²œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í™œì„±í™” ì—¬ë¶€ í™•ì¸
    if not new_product_data.get("activated", False):
        st.warning("ì‹ ë©”ë‰´ ì¶”ì²œì´ ë¹„í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤. (ì—…ì¢…ì´ í—ˆìš© ëª©ë¡ì— ì—†ìŒ)")
        return
    
    # ê¸°ë³¸ ì •ë³´
    st.markdown("#### ğŸ“Š ì‹ ë©”ë‰´ ì¶”ì²œ ê°œìš”")
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("í™œì„±í™” ìƒíƒœ", "âœ… í™œì„±í™”" if new_product_data.get("activated") else "âŒ ë¹„í™œì„±í™”")
    
    with col2:
        proposal_count = len(new_product_data.get("proposals", []))
        st.metric("ì œì•ˆ ë©”ë‰´ ìˆ˜", f"{proposal_count}ê°œ")
    
    with col3:
        used_categories = new_product_data.get("used_categories", [])
        st.metric("ì‚¬ìš©ëœ ì¹´í…Œê³ ë¦¬", f"{len(used_categories)}ê°œ")
    
    with col4:
        keywords_count = len(new_product_data.get("keywords_top", []))
        st.metric("ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ", f"{keywords_count}ê°œ")
    
    # íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤ ì •ë³´
    audience_filters = new_product_data.get("audience_filters", {})
    if audience_filters:
        st.markdown("#### ğŸ¯ íƒ€ê²Ÿ ì˜¤ë””ì–¸ìŠ¤")
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**ì£¼ìš” ì„±ë³„:** {audience_filters.get('gender', 'N/A')}")
            ages = audience_filters.get('ages', [])
            st.write(f"**ì£¼ìš” ì—°ë ¹ëŒ€:** {', '.join(ages) if ages else 'N/A'}")
        
        with col2:
            store_age = audience_filters.get('store_age', {})
            if store_age:
                st.write("**ì—°ë ¹ëŒ€ë³„ ë¹„ìœ¨:**")
                for age, ratio in store_age.items():
                    st.write(f"  - {age}: {ratio:.1f}%")
    
    # ì‚¬ìš©ëœ ì¹´í…Œê³ ë¦¬
    if used_categories:
        st.markdown("#### ğŸ“‚ ì‚¬ìš©ëœ ë°ì´í„°ë© ì¹´í…Œê³ ë¦¬")
        category_tags = " ".join([f"`{cat}`" for cat in used_categories])
        st.markdown(category_tags)
    
    # í‚¤ì›Œë“œ ìˆ˜ì§‘ ê²°ê³¼
    keywords_top = new_product_data.get("keywords_top", [])
    if keywords_top:
        st.markdown("#### ğŸ” ìˆ˜ì§‘ëœ í‚¤ì›Œë“œ (ìƒìœ„ 10ê°œ)")
        
        # ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
        categories = {}
        for keyword_data in keywords_top[:10]:
            category = keyword_data.get("category", "ê¸°íƒ€")
            if category not in categories:
                categories[category] = []
            categories[category].append(keyword_data)
        
        for category, keywords in categories.items():
            with st.expander(f"ğŸ“‚ {category} ({len(keywords)}ê°œ)"):
                for i, keyword_data in enumerate(keywords, 1):
                    keyword = keyword_data.get("keyword", "N/A")
                    rank = keyword_data.get("rank", "N/A")
                    st.write(f"{i}. **{keyword}** (ìˆœìœ„: {rank})")
    
    # ì¸ì‚¬ì´íŠ¸
    insight = new_product_data.get("insight", {})
    if insight:
        st.markdown("#### ğŸ’¡ ì¸ì‚¬ì´íŠ¸")
        col1, col2 = st.columns(2)
        
        with col1:
            st.write(f"**ì„±ë³„ ìš”ì•½:** {insight.get('gender_summary', 'N/A')}")
        
        with col2:
            st.write(f"**ì—°ë ¹ ìš”ì•½:** {insight.get('age_summary', 'N/A')}")
    
    # ì œì•ˆ ë©”ë‰´ë“¤
    proposals = new_product_data.get("proposals", [])
    if proposals:
        st.markdown("#### ğŸ½ï¸ ì œì•ˆ ë©”ë‰´")
        st.write(f"ì´ **{len(proposals)}ê°œ**ì˜ ì‹ ë©”ë‰´ê°€ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        for i, proposal in enumerate(proposals, 1):
            with st.expander(f"**{i}. {proposal.get('menu_name', 'N/A')}**", expanded=(i==1)):
                col1, col2 = st.columns(2)
                
                with col1:
                    st.write(f"**ì¹´í…Œê³ ë¦¬:** {proposal.get('category', 'N/A')}")
                    st.write(f"**íƒ€ê²Ÿ ì„±ë³„:** {proposal.get('target', {}).get('gender', 'N/A')}")
                    st.write(f"**íƒ€ê²Ÿ ì—°ë ¹:** {', '.join(proposal.get('target', {}).get('ages', []))}")
                
                with col2:
                    evidence = proposal.get('evidence', {})
                    st.write(f"**ì¦ê±° ì¹´í…Œê³ ë¦¬:** {evidence.get('category', 'N/A')}")
                    st.write(f"**ì¦ê±° í‚¤ì›Œë“œ:** {evidence.get('keyword', 'N/A')}")
                    st.write(f"**í‚¤ì›Œë“œ ìˆœìœ„:** {evidence.get('rank', 'N/A')}ìœ„")
                
                # ì œì•ˆë¬¸
                template_ko = proposal.get('template_ko', '')
                if template_ko:
                    st.markdown("**ğŸ“ ì œì•ˆ ê·¼ê±°:**")
                    st.write(template_ko)
                
                st.markdown("---")
    else:
        st.info("ì œì•ˆëœ ë©”ë‰´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # ìµœì¢… ê²°ê³¼ ìš”ì•½
    st.markdown("#### ğŸ“‹ ìµœì¢… ê²°ê³¼ ìš”ì•½")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"**ë§¤ì¥ì½”ë“œ:** {new_product_data.get('store_code', 'N/A')}")
        st.write(f"**í™œì„±í™” ì—¬ë¶€:** {'âœ… True' if new_product_data.get('activated') else 'âŒ False'}")
    
    with col2:
        st.write(f"**ì œì•ˆ ë©”ë‰´ ìˆ˜:** {len(proposals)}ê°œ")
        st.write(f"**ìˆ˜ì§‘ í‚¤ì›Œë“œ ìˆ˜:** {len(keywords_top)}ê°œ")

def display_visualizations(analysis_data):
    """ì‹œê°í™” íƒ­"""
    st.markdown("### ğŸ“Š ì‹œê°í™”")
    
    visualizations = analysis_data.get("visualizations", {})
    if not visualizations:
        st.info("ì‹œê°í™” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # Store ì°¨íŠ¸ë“¤
    store_charts = visualizations.get("store_charts", [])
    if store_charts:
        st.markdown("#### ğŸª ë§¤ì¥ ë¶„ì„ ì°¨íŠ¸")
        cols = st.columns(2)
        for i, chart_info in enumerate(store_charts[:6]):  # ìµœëŒ€ 6ê°œ í‘œì‹œ
            col_idx = i % 2
            with cols[col_idx]:
                chart_path = chart_info.get("path")
                chart_name = chart_info.get("name", f"Chart {i+1}")
                
                if chart_path and Path(chart_path).exists():
                    try:
                        st.image(chart_path, caption=chart_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name} - {e}")
                else:
                    # íŒŒì¼ ê²½ë¡œ ë””ë²„ê¹…
                    st.write(f"ì°¨íŠ¸ ì—†ìŒ: {chart_name}")
                    if chart_path:
                        st.write(f"ê²½ë¡œ: {chart_path}")
                        st.write(f"ì¡´ì¬ ì—¬ë¶€: {Path(chart_path).exists()}")
    
    # Mobility ì°¨íŠ¸ë“¤
    mobility_charts = visualizations.get("mobility_charts", [])
    if mobility_charts:
        st.markdown("#### ğŸš¶ ì´ë™ ë¶„ì„ ì°¨íŠ¸")
        cols = st.columns(2)
        for i, chart_info in enumerate(mobility_charts[:6]):  # ìµœëŒ€ 6ê°œ í‘œì‹œ
            col_idx = i % 2
            with cols[col_idx]:
                chart_path = chart_info.get("path")
                chart_name = chart_info.get("name", f"Chart {i+1}")
                
                if chart_path and Path(chart_path).exists():
                    try:
                        st.image(chart_path, caption=chart_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì°¨íŠ¸ ë¡œë”© ì‹¤íŒ¨: {chart_name} - {e}")
                else:
                    # íŒŒì¼ ê²½ë¡œ ë””ë²„ê¹…
                    st.write(f"ì°¨íŠ¸ ì—†ìŒ: {chart_name}")
                    if chart_path:
                        st.write(f"ê²½ë¡œ: {chart_path}")
                        st.write(f"ì¡´ì¬ ì—¬ë¶€: {Path(chart_path).exists()}")
    
    # Panorama ì´ë¯¸ì§€ë“¤
    panorama_images = visualizations.get("panorama_images", [])
    if panorama_images:
        st.markdown("#### ğŸ˜ï¸ íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì´ë¯¸ì§€")
        cols = st.columns(2)
        for i, img_info in enumerate(panorama_images[:4]):  # ìµœëŒ€ 4ê°œ í‘œì‹œ
            col_idx = i % 2
            with cols[col_idx]:
                img_path = img_info.get("path")
                img_name = img_info.get("name", f"Image {i+1}")
                
                if img_path and Path(img_path).exists():
                    try:
                        st.image(img_path, caption=img_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"ì´ë¯¸ì§€ ë¡œë”© ì‹¤íŒ¨: {img_name} - {e}")
                else:
                    # íŒŒì¼ ê²½ë¡œ ë””ë²„ê¹…
                    st.write(f"ì´ë¯¸ì§€ ì—†ìŒ: {img_name}")
                    if img_path:
                        st.write(f"ê²½ë¡œ: {img_path}")
                        st.write(f"ì¡´ì¬ ì—¬ë¶€: {Path(img_path).exists()}")
    
    # Spatial íŒŒì¼ë“¤
    spatial_files = visualizations.get("spatial_files", [])
    if spatial_files:
        st.markdown("#### ğŸ—ºï¸ ê³µê°„ ë¶„ì„")
        for file_info in spatial_files:
            file_path = file_info.get("path")
            file_name = file_info.get("name", "Unknown")
            file_type = file_info.get("type", "unknown")
            
            if file_path and Path(file_path).exists():
                if file_type == "spatial_chart" or file_type == "panorama_map":
                    try:
                        st.image(file_path, caption=file_name, use_column_width=True)
                    except Exception as e:
                        st.error(f"íŒŒì¼ ë¡œë”© ì‹¤íŒ¨: {file_name}")
                elif file_type == "spatial_map" or file_type == "panorama_map":
                    st.write(f"**{file_name}:** [ì§€ë„ íŒŒì¼]({file_path})")
                else:
                    st.write(f"**{file_name}:** {file_path}")
            else:
                st.write(f"íŒŒì¼ ì—†ìŒ: {file_name}")
    
    if not store_charts and not mobility_charts and not panorama_images and not spatial_files:
        st.info("í‘œì‹œí•  ì‹œê°í™” íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

def save_final_reports(store_code, md_content, json_content):
    """ìµœì¢… ë¦¬í¬íŠ¸ íŒŒì¼ ì €ì¥"""
    try:
        output_dir = Path(__file__).parent.parent / "output"
        output_dir.mkdir(parents=True, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_dir = output_dir / f"final_reports_{store_code}_{timestamp}"
        report_dir.mkdir(parents=True, exist_ok=True)
        
        # MD íŒŒì¼ ì €ì¥
        if md_content:
            md_file = report_dir / "final.md"
            with open(md_file, 'w', encoding='utf-8') as f:
                f.write(md_content)
            print(f"Final MD saved: {md_file}")
        
        # JSON íŒŒì¼ ì €ì¥
        if json_content:
            json_file = report_dir / "final.json"
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(json_content, f, ensure_ascii=False, indent=2)
            print(f"Final JSON saved: {json_file}")
        
        return str(report_dir)
        
    except Exception as e:
        print(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        return None

def merge_all_analysis_files(analysis_data):
    """ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ JSONê³¼ MDë¡œ í†µí•© (ìš”ì•½ì´ ì•„ë‹Œ ì›ë³¸ ë°ì´í„° ì „ë¶€)"""
    try:
        # í†µí•©ëœ ì „ì²´ ë°ì´í„°
        merged_data = {
            "store_code": analysis_data.get("store_code", "N/A"),
            "analysis_timestamp": datetime.now().isoformat(),
            "analysis_directory": analysis_data.get("analysis_dir", "N/A"),
            "store_analysis": analysis_data.get("store_analysis", {}),
            "marketing_analysis": analysis_data.get("marketing_analysis", {}),
            "marketplace_analysis": analysis_data.get("marketplace_analysis", {}),
            "panorama_analysis": analysis_data.get("panorama_analysis", {}),
            "mobility_analysis": analysis_data.get("mobility_analysis", {}),
            "comprehensive_analysis": analysis_data.get("comprehensive_analysis", {}),
            "visualizations": analysis_data.get("visualizations", {})
        }
        
        # ë¶„ì„ ë””ë ‰í† ë¦¬ì— í†µí•© íŒŒì¼ ì €ì¥
        if "analysis_dir" in analysis_data:
            analysis_dir = Path(analysis_data["analysis_dir"])
            
            # JSON íŒŒì¼ ì €ì¥
            merged_json_file = analysis_dir / "merged_analysis_full.json"
            with open(merged_json_file, 'w', encoding='utf-8') as f:
                json.dump(merged_data, f, ensure_ascii=False, indent=2)
            
            print(f"[OK] í†µí•© JSON íŒŒì¼ ì €ì¥: {merged_json_file}")
            print(f"[OK] í†µí•© ë°ì´í„° í¬ê¸°: {len(json.dumps(merged_data))} bytes")
            
            # MD íŒŒì¼ ìƒì„±
            merged_md_file = analysis_dir / "merged_analysis_full.md"
            md_content = generate_comprehensive_markdown(merged_data)
            
            with open(merged_md_file, 'w', encoding='utf-8') as f:
                f.write(md_content)
            
            print(f"[OK] í†µí•© MD íŒŒì¼ ì €ì¥: {merged_md_file}")
            
            return str(merged_json_file), str(merged_md_file)
        
        return None, None
        
    except Exception as e:
        print(f"[ERROR] í†µí•© íŒŒì¼ ìƒì„± ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None, None

def generate_comprehensive_markdown(merged_data):
    """í†µí•© ë¶„ì„ ë°ì´í„°ë¥¼ ë§ˆí¬ë‹¤ìš´ìœ¼ë¡œ ë³€í™˜"""
    store_code = merged_data.get("store_code", "N/A")
    timestamp = merged_data.get("analysis_timestamp", "N/A")
    
    md = f"""# ë§¤ì¥ ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ (ì „ì²´)

## ê¸°ë³¸ ì •ë³´
- ìƒì  ì½”ë“œ: {store_code}
- ë¶„ì„ ì¼ì‹œ: {timestamp}
- ë¶„ì„ ë””ë ‰í† ë¦¬: {merged_data.get('analysis_directory', 'N/A')}

---

"""
    
    # 1. Store ë¶„ì„
    store_analysis = merged_data.get("store_analysis", {})
    if store_analysis:
        md += f"""## 1. ë§¤ì¥ ë¶„ì„ (Store Analysis)

### ê¸°ë³¸ ì •ë³´
"""
        store_summary = store_analysis.get("store_summary", {})
        if store_summary:
            md += f"""- ë§¤ì¥ëª…: {store_summary.get('store_name', 'N/A')}
- ì—…ì¢…: {store_summary.get('industry', 'N/A')}
- ìƒê¶Œ: {store_summary.get('commercial_area', 'N/A')}
- í’ˆì§ˆ ì ìˆ˜: {store_summary.get('quality_score', 'N/A')}
- ì£¼ìš” ê³ ê°ì¸µ: {store_summary.get('main_customer', 'N/A')}
- ê³ ê° ìœ í˜•: {store_summary.get('customer_type', 'N/A')}

"""
    
    # 2. Marketing ë¶„ì„
    marketing_analysis = merged_data.get("marketing_analysis", {})
    if marketing_analysis:
        md += f"""## 2. ë§ˆì¼€íŒ… ë¶„ì„ (Marketing Analysis)

### í˜ë¥´ì†Œë‚˜ ì •ë³´
- í˜ë¥´ì†Œë‚˜ íƒ€ì…: {marketing_analysis.get('persona_type', 'N/A')}
- ë¦¬ìŠ¤í¬ ë ˆë²¨: {marketing_analysis.get('risk_level', 'N/A')}

### ë§ˆì¼€íŒ… ì „ëµ
"""
        strategies = marketing_analysis.get("strategies", [])
        for i, strategy in enumerate(strategies, 1):
            md += f"""
#### ì „ëµ {i}: {strategy.get('title', 'N/A')}
- ì„¤ëª…: {strategy.get('description', 'N/A')}
- íƒ€ê²Ÿ: {strategy.get('target', 'N/A')}
- ì˜ˆìƒ íš¨ê³¼: {strategy.get('expected_impact', 'N/A')}
"""
        
        md += "\n### ë§ˆì¼€íŒ… ìº í˜ì¸\n"
        campaigns = marketing_analysis.get("campaigns", [])
        for i, campaign in enumerate(campaigns, 1):
            md += f"""
#### ìº í˜ì¸ {i}: {campaign.get('name', 'N/A')}
- ì„¤ëª…: {campaign.get('description', 'N/A')}
- ì±„ë„: {campaign.get('channels', 'N/A')}
- ì˜ˆì‚°: {campaign.get('budget', 'N/A')}
"""
    
    # 3. Marketplace ë¶„ì„
    marketplace_analysis = merged_data.get("marketplace_analysis", {})
    if marketplace_analysis:
        md += f"""## 3. ìƒê¶Œ ë¶„ì„ (Marketplace Analysis)

### ê¸°ë³¸ ì •ë³´
- ìƒê¶Œëª…: {marketplace_analysis.get('ìƒê¶Œëª…', 'N/A')}
- ë¶„ì„ì¼ì‹œ: {marketplace_analysis.get('ë¶„ì„ì¼ì‹œ', 'N/A')}

### ìƒê¶Œ ë°ì´í„°
"""
        data_section = marketplace_analysis.get("ë°ì´í„°", [])
        for item in data_section:
            if item.get("ìœ í˜•") == "ì¢…í•©ì˜ê²¬":
                area_info = item.get("ë©´ì ", {})
                if area_info:
                    md += f"- ë¶„ì„ ë©´ì : {area_info.get('ë¶„ì„', 'N/A')}ã¡\n"
                
                store_count = item.get("ì í¬ìˆ˜", {})
                if store_count:
                    current = store_count.get("í˜„ì¬", {})
                    md += f"- í˜„ì¬ ì í¬ìˆ˜: {current.get('ê°’', 'N/A')}ê°œ ({current.get('ê¸°ì¤€', 'N/A')})\n"
                    
                    quarter_change = store_count.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                    if quarter_change:
                        md += f"- ì „ë¶„ê¸° ëŒ€ë¹„: {quarter_change.get('ë³€í™”', 'N/A')}ê°œ\n"
                    
                    year_change = store_count.get("ì „ë…„ë™ë¶„ê¸°ëŒ€ë¹„", {})
                    if year_change:
                        md += f"- ì „ë…„ ë™ë¶„ê¸° ëŒ€ë¹„: {year_change.get('ë³€í™”', 'N/A')}ê°œ\n"
                
                sales_info = item.get("ë§¤ì¶œì•¡", {})
                if sales_info:
                    current_sales = sales_info.get("í˜„ì¬", {})
                    md += f"- í˜„ì¬ ë§¤ì¶œì•¡: {current_sales.get('ê°’', 'N/A')}ë§Œì› ({current_sales.get('ê¸°ì¤€', 'N/A')})\n"
                    
                    quarter_sales = sales_info.get("ì „ë¶„ê¸°ëŒ€ë¹„", {})
                    if quarter_sales:
                        md += f"- ì „ë¶„ê¸° ëŒ€ë¹„: {quarter_sales.get('ë³€í™”', 'N/A')}ë§Œì›\n"
                
                break
    
    # 4. Panorama ë¶„ì„
    panorama_analysis = merged_data.get("panorama_analysis", {})
    if panorama_analysis:
        md += f"""
## 4. íŒŒë…¸ë¼ë§ˆ ë¶„ì„ (Panorama Analysis)

### ìœ„ì¹˜ ì •ë³´
- ì£¼ì†Œ: {panorama_analysis.get('address', 'N/A')}
- ì¢Œí‘œ: {panorama_analysis.get('coordinates', 'N/A')}
- í–‰ì •ë™: {panorama_analysis.get('administrative_dong', 'N/A')}
- ìƒê¶Œ: {panorama_analysis.get('marketplace', 'N/A')}

"""
    
    # 5. Mobility ë¶„ì„
    mobility_analysis = merged_data.get("mobility_analysis", {})
    if mobility_analysis:
        md += f"""## 5. ì´ë™ íŒ¨í„´ ë¶„ì„ (Mobility Analysis)

### ì´ë™ ë°ì´í„°
- ë°ì´í„° í¬í•¨: {len(mobility_analysis)} í•­ëª©

"""
    
    # 6. Comprehensive ë¶„ì„
    comprehensive_analysis = merged_data.get("comprehensive_analysis", {})
    if comprehensive_analysis:
        md += f"""## 6. ì¢…í•© ë¶„ì„ (Comprehensive Analysis)

{json.dumps(comprehensive_analysis, ensure_ascii=False, indent=2)}

"""
    
    # 7. ì‹œê°í™” ì •ë³´
    visualizations = merged_data.get("visualizations", {})
    if visualizations:
        md += f"""## 7. ì‹œê°í™” íŒŒì¼ ëª©ë¡

"""
        for viz_type, files in visualizations.items():
            md += f"### {viz_type}\n"
            for file_info in files:
                md += f"- {file_info.get('name', 'N/A')}: {file_info.get('path', 'N/A')}\n"
    
    md += f"""
---

## ë¶„ì„ ì™„ë£Œ
ì´ ë¦¬í¬íŠ¸ëŠ” ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©í•œ ì „ì²´ ë°ì´í„°ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
ìƒë‹´ ëª¨ë“œì—ì„œ ì´ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
"""
    
    return md

# ì‚¬ì´ë“œë°”: ë¶„ì„ ì§„í–‰ ìƒí™© í‘œì‹œ
with st.sidebar:
    st.markdown("## ğŸ“Š ë¶„ì„ ì§„í–‰ ìƒí™©")
    
    # ë¶„ì„ ìƒíƒœ í‘œì‹œ
    if st.session_state.get('is_analyzing', False):
        st.info("ğŸ”„ ë¶„ì„ ì§„í–‰ ì¤‘...")
        
        # ì§„í–‰ ë‹¨ê³„ í‘œì‹œ (ì ‘ì„ ìˆ˜ ìˆëŠ” í˜•íƒœ)
        with st.expander("ğŸ“‹ í˜„ì¬ ì§„í–‰ ë‹¨ê³„", expanded=True):
            progress = st.session_state.get('analysis_progress', {})
            
            steps = [
                ("ì£¼ì†Œ ì •ë³´ ë¶„ì„", "address"),
                ("Store Agent ë¶„ì„", "store"),
                ("Marketing ë¶„ì„", "marketing"),
                ("Mobility ë¶„ì„", "mobility"),
                ("Panorama ë¶„ì„", "panorama"),
                ("Marketplace ë¶„ì„", "marketplace"),
                ("ê²°ê³¼ í†µí•©", "integration")
            ]
            
            for i, (step_name, step_key) in enumerate(steps, 1):
                status = progress.get(step_key, "waiting")
                
                if status == "completed":
                    st.write(f"{i}. âœ… {step_name}")
                elif status == "in_progress":
                    st.write(f"{i}. ğŸ”„ {step_name} ì¤‘...")
                else:
                    st.write(f"{i}. â³ {step_name} ëŒ€ê¸°")
            
    elif st.session_state.get('analysis_complete', False):
        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
        
        # ì™„ë£Œëœ ë¶„ì„ ì •ë³´
        with st.expander("ğŸ“‹ ë¶„ì„ ê²°ê³¼ ìš”ì•½", expanded=True):
            store_code = st.session_state.get('store_code', 'N/A')
            st.write(f"**ìƒì  ì½”ë“œ:** {store_code}")
            st.write("**ë¶„ì„ ì™„ë£Œ ì‹œê°„:** ë°©ê¸ˆ ì „")
            st.write("**ë¶„ì„ í•­ëª©:** 5ì°¨ì› ì¢…í•© ë¶„ì„")
            st.write("**ìƒíƒœ:** ëª¨ë“  ë¶„ì„ ì™„ë£Œ")
            
    else:
        st.info("â³ ëŒ€ê¸° ì¤‘...")
        
        # ëŒ€ê¸° ìƒíƒœ ì•ˆë‚´
        with st.expander("ğŸ“‹ ì‚¬ìš© ë°©ë²•", expanded=True):
            st.write("1. ìƒì  ì½”ë“œ ì…ë ¥")
            st.write("2. ë¶„ì„ ì‹œì‘")
            st.write("3. ê²°ê³¼ í™•ì¸")
            st.write("4. ìƒë‹´ ì‹œì‘")
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
        st.rerun()

# ë©”ì¸ 2íŒ¨ë„ ë ˆì´ì•„ì›ƒ
col1, col2 = st.columns([1, 1])

# ì™¼ìª½ íŒ¨ë„: ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
with col1:
    st.markdown("## BigContest AI Agent - 1:1 ë¹„ë°€ ìƒë‹´ ì„œë¹„ìŠ¤")
    
    # ì´ˆê¸° í™˜ì˜ ë©”ì‹œì§€
    if not st.session_state.messages:
        st.session_state.messages = [{
            "role": "assistant", 
            "content": "ì•ˆë…•í•˜ì„¸ìš”! ë¹„ë°€ ìƒë‹´ì‚¬ AI ì‹œìŠ¤í…œì…ë‹ˆë‹¤. 10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì‹œë©´ ì¢…í•© ë¶„ì„ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤. (ì˜ˆ: 000F03E44A, 002816BA73)"
        }]
    
    # ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.write(message["content"])
    
    # ë¶„ì„ ì¤‘ì¼ ë•Œ ë¡œë”© í‘œì‹œ
    if st.session_state.is_analyzing:
        with st.chat_message("assistant"):
            st.markdown("ğŸ”„ 5ì°¨ì› ì¢…í•© ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ì•½ 3-5ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤.")
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # Query Classifierë¡œ ì˜ë„ íŒŒì•…
        if AGENTS_AVAILABLE:
            query_result = classify_query_sync(prompt)
            intent = query_result.get("intent", "general_consultation")
            detected_store_code = query_result.get("store_code")
            
            # 1. ìƒì  ì½”ë“œ ì¿¼ë¦¬
            if intent == "store_code_query" and detected_store_code and not st.session_state.analysis_complete:
                store_code = detected_store_code
                st.session_state.store_code = store_code
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸
                print(f"[DEBUG] ìƒì  ì½”ë“œ {store_code}ì— ëŒ€í•œ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸ ì¤‘...")
                existing_analysis = load_analysis_data_from_output(store_code)
                print(f"[DEBUG] ê¸°ì¡´ ë¶„ì„ ê²°ê³¼: {existing_analysis is not None}")
                
                if existing_analysis:
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"âœ… ìƒì  ì½”ë“œ {store_code}ì˜ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤! ë°”ë¡œ í‘œì‹œí•˜ê² ìŠµë‹ˆë‹¤."
                    })
                    st.session_state.analysis_data = existing_analysis
                    st.session_state.analysis_complete = True
                    st.session_state.is_analyzing = False
                    
                    # ê¸°ì¡´ ë¶„ì„ë„ í†µí•© íŒŒì¼ ìƒì„± (JSON + MD)
                    merged_json, merged_md = merge_all_analysis_files(existing_analysis)
                    if merged_json and merged_md:
                        print(f"[OK] ê¸°ì¡´ ë¶„ì„ í†µí•© íŒŒì¼ ìƒì„±ë¨: JSON={merged_json}, MD={merged_md}")
                    
                    # ë¶„ì„ ë°ì´í„° ë¡œë“œ ì„±ê³µ ë¡œê·¸
                    print(f"[OK] ê¸°ì¡´ ë¶„ì„ ë°ì´í„° ë¡œë“œ ì„±ê³µ: {len(existing_analysis)} ì„¹ì…˜")
                    
                    st.rerun()
                else:
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤... 5ì°¨ì› ì¢…í•© ë¶„ì„ì„ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤. ì•½ 3-5ë¶„ ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤."
                    })
                    st.session_state.is_analyzing = True
                    st.rerun()
            
            # 2. ì¬ì‹œì‘ ìš”ì²­
            elif intent == "restart_analysis":
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": "ìƒˆë¡œìš´ ë¶„ì„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ? 10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
                })
                # ìƒíƒœ ì´ˆê¸°í™”
                st.session_state.analysis_complete = False
                st.session_state.consultation_mode = False
                st.session_state.consultation_chain = None
                st.session_state.consultation_memory = None
                st.rerun()
            
            # 3. ì¼ë°˜ ìƒë‹´ (Consultation ëª¨ë“œ)
            elif st.session_state.consultation_mode and st.session_state.consultation_chain:
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                with st.spinner("ìƒë‹´ì‚¬ê°€ ë‹µë³€ì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤..."):
                    try:
                        print(f"[INFO] ìƒë‹´ ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘: {prompt[:50]}...")
                        response = chat_with_consultant(
                            st.session_state.consultation_chain,
                            st.session_state.consultation_memory,
                            prompt
                        )
                        print(f"[SUCCESS] ìƒë‹´ ë‹µë³€ ìƒì„± ì™„ë£Œ")
                        st.session_state.messages.append({"role": "assistant", "content": response})
                    except Exception as e:
                        print(f"[ERROR] ìƒë‹´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        st.session_state.messages.append({
                            "role": "assistant",
                            "content": f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
                        })
                st.rerun()
            
            # 4. ë¶„ì„ ì™„ë£Œ í›„ ìƒë‹´ ì‹œì‘ ìœ ë„
            elif st.session_state.analysis_complete:
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "ìƒë‹´ ëª¨ë“œë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ 'ğŸ’¬ ìƒë‹´ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”. AI ìƒë‹´ì‚¬ê°€ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•´ë“œë¦½ë‹ˆë‹¤."
                })
                st.rerun()
            
            # 5. ê¸°ë³¸ (ìƒì  ì½”ë“œ ì…ë ¥ ìœ ë„)
            else:
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 000F03E44A, 002816BA73)"
                })
                st.rerun()
        
        else:
            # Agents ë¯¸ì‚¬ìš© ì‹œ ê°„ë‹¨í•œ ì •ê·œì‹ ë§¤ì¹­
            import re
            store_code_match = re.search(r'[A-Z0-9]{10}', prompt)
            
            if store_code_match and not st.session_state.analysis_complete:
                store_code = store_code_match.group()
                st.session_state.store_code = store_code
                st.session_state.messages.append({"role": "user", "content": prompt})
                
                log_capture.add_log(f"ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ í™•ì¸ ì¤‘: {store_code}", "INFO")
                existing_analysis = load_analysis_data_from_output(store_code)
                
                if existing_analysis:
                    log_capture.add_log(f"ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ë°œê²¬: {store_code}", "SUCCESS")
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"âœ… ìƒì  ì½”ë“œ {store_code}ì˜ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤!"
                    })
                    st.session_state.analysis_data = existing_analysis
                    st.session_state.analysis_complete = True
                    st.session_state.is_analyzing = False
                    st.rerun()
                else:
                    log_capture.add_log(f"ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì—†ìŒ, ìƒˆ ë¶„ì„ ì‹œì‘: {store_code}", "INFO")
                    st.session_state.messages.append({
                        "role": "assistant", 
                        "content": "ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
                    })
                    st.session_state.is_analyzing = True
                    st.rerun()
            else:
                st.session_state.messages.append({"role": "user", "content": prompt})
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": "10ìë¦¬ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”. (ì˜ˆ: 000F03E44A)"
                })
                st.rerun()

# ì˜¤ë¥¸ìª½ íŒ¨ë„: ë¶„ì„ ê²°ê³¼ ëŒ€ì‹œë³´ë“œ
with col2:
    st.markdown("## ë¶„ì„ ê²°ê³¼")
    
    # ë¶„ì„ ì§„í–‰ ì¤‘
    if st.session_state.is_analyzing and not st.session_state.analysis_complete:
        st.info("ğŸ”„ ë¶„ì„ ì§„í–‰ ì¤‘...")
        
        # ì‹¤ì œ ë¶„ì„ ì‹¤í–‰
        try:
            log_capture.add_log(f"ë¶„ì„ ì‹œì‘: {st.session_state.store_code}", "INFO")
            log_capture.add_log("5ì°¨ì› ì¢…í•© ë¶„ì„ ì§„í–‰ ì¤‘...", "INFO")
            
            # ë¶„ì„ ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
            st.session_state.analysis_progress = {}
            
            # ë¶„ì„ ì‹¤í–‰
            result = asyncio.run(run_full_analysis_pipeline(st.session_state.store_code))
            
            # Marketing Agent ì‹¤í–‰ (app.pyì—ì„œ ì§ì ‘)
            marketing_result = None
            if result and result.get("status") == "success" and MARKETING_AGENT_AVAILABLE:
                try:
                    log_capture.add_log("Marketing Agent ë¶„ì„ ì‹œì‘...", "INFO")
                    
                    # Store analysisì—ì„œ marketing formatìœ¼ë¡œ ë³€í™˜
                    store_analysis = result.get("store_analysis")
                    if store_analysis:
                        store_report = convert_store_to_marketing_format(store_analysis)
                        
                        if store_report:
                            # Marketing Agent ì‹¤í–‰
                            store_code = st.session_state.store_code
                            agent = marketingagent(store_code)
                            
                            diagnostic = {
                                "overall_risk_level": "MEDIUM",
                                "detected_risks": [],
                                "diagnostic_results": {}
                            }
                            
                            marketing_result = asyncio.run(agent.run_marketing(store_report, diagnostic))
                            
                            if marketing_result and not marketing_result.get("error"):
                                # Enumì„ ë¬¸ìì—´ë¡œ ë³€í™˜
                                marketing_result = _convert_enums_to_strings(marketing_result)
                                
                                # resultì— ì¶”ê°€
                                result["marketing_result"] = marketing_result
                                
                                log_capture.add_log("Marketing Agent ì™„ë£Œ!", "SUCCESS")
                            else:
                                log_capture.add_log("Marketing Agent ì‹¤íŒ¨", "WARN")
                except Exception as e:
                    log_capture.add_log(f"Marketing Agent ì˜¤ë¥˜: {str(e)}", "ERROR")
                    import traceback
                    traceback.print_exc()
            
            # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ ë¡œë“œ
            if result and result.get("status") == "success":
                log_capture.add_log(f"ë¶„ì„ ì™„ë£Œ: {st.session_state.store_code}", "SUCCESS")
                st.session_state.is_analyzing = False
                st.session_state.analysis_complete = True
                
                # ì‹¤ì œ output í´ë”ì—ì„œ ìµœì‹  ê²°ê³¼ ë¡œë“œ
                analysis_data = load_analysis_data_from_output(st.session_state.store_code)
                if analysis_data:
                    st.session_state.analysis_data = analysis_data
                    log_capture.add_log("ë¶„ì„ ë°ì´í„° ë¡œë“œ ì„±ê³µ", "OK")
                else:
                    st.session_state.analysis_data = result
                    log_capture.add_log("ê¸°ë³¸ ë¶„ì„ ë°ì´í„° ì‚¬ìš©", "WARN")
                
                # ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ íŒŒì¼ë¡œ í†µí•© (JSON + MD)
                log_capture.add_log("ë¶„ì„ ê²°ê³¼ í†µí•© ì¤‘...", "INFO")
                merged_json, merged_md = merge_all_analysis_files(st.session_state.analysis_data)
                if merged_json and merged_md:
                    log_capture.add_log(f"í†µí•© ë¶„ì„ íŒŒì¼ ìƒì„±ë¨: JSON={merged_json}, MD={merged_md}", "OK")
                
                # ì™„ë£Œ ë©”ì‹œì§€ ì¶”ê°€
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": "ë¶„ì„ ì™„ë£Œ! ìš°ì¸¡ íŒ¨ë„ì—ì„œ ìƒì„¸ ë¶„ì„ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¶ê¸ˆí•˜ì‹  ì ì´ ìˆìœ¼ì‹œë©´ ì–¸ì œë“  ì§ˆë¬¸í•´ì£¼ì„¸ìš”!"
                })
                
                # ë¶„ì„ ì™„ë£Œ í›„ ì¦‰ì‹œ ê²°ê³¼ í‘œì‹œ
                st.success("âœ… ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                st.rerun()
                
                # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼ í‘œì‹œ
                if st.button("ğŸ“‹ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± (Gemini)", type="primary"):
                    with st.spinner("Geminië¡œ ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ ìƒì„± ì¤‘..."):
                        md_content, json_content = generate_final_report_with_gemini(result)
                        if md_content:
                            report_dir = save_final_reports(st.session_state.store_code, md_content, json_content)
                            if report_dir:
                                st.success(f"ìµœì¢… ë¦¬í¬íŠ¸ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {report_dir}")
                                st.session_state.final_report_generated = True
                                st.rerun()
                        else:
                            st.error("ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                
                st.rerun()
            else:
                log_capture.add_log(f"ë¶„ì„ ì‹¤íŒ¨: {st.session_state.store_code}", "ERROR")
                st.error("ë¶„ì„ ì‹¤íŒ¨")
                st.session_state.is_analyzing = False
                st.rerun()
                
        except Exception as e:
            log_capture.add_log(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}", "ERROR")
            st.error(f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}")
            st.session_state.is_analyzing = False
            st.rerun()
    
    # ë¶„ì„ ì™„ë£Œ í›„ ê²°ê³¼ í‘œì‹œ
    elif st.session_state.analysis_complete and st.session_state.analysis_data:
        # session_stateì— ì €ì¥ëœ ë¶„ì„ ë°ì´í„° ì‚¬ìš©
        store_code = st.session_state.store_code
        analysis_data = st.session_state.analysis_data
        
        if not analysis_data:
            st.error("ë¶„ì„ ë°ì´í„°ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.success(f"âœ… ë¶„ì„ ì™„ë£Œ! ({analysis_data.get('timestamp', 'N/A')})")
            
            # ê¸°ë³¸ ì •ë³´ í‘œì‹œ
            display_basic_info(analysis_data)
            
            # ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ë²„íŠ¼
            display_final_report_button(store_code, analysis_data)
            
            # ìƒë‹´ ì‹œì‘ ë²„íŠ¼
            st.markdown("---")
            if not st.session_state.consultation_mode:
                if st.button("ğŸ’¬ ìƒë‹´ ì‹œì‘", type="primary", use_container_width=True):
                    print(f"[INFO] ìƒë‹´ ëª¨ë“œ ì‹œì‘ ìš”ì²­: {store_code}")
                    if AGENTS_AVAILABLE:
                        print(f"[INFO] Langchain AI Agents ì‚¬ìš©í•˜ì—¬ ìƒë‹´ ì‹œìŠ¤í…œ ì¤€ë¹„ ì¤‘...")
                        with st.spinner("ìƒë‹´ ì‹œìŠ¤í…œì„ ì¤€ë¹„ì¤‘ì…ë‹ˆë‹¤..."):
                            try:
                                # í†µí•© ë¶„ì„ íŒŒì¼ ë¡œë“œ
                                log_capture.add_log("í†µí•© ë¶„ì„ íŒŒì¼ ë¡œë“œ ì¤‘...", "INFO")
                                merged_data, merged_md = load_merged_analysis(analysis_data["analysis_dir"])
                                
                                if merged_data and merged_md:
                                    log_capture.add_log("í†µí•© íŒŒì¼ ë¡œë“œ ì™„ë£Œ", "OK")
                                    log_capture.add_log(f"Analysis Dir: {analysis_data['analysis_dir']}", "DEBUG")
                                    log_capture.add_log(f"MD íŒŒì¼ í¬ê¸°: {len(merged_md)} bytes", "DEBUG")
                                    
                                    # ===== 1ë‹¨ê³„: MCP ë§¤ì¥ ê²€ìƒ‰ ë¨¼ì € ì‹¤í–‰ =====
                                    print("\n" + "="*60)
                                    print("[1/2] MCP ë§¤ì¥ ê²€ìƒ‰ ë¨¼ì € ì‹¤í–‰!")
                                    print("="*60)
                                    try:
                                        log_capture.add_log(f"[1/2] MCP ë§¤ì¥ ê²€ìƒ‰ ì‹œì‘: {store_code}", "INFO")
                                        print(f"ğŸ” MCP ê²€ìƒ‰ ì¤‘: {store_code}")
                                        
                                        # StoreSearchProcessor import (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
                                        import sys
                                        import importlib.util
                                        processor_path = Path(__file__).parent / "utils" / "store_search_processor.py"
                                        spec = importlib.util.spec_from_file_location("store_search_processor", processor_path)
                                        processor_module = importlib.util.module_from_spec(spec)
                                        spec.loader.exec_module(processor_module)
                                        StoreSearchProcessor = processor_module.StoreSearchProcessor
                                        
                                        csv_path = Path(__file__).parent.parent.parent / "data" / "matched_store_results.csv"
                                        
                                        if csv_path.exists():
                                            processor = StoreSearchProcessor(csv_path=str(csv_path))
                                            mcp_result = processor.search_and_save_store(store_code)
                                            
                                            if mcp_result.get("success"):
                                                output_file = mcp_result.get("file", "")
                                                print(f"âœ… MCP ê²€ìƒ‰ ì„±ê³µ! ì €ì¥: {output_file}")
                                                log_capture.add_log(f"âœ… MCP ë§¤ì¥ ê²€ìƒ‰ ì„±ê³µ: {output_file}", "SUCCESS")
                                                analysis_data["mcp_search_result"] = mcp_result
                                            else:
                                                error_msg = mcp_result.get("error", "Unknown error")
                                                log_capture.add_log(f"âš ï¸ MCP ê²€ìƒ‰ ì‹¤íŒ¨: {error_msg}", "WARNING")
                                                analysis_data["mcp_search_result"] = {"success": False, "error": error_msg}
                                        else:
                                            log_capture.add_log(f"âš ï¸ MCP CSV íŒŒì¼ ì—†ìŒ: {csv_path}", "WARNING")
                                    except Exception as e:
                                        log_capture.add_log(f"âŒ MCP ë§¤ì¥ ê²€ìƒ‰ ì˜¤ë¥˜: {e}", "ERROR")
                                        import traceback
                                        traceback.print_exc()
                                    
                                    # ===== 2ë‹¨ê³„: New Product Agent ì‹¤í–‰ (í¬ë¡¤ë§) =====
                                    print("\n" + "="*60)
                                    print("[2/2] New Product Agent ì‹¤í–‰ (ë„¤ì´ë²„ í¬ë¡¤ë§)")
                                    print("="*60)
                                    # New Product Agent ì‹¤í–‰ (Store ë¶„ì„ ê²°ê³¼ê°€ ìˆì„ ë•Œë§Œ)
                                    if analysis_data.get("store_analysis"):
                                        try:
                                            log_capture.add_log("[2/2] New Product Agent ì‹¤í–‰ ì¤‘ (ë„¤ì´ë²„ í¬ë¡¤ë§)...", "INFO")
                                            
                                            # New Product Agent import ë° ì‹¤í–‰
                                            import sys
                                            from pathlib import Path
                                            project_root = Path(__file__).parent.parent.parent
                                            sys.path.insert(0, str(project_root))
                                            
                                            from agents_new.new_product_agent import NewProductAgent
                                            
                                            # New Product Agent ì‹¤í–‰
                                            agent = NewProductAgent(headless=True, save_outputs=True)
                                            
                                            # ì´ë²¤íŠ¸ ë£¨í”„ ì²˜ë¦¬ (íƒ€ì„ì•„ì›ƒ ì ìš©)
                                            new_product_result = None
                                            
                                            # ìƒˆ ì´ë²¤íŠ¸ ë£¨í”„ë¥¼ ë§Œë“¤ì–´ì„œ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰
                                            loop = asyncio.new_event_loop()
                                            asyncio.set_event_loop(loop)
                                            
                                            try:
                                                # íƒ€ì„ì•„ì›ƒ ì—†ì´ ì‹¤í–‰
                                                new_product_result = loop.run_until_complete(agent.run(analysis_data["store_analysis"]))
                                                log_capture.add_log("âœ… New Product Agent ì™„ë£Œ", "SUCCESS")
                                            except Exception as e:
                                                log_capture.add_log(f"New Product Agent ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {e}", "ERROR")
                                                new_product_result = {"activated": False, "error": str(e)}
                                            finally:
                                                try:
                                                    loop.close()
                                                except:
                                                    pass
                                            
                                            if new_product_result:
                                                analysis_data["new_product_result"] = new_product_result
                                                if new_product_result.get("activated"):
                                                    log_capture.add_log(f"New Product Agent - {len(new_product_result.get('proposals', []))}ê°œ ì œì•ˆ", "SUCCESS")
                                                else:
                                                    log_capture.add_log(f"New Product Agent ë¹„í™œì„±í™”: {new_product_result.get('reason', 'N/A')}", "INFO")
                                            else:
                                                log_capture.add_log("New Product Agent ê²°ê³¼ ì—†ìŒ", "WARN")
                                            
                                        except Exception as e:
                                            log_capture.add_log(f"âŒ New Product Agent ì‹¤í–‰ ì‹¤íŒ¨: {e}", "ERROR")
                                            analysis_data["new_product_result"] = {"activated": False, "error": str(e)}
                                            import traceback
                                            traceback.print_exc()
                                    else:
                                        log_capture.add_log("Store ë¶„ì„ ê²°ê³¼ ì—†ìŒ - New Product Agent ê±´ë„ˆëœ€", "INFO")
                                    
                                    # ===== 3ë‹¨ê³„: Langchain Consultation Chain ìƒì„± =====
                                    # Langchain Consultation Chain ìƒì„±
                                    log_capture.add_log("Langchain Consultation Chain ìƒì„± ì¤‘...", "INFO")
                                    
                                    # MCP ê²€ìƒ‰ ê²°ê³¼ txt íŒŒì¼ ì½ê¸° (ìˆìœ¼ë©´)
                                    mcp_content = ""
                                    if "mcp_search_result" in analysis_data and analysis_data["mcp_search_result"].get("success"):
                                        mcp_file = analysis_data["mcp_search_result"].get("file")
                                        if mcp_file and Path(mcp_file).exists():
                                            try:
                                                with open(mcp_file, 'r', encoding='utf-8') as f:
                                                    mcp_content = f.read()
                                                log_capture.add_log(f"MCP ê²€ìƒ‰ ê²°ê³¼ ë¡œë“œ ì™„ë£Œ: {len(mcp_content)} bytes", "DEBUG")
                                            except Exception as e:
                                                log_capture.add_log(f"MCP íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}", "WARNING")
                                    
                                    chain, memory = create_consultation_chain(store_code, merged_data, merged_md, mcp_content)
                                    
                                    if chain and memory:
                                        log_capture.add_log("ìƒë‹´ ì²´ì¸ ìƒì„± ì™„ë£Œ", "SUCCESS")
                                        st.session_state.consultation_chain = chain
                                        st.session_state.consultation_memory = memory
                                        st.session_state.merged_data = merged_data
                                        st.session_state.merged_md = merged_md
                                        st.session_state.consultation_mode = True
                                        
                                        st.session_state.messages.append({
                                            "role": "assistant",
                                            "content": "ìƒë‹´ì„ ì‹œì‘í•©ë‹ˆë‹¤! í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”. ğŸ“Š"
                                        })
                                        st.success("âœ… ìƒë‹´ ëª¨ë“œê°€ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")
                                        st.rerun()
                                    else:
                                        log_capture.add_log("ìƒë‹´ ì²´ì¸ ìƒì„± ì‹¤íŒ¨", "ERROR")
                                        st.error("ìƒë‹´ ì²´ì¸ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                                else:
                                    log_capture.add_log("í†µí•© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", "ERROR")
                                    st.error(f"í†µí•© íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                            except Exception as e:
                                log_capture.add_log(f"ìƒë‹´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", "ERROR")
                                st.error(f"ìƒë‹´ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                                import traceback
                                traceback.print_exc()
                    else:
                        log_capture.add_log("AI Agentsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.", "WARN")
                        st.warning("AI Agentsê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë“œë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")
            else:
                st.info("âœ… ìƒë‹´ ëª¨ë“œ í™œì„±í™”ë¨ - ììœ ë¡­ê²Œ ì§ˆë¬¸í•˜ì„¸ìš”!")
            
            # ëŒ€í™” ì´ˆê¸°í™” ë²„íŠ¼ ì¶”ê°€
            col1, col2, col3 = st.columns([1, 1, 1])
            with col2:
                if st.button("ğŸ”„ ëŒ€í™” ì´ˆê¸°í™”", type="secondary", help="ìƒˆë¡œìš´ ìƒì  ì½”ë“œë¡œ ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤"):
                    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
                    for key in list(st.session_state.keys()):
                        if key not in ["log_data", "analysis_progress"]:
                            del st.session_state[key]
                    st.rerun()
            
            # íƒ­ìœ¼ë¡œ ìƒì„¸ ê²°ê³¼ í‘œì‹œ (ì‹œê°í™” íƒ­ ì œê±°)
            tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
                "ê°œìš”", "ê³ ê° ë¶„ì„", "ì´ë™ íŒ¨í„´", "ì§€ì—­ ë¶„ì„", "ìƒê¶Œ ë¶„ì„", "ë§ˆì¼€íŒ…", "ì‹ ë©”ë‰´ ì¶”ì²œ"
            ])
            
            with tab1:
                display_store_overview(analysis_data)
            
            with tab2:
                display_customer_analysis(analysis_data)
            
            with tab3:
                display_mobility_analysis(analysis_data)
            
            with tab4:
                display_panorama_analysis(analysis_data)
            
            with tab5:
                display_marketplace_analysis(analysis_data)
            
            with tab6:
                display_marketing_analysis(analysis_data)
            
            with tab7:
                display_new_product_recommendations(analysis_data)
    
    else:
        # ì´ˆê¸° ìƒíƒœ
        st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ìƒì  ì½”ë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”!")
        
        # ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ìƒì  ì½”ë“œë“¤ì„ ë™ì ìœ¼ë¡œ í‘œì‹œ
        st.markdown("### ğŸ“Š ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ìƒì  ì½”ë“œ:")
        
        # output í´ë”ì—ì„œ ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ìŠ¤ìº”
        output_dir = Path("open_sdk/output")
        existing_analyses = []
        
        if output_dir.exists():
            for analysis_folder in output_dir.iterdir():
                if analysis_folder.is_dir() and analysis_folder.name.startswith("analysis_"):
                    # í´ë”ëª…ì—ì„œ ìƒì  ì½”ë“œ ì¶”ì¶œ (analysis_XXXXX_YYYYMMDD_HHMMSS í˜•ì‹)
                    parts = analysis_folder.name.split("_")
                    if len(parts) >= 2:
                        store_code = parts[1]
                        # analysis_result.json íŒŒì¼ì´ ìˆëŠ”ì§€ í™•ì¸
                        result_file = analysis_folder / "analysis_result.json"
                        if result_file.exists():
                            existing_analyses.append({
                                "store_code": store_code,
                                "folder_name": analysis_folder.name,
                                "analysis_date": parts[2] + "_" + parts[3] if len(parts) >= 4 else "N/A"
                            })
        
        if existing_analyses:
            # ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬
            existing_analyses.sort(key=lambda x: x["analysis_date"], reverse=True)
            
            # ìƒì  ì½”ë“œë“¤ì„ í‘œì‹œ
            for analysis in existing_analyses:
                st.code(f"{analysis['store_code']}  # ë¶„ì„ì¼: {analysis['analysis_date']}")
        else:
            st.info("ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")


# ì•± ì¢…ë£Œ ì‹œ ë¡œê·¸ ìº¡ì²˜ ì¤‘ì§€
# log_capture.stop_capture()  # ì£¼ì„ ì²˜ë¦¬ - Streamlitì€ ê³„ì† ì‹¤í–‰ë˜ë¯€ë¡œ