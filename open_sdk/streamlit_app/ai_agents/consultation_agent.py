"""
Consultation Agent using Langchain + Gemini
ëŒ€í™”í˜• ìƒë‹´ ì—ì´ì „íŠ¸ (ConversationBufferMemory ì‚¬ìš©)
"""
import os
import sys
import json
from pathlib import Path
from datetime import datetime
from typing import Dict, Any

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.runnables import RunnableWithMessageHistory
from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory


# Langfuse tracing ì¶”ê°€ (ì˜¬ë°”ë¥¸ ë°©ì‹)
try:
    from langfuse import observe
    from langfuse.openai import openai as langfuse_openai
    LANGFUSE_AVAILABLE = True
    print("[OK] Langfuse initialized successfully")
except ImportError:
    print("[WARN] Langfuse not available - tracing disabled")
    LANGFUSE_AVAILABLE = False
    langfuse_openai = None

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# UTF-8 ê°•ì œ ì„¤ì • (Windows í™˜ê²½) - LogCaptureì™€ ì¶©ëŒ ë°©ì§€
if sys.platform == "win32":
    try:
        sys.stdout.reconfigure(encoding='utf-8')
        sys.stderr.reconfigure(encoding='utf-8')
    except AttributeError:
        # LogCapture ê°ì²´ì¸ ê²½ìš° ë¬´ì‹œ
        pass

# Gemini API Key í™•ì¸
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    print("[ERROR] GEMINI_API_KEY not found in environment")


def load_agent_results(store_code: str) -> dict:
    """
    ì—ì´ì „íŠ¸ ê²°ê³¼ JSON íŒŒì¼ë“¤ì„ ë¡œë“œí•˜ì—¬ íŒŒì‹±
    
    Args:
        store_code: ë§¤ì¥ ì½”ë“œ
        
    Returns:
        dict: íŒŒì‹±ëœ ì—ì´ì „íŠ¸ ê²°ê³¼ë“¤
    """
    results = {
        "marketing_result": None,
        "new_product_result": None
    }
    
    try:
        from pathlib import Path
        
        # output í´ë”ì—ì„œ í•´ë‹¹ store_codeì˜ ìµœì‹  ë¶„ì„ í´ë” ì°¾ê¸°
        output_dir = Path(__file__).parent.parent.parent / "output"
        store_folders = sorted(
            [f for f in output_dir.glob(f"analysis_{store_code}_*") if f.is_dir()],
            key=lambda x: x.name,
            reverse=True
        )
        
        if store_folders:
            latest_folder = store_folders[0]
            
            # Marketing Agent ê²°ê³¼ ë¡œë“œ
            marketing_file = latest_folder / "marketing_result.json"
            if marketing_file.exists():
                with open(marketing_file, 'r', encoding='utf-8') as f:
                    results["marketing_result"] = json.load(f)
                print(f"[DEBUG] Marketing result loaded: {marketing_file.name}")
            
            # New Product Agent ê²°ê³¼ ë¡œë“œ
# 86-90ë²ˆì§¸ ì¤„ ë³€ê²½
            # New Product Agent ê²°ê³¼ ë¡œë“œ
            new_product_file = latest_folder / "new_product_result.json"
            if new_product_file.exists():
                with open(new_product_file, 'r', encoding='utf-8') as f:
                    results["new_product_result"] = json.load(f)
                print(f"[DEBUG] New Product result loaded: {new_product_file.name}")
            else:
                # analysis_ í´ë”ì— ì—†ìœ¼ë©´ naver_datalab_ í´ë”ì—ì„œ ì°¾ê¸°
                datalab_folders = sorted(
                    [f for f in output_dir.glob("naver_datalab_*") if f.is_dir()],
                    key=lambda x: x.name,
                    reverse=True
                )
                
                for datalab_folder in datalab_folders:
                    new_product_file = datalab_folder / f"{store_code}_new_product_result.json"
                    if new_product_file.exists():
                        with open(new_product_file, 'r', encoding='utf-8') as f:
                            results["new_product_result"] = json.load(f)
                        print(f"[DEBUG] New Product result loaded from datalab: {new_product_file.name}")
                        break
    except Exception as e:
        print(f"[WARN] Failed to load agent results: {e}")
    
    return results

def load_sns_segment_data() -> dict:
    """
    segment_sns.json ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì—¬ ì—°ë ¹ëŒ€ë³„ SNS ì±„ë„ ì •ë³´ ë°˜í™˜
    
    Returns:
        dict: ì—°ë ¹ëŒ€ë³„ SNS ì±„ë„ ë°ì´í„°
    """
    try:
        from pathlib import Path
        
        # segment_sns.json íŒŒì¼ ê²½ë¡œ
        sns_file = Path(__file__).parent.parent.parent.parent / "data" / "segment_sns.json"
        
        if sns_file.exists():
            with open(sns_file, 'r', encoding='utf-8') as f:
                sns_data = json.load(f)
            print(f"[DEBUG] SNS segment data loaded: {sns_file.name}")
            return sns_data
        else:
            print(f"[WARN] SNS segment file not found: {sns_file}")
            return {}
            
    except Exception as e:
        print(f"[WARN] Failed to load SNS segment data: {e}")
        return {}

def get_age_based_sns_recommendations(age_groups: list, sns_data: dict) -> str:
    """
    ì—°ë ¹ëŒ€ë³„ SNS ì±„ë„ ì¶”ì²œ ì •ë³´ ìƒì„±
    
    Args:
        age_groups: íƒ€ê²Ÿ ì—°ë ¹ëŒ€ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ["20ëŒ€", "30ëŒ€"])
        sns_data: segment_sns.json ë°ì´í„°
        
    Returns:
        str: ì—°ë ¹ëŒ€ë³„ SNS ì±„ë„ ì¶”ì²œ ì •ë³´
    """
    if not sns_data or "age_top5_channels" not in sns_data:
        return "SNS ì±„ë„ ë°ì´í„° ì—†ìŒ"
    
    recommendations = []
    age_channels = sns_data["age_top5_channels"]
    
    for age_group in age_groups:
        age_key = f"ì—°ë ¹-{age_group}"
        if age_key in age_channels:
            channels = age_channels[age_key]
            age_info = f"**{age_group}**: "
            top_channels = []
            
            for channel in channels[:3]:  # ìƒìœ„ 3ê°œë§Œ
                channel_name = channel["channel"]
                usage_percent = channel["usage_percent"]
                trend = channel["trend_label"]
                top_channels.append(f"{channel_name}({usage_percent}%, {trend})")
            
            age_info += " / ".join(top_channels)
            recommendations.append(age_info)
    
    if recommendations:
        return "\n".join(recommendations)
    else:
        return "í•´ë‹¹ ì—°ë ¹ëŒ€ SNS ë°ì´í„° ì—†ìŒ"


def analyze_flyer_marketing_potential(store_data: dict, panorama_data: dict) -> dict:
    """
    íŒŒë…¸ë¼ë§ˆ ë°ì´í„°ì™€ ë§¤ì¥ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì „ë‹¨ì§€ ë§ˆì¼€íŒ… ì í•©ì„± íŒë‹¨
    
    Args:
        store_data: ë§¤ì¥ ë¶„ì„ ë°ì´í„°
        panorama_data: íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ë°ì´í„°
        
    Returns:
        dict: ì „ë‹¨ì§€ ë§ˆì¼€íŒ… ì¶”ì²œ ê²°ê³¼
    """
    # ë§¤ì¥ í˜ë¥´ì†Œë‚˜ ë¶„ì„
    customer_analysis = store_data.get("customer_analysis", {})
    age_distribution = customer_analysis.get("age_group_distribution", {})
    
    # ê³ ë ¹ì¸µ ë¹„ìœ¨ ê³„ì‚° (50ëŒ€ ì´ìƒ)
    senior_ratio = (
        age_distribution.get("50ëŒ€", 0) + 
        age_distribution.get("60ëŒ€ ì´ìƒ", 0)
    )
    
    # ì‹ ê·œ ê³ ê° ë¹„ìœ¨
    customer_type_analysis = customer_analysis.get("customer_type_analysis", {})
    new_customer_ratio = customer_type_analysis.get("new_customers", {}).get("ratio", 0)
    
    # ìƒê¶Œ ë¶„ì„
    commercial_area_analysis = store_data.get("commercial_area_analysis", {})
    commercial_area = commercial_area_analysis.get("commercial_area", "")
    
    # í˜ë¥´ì†Œë‚˜ íŒì •
    is_senior_heavy = senior_ratio >= 30  # 50ëŒ€ ì´ìƒ 30% ì´ìƒ
    is_low_new_customer = new_customer_ratio <= 15  # ì‹ ê·œ ê³ ê° 15% ì´í•˜
    is_residential = "ì•„íŒŒíŠ¸" in commercial_area or "ì£¼ê±°" in commercial_area or "ë‹¨ì§€" in commercial_area
    
    # íŒŒë…¸ë¼ë§ˆ ë°ì´í„°ì—ì„œ ìƒê¶Œ íŠ¹ì„± ì¶”ì¶œ
    panorama_summary = panorama_data.get("synthesis", {})
    area_character = panorama_summary.get("area_summary", {}).get("overall_character", "")
    dominant_zone = panorama_summary.get("area_summary", {}).get("dominant_zone_type", "")
    
    # ì „ë‹¨ì§€ ë§ˆì¼€íŒ… ì í•©ì„± íŒë‹¨
    needs_flyer_marketing = is_senior_heavy and is_low_new_customer and is_residential
    
    if not needs_flyer_marketing:
        return {
            "recommended": False,
            "reason": "ì˜¨ë¼ì¸ ë§ˆì¼€íŒ…ì´ ë” íš¨ê³¼ì ì…ë‹ˆë‹¤. ì Šì€ ê³ ê°ì¸µì´ ë§ì•„ SNS ë§ˆì¼€íŒ…ì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
            "alternative": "ì¸ìŠ¤íƒ€ê·¸ë¨, í˜ì´ìŠ¤ë¶ ë“± SNS ë§ˆì¼€íŒ… ì „ëµì„ ì¶”ì²œí•©ë‹ˆë‹¤.",
            "persona_analysis": {
                "senior_ratio": senior_ratio,
                "new_customer_ratio": new_customer_ratio,
                "commercial_area": commercial_area,
                "is_senior_heavy": is_senior_heavy,
                "is_low_new_customer": is_low_new_customer,
                "is_residential": is_residential
            }
        }
    
    # ì „ë‹¨ì§€ ë§ˆì¼€íŒ… ì¶”ì²œ ìœ„ì¹˜ë“¤ (íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ê¸°ë°˜)
    recommended_locations = []
    
    # íŒŒë…¸ë¼ë§ˆ ë¶„ì„ì—ì„œ ì¶”ì¶œí•œ ìƒê¶Œ íŠ¹ì„±ì— ë”°ë¥¸ ìœ„ì¹˜ ì¶”ì²œ
    if "ì£¼ê±°" in area_character or "ì•„íŒŒíŠ¸" in area_character:
        recommended_locations.extend([
            {
                "location": "ì•„íŒŒíŠ¸ ì •ë¬¸ ë¶ì¸¡ ë³´ë„",
                "position": "ê²½ë¹„ì‹¤ ìœ ë¦¬ë©´ì—ì„œ ì˜¤ë¥¸ìª½ 2m, ë²½ë©´ìª½ 0.6m",
                "time_slot": "16-19ì‹œ",
                "reason": "ì•‰ì•„ ì‰¬ëŠ” ë³´í˜¸ìÂ·ì–´ë¥´ì‹  ëŒ€ê¸° ë§ìŒ(ì²´ë¥˜ì„±â†‘) + ë°ê³  ë°˜ì‚¬ ì ì–´ ëŒ€í™”/ì½ê¸° ì‰¬ì›€",
                "cautions": "ë¬¸ ì „ë©´ ê¸ˆì§€, ìœ ëª¨ì°¨ ë™ì„  ì£¼ì˜"
            },
            {
                "location": "ë™ë„¤ ë³‘ì› ì• ì°¨ì–‘ ì•„ë˜",
                "position": "ì°¨ì–‘ ê¸°ë‘¥ê³¼ 1m ì´ê²©, ë²½ë©´ìª½ 0.5m",
                "time_slot": "09-11ì‹œ",
                "reason": "ë³‘ì›Â·ì•½êµ­ ëŒ€ê¸° ì˜ì(ì •ì§€ ì‹œê°„) â†’ ì„¤ëª… ë“¤ì„ ì—¬ìœ  ìˆìŒ",
                "cautions": "ì§„ì…ë™ì„ /íœ ì²´ì–´ ë°©í•´ ê¸ˆì§€"
            }
        ])
    
    if "ê³µì›" in area_character or "ì‚°ì±…" in area_character:
        recommended_locations.append({
            "location": "ê³µì› ì…êµ¬ ê·¸ëŠ˜ ë©´",
            "position": "ì…êµ¬ì—ì„œ 2m ì´ê²©, ë‚˜ë¬´ ê·¸ëŠ˜ ì•„ë˜ 1m",
            "time_slot": "16-19ì‹œ",
            "reason": "ì‚°ì±… ê·€ê°€ ë™ì„  + ê·¸ëŠ˜ì—ì„œ í¸ì•ˆí•œ ëŒ€í™” ê°€ëŠ¥",
            "cautions": "ì‚°ì±…ë¡œ ì°¨ë‹¨ ê¸ˆì§€, ìš´ë™í•˜ëŠ” ì‚¬ëŒë“¤ ì£¼ì˜"
        })
    
    # ê¸°ë³¸ ì¶”ì²œ ìœ„ì¹˜ (ìƒê¶Œ íŠ¹ì„±ê³¼ ê´€ê³„ì—†ì´)
    if not recommended_locations:
        recommended_locations = [
            {
                "location": "ë²„ìŠ¤ì‰˜í„° ì¸¡ë©´ ë²¤ì¹˜ ëë‹¨",
                "position": "ë²¤ì¹˜ ëë‹¨ ì˜† 0.5m, ê¹”ë•Œê¸° ë™ì„  ì¸¡ë©´",
                "time_slot": "16-19ì‹œ",
                "reason": "ë²„ìŠ¤ ëŒ€ê¸° ì‹œê°„(4ì´ˆ ì´ìƒ) â†’ ë†’ì€ ì£¼ëª©ë„ + ë©”ì‹œì§€ ì´í•´ ì‹œê°„ í™•ë³´",
                "cautions": "íƒ‘ìŠ¹ë¬¸ ì „ë©´ ê¸ˆì§€, ëŒ€ê¸°ì¤„ ë°©í•´ ì£¼ì˜"
            },
            {
                "location": "ë™ë„¤ ë§ˆíŠ¸ ê³„ì‚°ëŒ€ ë³´ì´ëŠ” ì¶œì…ë¶€",
                "position": "ì¶œì…êµ¬ì—ì„œ 1.5m ì´ê²©, ìœ ë¦¬ë©´ ì˜† 0.8m",
                "time_slot": "09-11ì‹œ",
                "reason": "ì‡¼í•‘ í›„ íœ´ì‹ ì‹œê°„ + ê³„ì‚°ëŒ€ ëŒ€ê¸° ì¤‘ ìì—°ìŠ¤ëŸ¬ìš´ ì ‘ì´‰",
                "cautions": "ì¶œì…êµ¬ ì°¨ë‹¨ ê¸ˆì§€, ì¥ë°”êµ¬ë‹ˆ ë™ì„  ì£¼ì˜"
            }
        ]
    
    # ì—…ì¢…ë³„ ìŠ¤í¬ë¦½íŠ¸
    store_overview = store_data.get("store_overview", {})
    industry = store_overview.get("industry", "ê¸°ë³¸")
    
    scripts = {
        "ì¹´í˜": [
            "ë™ë„¤ ì¹´í˜ ìƒˆë¡œ ì˜¤í”ˆí–ˆì–´ìš”. ì–´ë¥´ì‹  ì„¸íŠ¸ í• ì¸ê¶Œ ë“œë¦´ê²Œìš”. ì—¬ê¸° QRë¡œ ì•ˆë‚´ë©ë‹ˆë‹¤.",
            "ë§›ìˆëŠ” ì»¤í”¼ì™€ ë””ì €íŠ¸ë¡œ ëª¨ì‹œê² ìŠµë‹ˆë‹¤. ì–´ë¥´ì‹ ë“¤ê»˜ íŠ¹ë³„ í• ì¸ ì¿ í° ë“œë ¤ìš”.",
            "í¸ì•ˆí•œ ë¶„ìœ„ê¸°ì—ì„œ ì°¨ í•œ ì” ì–´ë– ì„¸ìš”? ì‹ ê·œ ì˜¤í”ˆ ê¸°ë… ì¿ í° ë“œë¦½ë‹ˆë‹¤."
        ],
        "ì‹ë£Œí’ˆ": [
            "ì‹ ì„ í•œ ì¬ë£Œë¡œ ë§Œë“  ê±´ê°•í•œ ìŒì‹ì…ë‹ˆë‹¤. ì–´ë¥´ì‹ ë“¤ê»˜ íŠ¹ë³„ í• ì¸ ë“œë ¤ìš”.",
            "ë™ë„¤ ì‹ë£Œí’ˆì ì—ì„œ ì‹ ì„ í•œ ì±„ì†Œì™€ ê³¼ì¼ì„ ë§Œë‚˜ë³´ì„¸ìš”. í• ì¸ ì¿ í° ë“œë¦½ë‹ˆë‹¤."
        ]
    }
    
    industry_scripts = scripts.get(industry, scripts["ì¹´í˜"])
    
    # ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê° ìœ„ì¹˜ì— ì¶”ê°€
    import random
    for location in recommended_locations:
        location["script"] = random.choice(industry_scripts)
    
    return {
        "recommended": True,
        "persona_analysis": {
            "senior_ratio": senior_ratio,
            "new_customer_ratio": new_customer_ratio,
            "commercial_area": commercial_area,
            "is_senior_heavy": is_senior_heavy,
            "is_low_new_customer": is_low_new_customer,
            "is_residential": is_residential
        },
        "panorama_insights": {
            "area_character": area_character,
            "dominant_zone": dominant_zone
        },
        "why_flyer_effective": f"ê³ ë ¹ì¸µ ë¹„ìœ¨ {senior_ratio:.1f}% + ì‹ ê·œ ê³ ê° ë¹„ìœ¨ {new_customer_ratio:.1f}% + ì£¼ê±°í˜• ìƒê¶Œìœ¼ë¡œ ì˜¤í”„ë¼ì¸ ì ‘ì´‰ì´ íš¨ê³¼ì ",
        "recommended_locations": recommended_locations[:3],  # ìƒìœ„ 3ê°œë§Œ
        "general_guidelines": [
            "ì²´ë¥˜ì„± 40ì : ë²¤ì¹˜/ê·¸ëŠ˜(+10), ëŒ€ê¸° í”ì (+10), ìœ íš¨í­â‰¥2.5m(+8), ì†ŒìŒ ë‚®ìŒ(+12)",
            "ê°€ë…ì„± 30ì : ì ì • ì¡°ë„(+12), ê¸€ë ˆì–´ ë‚®ìŒ(+6), ì‹œì•¼ ì°¨ë‹¨ë¬¼ ì—†ìŒ(+12)",
            "ì•ˆì „ 20ì : ì¶œì…êµ¬Â·ê³„ë‹¨Â·ì°¨ëŸ‰ë™ì„ ê³¼ ì´ê²©(+12), ì¶©ëŒ ìœ„í—˜ ì—†ìŒ(+8)",
            "ê³ ë ¹ì¹œí™” 10ì : ì˜ìÂ·ë‚œê°„Â·í‰íƒ„ í¬ì¥ í™•ì¸(+10)",
            "70ì â†‘ ìš°ì„  ì¶”ì²œ / 60-69 ì¡°ê±´ë¶€(ì‹œê°„ëŒ€ ì œí•œ) / 59â†“ ì œì™¸",
            "ì˜¤ì „ 9-11ì‹œ: ë³‘ì›/ì•½êµ­, ì‹œì¥ ì…êµ¬, ê²½ë¡œë‹¹ ì£¼ë³€",
            "ì˜¤í›„ 4-7ì‹œ: ì•„íŒŒíŠ¸ ì •ë¬¸, ê³µì› ì…êµ¬, í•™ì›ê°€ ë³´í˜¸ì ëŒ€ê¸° êµ¬ì—­"
        ]
    }


def load_merged_analysis(analysis_dir: str) -> tuple:
    """
    í†µí•© ë¶„ì„ íŒŒì¼ (JSON + MD) ë¡œë“œ
    
    Args:
        analysis_dir: ë¶„ì„ ê²°ê³¼ ë””ë ‰í† ë¦¬
        
    Returns:
        tuple: (merged_json_data: dict, merged_md_content: str)
    """
    try:
        analysis_path = Path(analysis_dir)
        
        # JSON íŒŒì¼ ë¡œë“œ
        merged_json_file = analysis_path / "merged_analysis_full.json"
        with open(merged_json_file, 'r', encoding='utf-8') as f:
            merged_json = json.load(f)
        
        # MD íŒŒì¼ ë¡œë“œ
        merged_md_file = analysis_path / "merged_analysis_full.md"
        with open(merged_md_file, 'r', encoding='utf-8') as f:
            merged_md = f.read()
        
        print(f"[OK] Merged analysis loaded: JSON={len(str(merged_json))} chars, MD={len(merged_md)} chars")
        
        return merged_json, merged_md
        
    except Exception as e:
        print(f"[ERROR] Failed to load merged analysis: {e}")
        return None, None


def create_consultation_chain(store_code: str, analysis_data: dict, analysis_md: str, mcp_content: str = ""):
    """
    Langchain ê¸°ë°˜ ìƒë‹´ ì²´ì¸ ìƒì„±
    
    Args:
        store_code: ìƒì  ì½”ë“œ
        analysis_data: í†µí•© ë¶„ì„ JSON ë°ì´í„°
        analysis_md: í†µí•© ë¶„ì„ MD í…ìŠ¤íŠ¸
        mcp_content: Google Maps MCP ê²€ìƒ‰ ê²°ê³¼ (txt)
        
    Returns:
        tuple: (chain, chat_history)
    """
    try:
        print(f"[DEBUG] Creating consultation chain for store {store_code}")
        
        # Gemini ëª¨ë¸ ì´ˆê¸°í™” (ì¶œë ¥ í† í° ìˆ˜ ëŒ€í­ ì¦ê°€)
        llm = ChatGoogleGenerativeAI(
            model="gemini-2.5-flash",
            google_api_key=GEMINI_API_KEY,
            temperature=0.7,
            max_output_tokens=14192  # í† í° ìˆ˜ ëŒ€í­ ì¦ê°€ë¡œ í…ìŠ¤íŠ¸ ì˜ë¦¼ ë°©ì§€
        )
        
        # ë©”ëª¨ë¦¬ ì´ˆê¸°í™” (InMemoryChatMessageHistory)
        chat_history = InMemoryChatMessageHistory()
        
        # ë¶„ì„ ë°ì´í„°ì—ì„œ í•µì‹¬ ì •ë³´ ì¶”ì¶œ
        store_name = analysis_data.get("store_analysis", {}).get("store_overview", {}).get("name", "N/A")
        industry = analysis_data.get("store_analysis", {}).get("store_overview", {}).get("industry", "N/A")
        commercial_area = analysis_data.get("store_analysis", {}).get("store_overview", {}).get("commercial_area", "N/A")
        
        # ì¬ë°©ë¬¸ìœ¨ ë°ì´í„° ëª…ì‹œì ìœ¼ë¡œ ì¶”ì¶œ
        store_analysis = analysis_data.get("store_analysis", {})
        customer_analysis = store_analysis.get("customer_analysis", {})
        customer_type_analysis = customer_analysis.get("customer_type_analysis", {})
        returning_customers = customer_type_analysis.get("returning_customers", {})
        returning_customer_ratio = returning_customers.get("ratio", "N/A")
        returning_customer_trend = returning_customers.get("trend", "N/A")
        
        new_customers = customer_type_analysis.get("new_customers", {})
        new_customer_ratio = new_customers.get("ratio", "N/A")
        new_customer_trend = new_customers.get("trend", "N/A")
        
        # ì—ì´ì „íŠ¸ ê²°ê³¼ ë¡œë“œ
        agent_results = load_agent_results(store_code)   
        
        # SNS ì„¸ê·¸ë¨¼íŠ¸ ë°ì´í„° ë¡œë“œ
        sns_data = load_sns_segment_data()
        
        # ë§ˆì¼€íŒ… ì „ëµ ì¶”ì¶œ (JSON íŒŒì¼ì—ì„œ ë¡œë“œ)
        marketing_strategies = []
        marketing_personas = []
        marketing_risks = []
        if agent_results.get("marketing_result"):
            marketing_data = agent_results["marketing_result"]
            marketing_strategies = marketing_data.get("marketing_strategies", [])
            marketing_personas = marketing_data.get("personas", [])
            marketing_risks = marketing_data.get("risk_analysis", {}).get("detected_risks", [])
        else:
            # ê¸°ì¡´ ë°©ì‹ (fallback)
            marketing_data = analysis_data.get("marketing_analysis", {})
            marketing_strategies = marketing_data.get("marketing_strategies", [])
            marketing_personas = marketing_data.get("personas", [])
            marketing_risks = marketing_data.get("risk_analysis", {}).get("detected_risks", [])
        
        # ë§ˆì¼€íŒ… ì „ëµ ê°„ì†Œí™” (í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ)
        strategy_summary = "\n".join([
            f"- {i+1}. **{s.get('name', 'N/A')}**: {s.get('description', 'N/A')[:100]}..."
            for i, s in enumerate(marketing_strategies[:3])
        ]) if marketing_strategies else "ë§ˆì¼€íŒ… ì „ëµ ì •ë³´ ì—†ìŒ"
        
        # í˜ë¥´ì†Œë‚˜ ì •ë³´ ê°„ì†Œí™” ë° SNS ì±„ë„ ì¶”ì²œ ìƒì„±
        persona_summary = ""
        sns_recommendations = ""
        
        if marketing_personas:
            persona_details = []
            age_groups = []
            
            for p in marketing_personas[:2]:
                age_range = p.get('age_range', 'N/A')
                persona_info = f"- **{p.get('name', 'N/A')}** ({age_range}, {p.get('gender', 'N/A')}): {p.get('characteristics', 'N/A')[:80]}..."
                persona_details.append(persona_info)
                
                # ì—°ë ¹ëŒ€ ì¶”ì¶œ (ì˜ˆ: "20-30ëŒ€" -> ["20ëŒ€", "30ëŒ€"])
                if age_range and age_range != 'N/A':
                    if "20ëŒ€" in age_range:
                        age_groups.append("20ëŒ€")
                    if "30ëŒ€" in age_range:
                        age_groups.append("30ëŒ€")
                    if "40ëŒ€" in age_range:
                        age_groups.append("40ëŒ€")
                    if "50ëŒ€" in age_range:
                        age_groups.append("50ëŒ€")
                    if "60ëŒ€" in age_range:
                        age_groups.append("60ëŒ€")
                    if "70ëŒ€" in age_range:
                        age_groups.append("70ëŒ€ ì´ìƒ")
            
            persona_summary = "\n".join(persona_details)
            
            # ì¤‘ë³µ ì œê±° í›„ SNS ì±„ë„ ì¶”ì²œ ìƒì„±
            unique_age_groups = list(set(age_groups))
            if unique_age_groups and sns_data:
                sns_recommendations = get_age_based_sns_recommendations(unique_age_groups, sns_data)
        else:
            persona_summary = "í˜ë¥´ì†Œë‚˜ ì •ë³´ ì—†ìŒ"
        
        # ìœ„í—˜ ë¶„ì„ ì •ë³´ ê°„ì†Œí™”
        risk_summary = "\n".join([
            f"- **{r.get('code', 'N/A')}**: {r.get('name', 'N/A')} ({r.get('level', 'N/A')}, {r.get('score', 'N/A')}/10) - {r.get('evidence', 'N/A')[:60]}..."
            for r in marketing_risks[:3]
        ]) if marketing_risks else "ìœ„í—˜ ë¶„ì„ ì •ë³´ ì—†ìŒ"


        
        # ì‹ ì œí’ˆ ì œì•ˆ ì¶”ì¶œ (JSON íŒŒì¼ì—ì„œ ë¡œë“œ)
        new_product_proposals = []
        new_product_insights = {}
        if agent_results.get("new_product_result") and agent_results["new_product_result"].get("activated"):
            new_product_data = agent_results["new_product_result"]
            new_product_proposals = new_product_data.get("proposals", [])
            new_product_insights = new_product_data.get("insight", {})
        
        # ì‹ ì œí’ˆ ì œì•ˆ ê°„ì†Œí™”
        new_product_summary = "\n".join([
            f"- {i+1}. **{p.get('menu_name', 'N/A')}** ({p.get('category', 'N/A')}) - íƒ€ê²Ÿ: {p.get('target', {}).get('gender', 'N/A')} {', '.join(p.get('target', {}).get('ages', []))} - í‚¤ì›Œë“œ: {p.get('evidence', {}).get('keyword', 'N/A')}"
            for i, p in enumerate(new_product_proposals[:3])
        ]) if new_product_proposals else "ì‹ ì œí’ˆ ì œì•ˆ ì •ë³´ ì—†ìŒ"
        
        # ì‹ ì œí’ˆ ì¸ì‚¬ì´íŠ¸ ê°„ì†Œí™”
        new_product_insight_summary = f"ê³ ê°: {new_product_insights.get('gender_summary', 'N/A')}, {new_product_insights.get('age_summary', 'N/A')}" if new_product_insights else "ì‹ ì œí’ˆ ì¸ì‚¬ì´íŠ¸ ì •ë³´ ì—†ìŒ"
        
        # ìƒê¶Œ ë¶„ì„ ì¶”ì¶œ
        marketplace_name = analysis_data.get("marketplace_analysis", {}).get("ìƒê¶Œëª…", "N/A")
        
        # íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ì¶”ì¶œ
        panorama_summary = analysis_data.get("panorama_analysis", {}).get("synthesis", {}).get("final_recommendation", "N/A")
        
        # ì „ë‹¨ì§€ ë§ˆì¼€íŒ… ë¶„ì„ì€ ì§ˆë¬¸ ì²˜ë¦¬ ì‹œì—ë§Œ ì¡°ê±´ë¶€ë¡œ ì‹¤í–‰
        # (ìƒë‹´ ì²´ì¸ ìƒì„± ì‹œì—ëŠ” ì‹¤í–‰í•˜ì§€ ì•ŠìŒ)
        
        # MCP ê²€ìƒ‰ ê²°ê³¼ ì²˜ë¦¬ (ì•ˆì „í•˜ê²Œ)
        safe_mcp_content = ""
        if mcp_content:
            # ì²˜ìŒ 2000ìë§Œ ì‚¬ìš© (í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ)
            safe_mcp_content = mcp_content[:2000].replace("{", "{{").replace("}", "}}")
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì¤‘ê´„í˜¸ ì´ìŠ¤ì¼€ì´í”„ - ëª¨ë“  { } ë¥¼ {{ }} ë¡œ ë³€í™˜)
        # analysis_mdì— JSONì´ í¬í•¨ë˜ì–´ ìˆì–´ ì¤‘ê´„í˜¸ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ì¤‘ê´„í˜¸ ì´ìŠ¤ì¼€ì´í”„ - ëª¨ë“  { } ë¥¼ {{ }} ë¡œ ë³€í™˜)
        # analysis_mdì— JSONì´ í¬í•¨ë˜ì–´ ìˆì–´ ì¤‘ê´„í˜¸ ë¬¸ì œ ë°œìƒ ê°€ëŠ¥
        safe_analysis_md = analysis_md[:3000].replace("{", "{{").replace("}", "}}")
        safe_strategy_summary = strategy_summary.replace("{", "{{").replace("}", "}}")
        safe_persona_summary = persona_summary.replace("{", "{{").replace("}", "}}")
        safe_risk_summary = risk_summary.replace("{", "{{").replace("}", "}}")
        safe_panorama_summary = panorama_summary[:500].replace("{", "{{").replace("}", "}}")
        safe_new_product_summary = new_product_summary.replace("{", "{{").replace("}", "}}")
        safe_new_product_insight = new_product_insight_summary.replace("{", "{{").replace("}", "}}")
        safe_sns_recommendations = sns_recommendations.replace("{", "{{").replace("}", "}}")
        
        # ì¬ë°©ë¬¸ìœ¨ ì •ë³´ ìƒì„±
        revisit_info = f"ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨: {returning_customer_ratio}% (íŠ¸ë Œë“œ: {returning_customer_trend}), ì‹ ê·œ ê³ ê° ë¹„ìœ¨: {new_customer_ratio}% (íŠ¸ë Œë“œ: {new_customer_trend})"
        safe_revisit_info = revisit_info.replace("{", "{{").replace("}", "}}")
        # MCP ì„¹ì…˜ ì¡°ê±´ë¶€ ì¶”ê°€
        mcp_section = ""
        if safe_mcp_content:
            mcp_section = f"""
### Google Maps ì •ë³´ (MCP ê²€ìƒ‰ ê²°ê³¼) - ì¶œì²˜: Google Maps API
{safe_mcp_content}...
"""
        
        system_prompt = f"""ë‹¹ì‹ ì€ ë§¤ì¥ '{store_name}' (ì—…ì¢…: {industry}, ìƒê¶Œ: {commercial_area})ì˜ ì „ë¬¸ ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

## ğŸ“Š í•µì‹¬ ë¶„ì„ ë°ì´í„° (JSON ê¸°ë°˜)
{mcp_section}
### ğŸ“ˆ ë§ˆì¼€íŒ… ì „ëµ - marketing_result.json
{safe_strategy_summary}

### ğŸ‘¥ ê³ ê° í˜ë¥´ì†Œë‚˜ - marketing_result.json  
{safe_persona_summary}

### ğŸ“± SNS ì±„ë„ ì¶”ì²œ - segment_sns.json ì°¸ê³ 
{safe_sns_recommendations}

### âš ï¸ ìœ„í—˜ ë¶„ì„ - marketing_result.json
{safe_risk_summary}

**ìœ„í—˜ ì½”ë“œ ì •ì˜ (R1-R10 )**:
- R1: ì‹ ê·œìœ ì… ê¸‰ê° (ì‹ ê·œ ê³ ê° ìœ ì…ì´ ê¸‰ê²©íˆ ê°ì†Œ)
- R2: ì¬ë°©ë¬¸ìœ¨ ë™ì¼ ì—…ì¢… ë¹„í•´ ì €í•˜ (í‰ê·  ëŒ€ë¹„ 3% ì´ìƒ ë‚®ìŒ)
- R3: ì¥ê¸°ë§¤ì¶œì¹¨ì²´ (10ì¼ ì´ìƒ ë§¤ì¶œ ì •ì²´)
- R4: ë‹¨ê¸°ë§¤ì¶œí•˜ë½ (15% ì´ìƒ ê¸‰ê²© í•˜ë½)
- R5: ë°°ë‹¬ë§¤ì¶œí•˜ë½ (10% ì´ìƒ ê°ì†Œ)
- R6: ì·¨ì†Œìœ¨ ê¸‰ë“± (0.7% ì´ìƒ ì¦ê°€)
- R7: í•µì‹¬ì—°ë ¹ê´´ë¦¬ (í•µì‹¬ ê³ ê° ì—°ë ¹ì¸µê³¼ 8% ì´ìƒ ê´´ë¦¬)
- R8: ì‹œì¥ë¶€ì í•© (ì‹œì¥ ì í•©ë„ ì ìˆ˜ 70ì  ì´ìƒ)
- R9: ìƒê¶Œí•´ì§€ìœ„í—˜ (ìƒê¶Œ ë‚´ ê²½ìŸë ¥ ì•½í™”, í‰ê· +1.5Ïƒ ì´ìƒ)
- R10: ì¬ë°©ë¬¸ìœ¨ ë‚®ìŒ (ì¬ë°©ë¬¸ìœ¨ 30% ì´í•˜)

**ìœ„í—˜ íŒë‹¨ ì›ì¹™**:
- `risk_analysis.detected_risks` ë°°ì—´ì— ë‚˜ì—´ëœ ìœ„í—˜ë§Œ ì–¸ê¸‰í•˜ì„¸ìš”
- ê°ì§€ëœ ìœ„í—˜ ì™¸ì—ëŠ” "ì–‘í˜¸"í•˜ë‹¤ê³  ëª…ì‹œí•˜ì„¸ìš”

### ğŸ° ì‹ ì œí’ˆ ì œì•ˆ - new_product_result.json

### ğŸ° ì‹ ì œí’ˆ ì œì•ˆ - new_product_result.json
{safe_new_product_summary}

### ğŸ“Š ì‹ ì œí’ˆ ì¸ì‚¬ì´íŠ¸ - new_product_result.json
{safe_new_product_insight}

### ğŸŒ† ì§€ì—­ íŠ¹ì„± - panorama_analysis.json
{safe_panorama_summary[:200]}...

### ğŸª ë§¤ì¥ ì„±ê³¼ - store_analysis.json
**ì¤‘ìš”**: ë°˜ë“œì‹œ ì•„ë˜ ì¬ë°©ë¬¸ìœ¨ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
{safe_revisit_info}
- ë§¤ì¶œ íŠ¸ë Œë“œ, ê³ ê° ë¶„í¬, ë™ì¢…ì—…ê³„ ìˆœìœ„

### ğŸ¬ ìƒê¶Œ ë¶„ì„ - ì¶œì²˜: marketplace_analysis.json
- ìƒê¶Œ ê·œëª¨, ê²½ìŸ í™˜ê²½
- ìœ ë™ì¸êµ¬ íŒ¨í„´, ì í¬ ìˆ˜
- ì…ì§€ ì í•©ì„± í‰ê°€

### ğŸ“‹ í†µí•© ë¦¬í¬íŠ¸ - ì¶œì²˜: merged_analysis_full.md
{safe_analysis_md}

### ğŸ“„ ì „ë‹¨ì§€ ê´‘ê³  ìœ„ì¹˜ ì¶”ì²œ - ì¶œì²˜: íŒŒë…¸ë¼ë§ˆ + ë§¤ì¥ ë°ì´í„° ë¶„ì„
- ê³ ë ¹ì¸µì´ ë§ì€ ë§¤ì¥ì„ ìœ„í•œ ì˜¤í”„ë¼ì¸ ë§ˆì¼€íŒ… ì „ëµ
- íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€ ë¶„ì„ì„ í†µí•œ ìµœì  ë°°ë¶€ ìœ„ì¹˜ ì œì•ˆ
- ì‹œê°„ëŒ€ë³„, ìœ„ì¹˜ë³„ êµ¬ì²´ì ì¸ ì‹¤í–‰ ê°€ì´ë“œ
- *ì „ë‹¨ì§€ ê´€ë ¨ ì§ˆë¬¸ ì‹œ ë™ì ìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ ì œê³µ*

## ğŸ¯ ìƒë‹´ ì›ì¹™

### 1. **ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ë‹µë³€ (í—›ì†Œë¦¬ ê¸ˆì§€)**
- **ë°˜ë“œì‹œ ìœ„ì˜ JSON ë°ì´í„°ë¥¼ ê·¼ê±°ë¡œ ë‹µë³€**í•˜ì„¸ìš”
- ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ë¡  ê¸ˆì§€ - ì‹¤ì œ ë¶„ì„ ê²°ê³¼ë§Œ ì¸ìš©
- ë¬¸ì„œëª… + ì„¹ì…˜ëª… + êµ¬ì²´ì  ìˆ˜ì¹˜ë¥¼ í•¨ê»˜ ì œì‹œ
- ì˜ˆ: "ì‹ ë©”ë‰´ ì œì•ˆì€?"
  - âŒ "ì¼ë°˜ì ìœ¼ë¡œ ì¸ê¸° ìˆëŠ” ë©”ë‰´ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤" (ê·¼ê±° ì—†ìŒ)
  - âœ… "new_product_result.jsonì˜ 'proposals' ë°°ì—´ì—ì„œ 'ë¬´í™”ê³¼ íƒ€ë¥´íŠ¸'ê°€ ì œì•ˆë˜ì—ˆìœ¼ë©° (rank: 1, keyword: 'ë¬´í™”ê³¼'), 
    íƒ€ê²Ÿì€ ì—¬ì„± 10ëŒ€, 20ëŒ€, 30ëŒ€ì…ë‹ˆë‹¤. í•˜ì§€ë§Œ store_analysis.jsonì˜ 'customer_analysis.customer_type_analysis'ë¥¼ ë³´ë©´ 
    ë‚¨ì„± 43.8%, 50ëŒ€ ë¹„ì¤‘ì´ í¬ë¯€ë¡œ ì´ ë¶ˆì¼ì¹˜ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë‚¨ì„± ê³ ê°ì¸µë„ ê³ ë ¤í•œ ë©”ë‰´ ë³´ì™„ì´ í•„ìš”í•©ë‹ˆë‹¤."

### 2. **êµ¬ì²´ì ì¸ ë°ì´í„° ì¸ìš©**
- **ì •í™•í•œ ìˆ˜ì¹˜ì™€ í¼ì„¼íŠ¸**ë¥¼ ì œì‹œí•˜ì„¸ìš”
- **ì¶œì²˜ íŒŒì¼ëª…**ì„ ëª…ì‹œí•˜ì„¸ìš” (ì˜ˆ: "marketing_result.jsonì˜ R2 ìœ„í—˜ ë¶„ì„ì— ë”°ë¥´ë©´...")
- **ê³ ê° ë¦¬ë·°ì˜ ì‹¤ì œ ë¬¸ì¥**ì„ ì¸ìš©í•˜ì„¸ìš”

### 3. **ë°ì´í„° ê°„ ì—°ê´€ì„± ë¶„ì„**
- ì—¬ëŸ¬ JSON íŒŒì¼ì˜ ë°ì´í„°ë¥¼ ì—°ê²°í•˜ì—¬ ë¶„ì„í•˜ì„¸ìš”
- ì˜ˆ: "Google Maps ë¦¬ë·°ì˜ 'ì»¤í”¼ê°€ ê³ ì†Œí•˜ê³  ë¶€ë“œëŸ¬ì›Œì„œ ë§›ìˆì–´ìš”' + marketing_result.jsonì˜ 'ì‹œê·¸ë‹ˆì²˜ ë¸”ë Œë“œ ê°œë°œ' ì „ëµ + 
  store_analysis.jsonì˜ ì¬ë°©ë¬¸ìœ¨ ì €í•˜(R2) = ì»¤í”¼ ì „ë¬¸ì„± ê°•í™”ë¡œ ì¬ë°©ë¬¸ìœ¨ ê°œì„  í•„ìš”"

### 4. **ìœ„í—˜ ìš”ì†Œ ê¸°ë°˜ ì „ëµ ìˆ˜ì •**
- marketing_result.jsonì˜ ìœ„í—˜ ë¶„ì„(R1-R10)ì„ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ì„¸ìš”
- **ì¤‘ìš”**: ìœ„ì˜ "ìœ„í—˜ ì½”ë“œ ì •ì˜"ë¥¼ ì°¸ê³ í•˜ì—¬, `risk_analysis.detected_risks` ë°°ì—´ì— ë‚˜ì—´ëœ ìœ„í—˜ë§Œ ì–¸ê¸‰í•˜ê³ , ë‚˜ë¨¸ì§€ëŠ” "ì–‘í˜¸"í•˜ë‹¤ê³  ëª…ì‹œí•˜ì„¸ìš”
- ì˜ˆ: "í˜„ì¬{íŒŒì‹±ëœ R * }ì™€ {íŒŒì‹±ëœ R * } ìœ„í—˜ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚˜ë¨¸ì§€ ìœ„í—˜ ìš”ì†Œ(ì–¸ê¸‰ë˜ì§€ ì•Šì€ R *)ëŠ” ì–‘í˜¸í•œ ìƒíƒœì…ë‹ˆë‹¤."
- ê° ìœ„í—˜ ìš”ì†Œì— ëŒ€í•œ êµ¬ì²´ì ì¸ í•´ê²° ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”

### 5. **ì‹ ì œí’ˆ ì œì•ˆ ì‹œ í•„ìˆ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸**
- new_product_result.jsonì˜ ê¸°ì¡´ ì œì•ˆì„ ë¨¼ì € ì–¸ê¸‰í•˜ì„¸ìš”
- store_analysis.jsonì˜ ì‹¤ì œ ê³ ê° ë¶„í¬ì™€ ë¹„êµí•˜ì„¸ìš”
- ë¶ˆì¼ì¹˜ê°€ ìˆìœ¼ë©´ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ë¡œ ì„¤ëª…í•˜ê³  ë³´ì™„ ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”
- marketing_result.jsonì˜ ìœ„í—˜ ìš”ì†Œì™€ ì—°ê²°í•˜ì—¬ ê°œì„  íš¨ê³¼ë¥¼ ì„¤ëª…í•˜ì„¸ìš”

### 6. **ë§ˆì¼€íŒ… ì±„ë„ êµ¬ì²´í™”**
"ë‹¤ì–‘í•œ ì±„ë„" ê¸ˆì§€! í•­ìƒ êµ¬ì²´ì ìœ¼ë¡œ:
- ğŸ“± **ì˜¨ë¼ì¸**: ì¸ìŠ¤íƒ€ê·¸ë¨ í”¼ë“œ/ë¦´ìŠ¤, ë„¤ì´ë²„ í”Œë ˆì´ìŠ¤, ì¹´ì¹´ì˜¤ë§µ, ì§€ì—­ ë§˜ì¹´í˜
- ğŸª **ì˜¤í”„ë¼ì¸**: ë§¤ì¥ POP, ì „ë‹¨ì§€, í˜„ìˆ˜ë§‰, ìŠ¤íƒ ë“œë°°ë„ˆ
- ğŸ¤ **í˜‘ì—…**: ì¸ê·¼ ì˜¤í”¼ìŠ¤ ì œíœ´, ì§€ì—­ ì¶•ì œ ì°¸ì—¬, ë°°ë‹¬ì•± ì…ì 
- ï¿½ **ì…ì†Œë¬¸**: ë¦¬ë·° ì´ë²¤íŠ¸, ì¸í”Œë£¨ì–¸ì„œ ì´ˆëŒ€, ë‹¨ê³¨ ì¶”ì²œ í˜œíƒ

### 7. **ë‹µë³€ êµ¬ì¡° (í•„ìˆ˜)**
1. **í˜„ì¬ ìƒí™©**: JSON ë°ì´í„°ì—ì„œ í™•ì¸ëœ ì‹¤ì œ ìƒí™©
2. **ë¬¸ì œì **: ë°ì´í„° ê°„ ë¶ˆì¼ì¹˜ë‚˜ ìœ„í—˜ ìš”ì†Œ
3. **í•´ê²° ë°©ì•ˆ**: êµ¬ì²´ì ì¸ ì „ëµê³¼ ì‹¤í–‰ ë°©ë²•
4. **ê·¼ê±°**: ì–´ë–¤ JSON íŒŒì¼ì˜ ì–´ë–¤ ë°ì´í„°ë¥¼ ê·¼ê±°ë¡œ í–ˆëŠ”ì§€ ëª…ì‹œ
5. **ì˜ˆìƒ íš¨ê³¼**: ì •ëŸ‰ì  ëª©í‘œì™€ ê°œì„  ì§€í‘œ

### 8. **ì „ë‹¨ì§€ ê´‘ê³  ì „ëµ (ê³ ë ¹ì¸µ íƒ€ê²Ÿ)**
ê³ ê°ì´ "ì „ë‹¨ì§€", "ì˜¤í”„ë¼ì¸ ë§ˆì¼€íŒ…", "ë°°ë¶€", "ê´‘ê³  ìœ„ì¹˜" ë“±ì„ ì–¸ê¸‰í•˜ë©´:
- **í˜ë¥´ì†Œë‚˜ ë¶„ì„**: ê³ ë ¹ì¸µ ë¹„ìœ¨, ì‹ ê·œ ê³ ê° ë¹„ìœ¨, ìƒê¶Œ íŠ¹ì„± í™•ì¸
- **ìœ„ì¹˜ ì¶”ì²œ**: íŒŒë…¸ë¼ë§ˆ ë¶„ì„ ê¸°ë°˜ êµ¬ì²´ì ì¸ ë°°ë¶€ ìœ„ì¹˜ ì œì‹œ
- **ì‹œê°„ëŒ€ ê°€ì´ë“œ**: ì˜¤ì „ 9-11ì‹œ, ì˜¤í›„ 4-7ì‹œ ë“± ìµœì  ì‹œê°„ëŒ€ ì•ˆë‚´
- **ìŠ¤í¬ë¦½íŠ¸ ì œê³µ**: ê³ ë ¹ì¸µì—ê²Œ íš¨ê³¼ì ì¸ ëŒ€í™” ìŠ¤í¬ë¦½íŠ¸ ì œì‹œ
- **ì£¼ì˜ì‚¬í•­**: ë²•ì  ì œì•½, ë¯¼ì› ë°©ì§€, ì•ˆì „ ìˆ˜ì¹™ ì•ˆë‚´
- **ëŒ€ì•ˆ ì œì‹œ**: ì „ë‹¨ì§€ê°€ ë¶€ì í•©í•œ ê²½ìš° ì˜¨ë¼ì¸ ë§ˆì¼€íŒ… ëŒ€ì•ˆ ì œì‹œ

## ğŸ“‹ ì¶œì²˜ í‘œê¸° (í•„ìˆ˜)
ëª¨ë“  ë‹µë³€ ë§ˆì§€ë§‰ì—:
ğŸ“‹ **ì°¸ê³  ìë£Œ:**
- Google Maps API: [êµ¬ì²´ì  ë‚´ìš©]
- marketing_analysis.json: [ì „ëµ ë²ˆí˜¸]
- panorama_analysis.json: [í•­ëª©ëª…]
- store_analysis.json: [ì„¹ì…˜ëª…]
- ì „ë‹¨ì§€ ìœ„ì¹˜ ì¶”ì²œ: [íŒŒë…¸ë¼ë§ˆ + ë§¤ì¥ ë°ì´í„° ë¶„ì„]

### 9. **ë¬¸ì„œ ë‚´ìš© ìƒì„¸ ì„¤ëª… (ì‹ ê·œ ì¶”ê°€)**
ë°ì´í„°ë¥¼ ì°¸ì¡°í•  ë•ŒëŠ” íŒŒì¼ëª…ë¿ë§Œ ì•„ë‹ˆë¼ **êµ¬ì²´ì ì¸ ë‚´ìš©ê³¼ ì˜ë¯¸**ë¥¼ ì„¤ëª…í•˜ì„¸ìš”:

ì˜ˆì‹œ 1:
- âŒ ë‚˜ìœ ë‹µë³€: "marketing_result.jsonì„ ë³´ë©´..."
- âœ… ì¢‹ì€ ë‹µë³€: "marketing_result.jsonì˜ 'ë§ˆì¼€íŒ… ì „ëµ 2: ê³„ì ˆë³„ ì‹œê·¸ë‹ˆì²˜ ë©”ë‰´ ê°œë°œ' ë¶„ì„ì— ë”°ë¥´ë©´, 
  'ì¼ìƒ ì† ì‘ì€ ì—¬ìœ ' ì½˜ì…‰íŠ¸ë¡œ ê³„ì ˆ ì¬ë£Œë¥¼ í™œìš©í•œ í•œì •íŒ ë©”ë‰´ë¥¼ ì¶”ì²œí•˜ê³  ìˆìŠµë‹ˆë‹¤. 
  ì´ ì „ëµì€ ë§¤ì¥ì˜ ì¬ë°©ë¬¸ìœ¨ ì €í•˜(R2 ìœ„í—˜)ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ í•µì‹¬ ë°©ì•ˆ ì¤‘ í•˜ë‚˜ë¡œ ì œì‹œë˜ì—ˆìŠµë‹ˆë‹¤."

ì˜ˆì‹œ 2:
- âŒ ë‚˜ìœ ë‹µë³€: "store_analysis.jsonì˜ ê³ ê° ë¶„ì„ì„ ë³´ë©´..."
- âœ… ì¢‹ì€ ë‹µë³€: "store_analysis.jsonì˜ 'customer_type_analysis' ì„¹ì…˜ì„ ë³´ë©´, 
  ì¬ë°©ë¬¸ ê³ ê° ë¹„ìœ¨ì´ [ì‹¤ì œ ìˆ˜ì¹˜]%ë¡œ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤. ì´ëŠ” í•œì‹ ì—…ì¢… í‰ê·  ì¬ë°©ë¬¸ìœ¨([ì—…ì¢… í‰ê· ]%)ê³¼ ë¹„êµí•˜ì—¬ 
  [ì°¨ì´]%p [ë‚®ìŒ/ë†’ìŒ] ìˆ˜ì¹˜ë¡œ, [R2 ìœ„í—˜ ìš”ì†Œ ê°ì§€ ì—¬ë¶€]ë¥¼ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. 
  ë˜í•œ 'customer_type_analysis'ì˜ 'new_customers' ë¹„ìœ¨ì€ [ì‹ ê·œ ê³ ê° ë¹„ìœ¨]%ë¡œ ë‚˜íƒ€ë‚˜ ì‹ ê·œ ê³ ê° ìœ ì…ë„ [ê°œì„  í•„ìš”/ì–‘í˜¸]í•©ë‹ˆë‹¤."

ì˜ˆì‹œ 3:
- âŒ ë‚˜ìœ ë‹µë³€: "ìœ„í—˜ ì§„ë‹¨ì— R2ê°€ ìˆìŠµë‹ˆë‹¤."
- âœ… ì¢‹ì€ ë‹µë³€: "marketing_result.jsonì˜ 'risk_analysis.detected_risks' ë°°ì—´ì—ì„œ R2 ìœ„í—˜ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. 
  R2ëŠ” 'ì¬ë°©ë¬¸ìœ¨ ì €í•˜' ìœ„í—˜ìœ¼ë¡œ, ì¬ë°©ë¬¸ìœ¨ì´ ì—…ì¢… í‰ê·  ëŒ€ë¹„ 3% ì´ìƒ í•˜ë½í–ˆì„ ë•Œ íŠ¸ë¦¬ê±°ë©ë‹ˆë‹¤. 
  í˜„ì¬ ë§¤ì¥ì˜ ì¬ë°©ë¬¸ìœ¨ì€ [ì‹¤ì œ ìˆ˜ì¹˜]%ë¡œ í•œì‹ ì—…ì¢… í‰ê· ([ì—…ì¢… í‰ê· ]%)ë³´ë‹¤ [ì°¨ì´]%p [ë‚®ìŒ/ë†’ìŒ]ì•„ [ë†’ì€ ìš°ì„ ìˆœìœ„/ë³´í†µ ìš°ì„ ìˆœìœ„]ë¡œ ë¶„ë¥˜ë˜ì—ˆìœ¼ë©°, 
  ê°€ì¤‘ì¹˜ [ê°€ì¤‘ì¹˜]ì , ì˜í–¥ë„ ì ìˆ˜(impact_score) [ì˜í–¥ë„]ì ì´ ë¶€ì—¬ë˜ì—ˆìŠµë‹ˆë‹¤. 
  ì™„í™” ì „ëµìœ¼ë¡œëŠ” [ì™„í™” ì „ëµ ëª©ë¡]ì´ ì œì•ˆë˜ì—ˆìŠµë‹ˆë‹¤."
### 10. **ì ìˆ˜ ë° ìœ„í—˜ ê³„ì‚° ë¡œì§ ì„¤ëª… (ì‹ ê·œ ì¶”ê°€)**
ì‚¬ìš©ìê°€ ì ìˆ˜ë‚˜ ìœ„í—˜ì— ëŒ€í•´ ì§ˆë¬¸í•  ë•ŒëŠ” **ê³„ì‚° ë°©ì‹ê³¼ ê·¼ê±°**ë¥¼ ëª…í™•íˆ ì„¤ëª…í•˜ì„¸ìš”:

**ë§ˆì¼€íŒ… ìœ„í—˜ ì ìˆ˜ (Risk Score) ê³„ì‚°:**
- ê° ìœ„í—˜ ì½”ë“œ(R1-R10)ëŠ” ê³ ìœ í•œ ê°€ì¤‘ì¹˜(threshold_value)ì™€ ì˜í–¥ë„ ì ìˆ˜(impact_score)ë¥¼ ê°€ì§‘ë‹ˆë‹¤
- ì‹¤ì œ ì ìˆ˜ëŠ” (ì‹¬ê°ë„ Ã— ê°€ì¤‘ì¹˜)ë¡œ ê³„ì‚°ë˜ë©°, ìµœëŒ€ 100ì ì…ë‹ˆë‹¤
- ì˜ˆ: R2(ì¬ë°©ë¬¸ìœ¨ ì €í•˜)ì˜ ì ìˆ˜ ê³„ì‚°: |[ì¬ë°©ë¬¸ìœ¨] - [ì—…ì¢… í‰ê· ]| Ã— 5 = [ê³„ì‚°ëœ ì ìˆ˜]ì 
- **ì¤‘ìš”**: ìœ„ì˜ "ë§¤ì¥ ì„±ê³¼" ì„¹ì…˜ì— ì œê³µëœ ì‹¤ì œ ì¬ë°©ë¬¸ìœ¨ ê°’ì„ ì‚¬ìš©í•˜ì„¸ìš”!

**ì „ì²´ ìœ„í—˜ ìˆ˜ì¤€ (Overall Risk Level) ê²°ì •:**
- ìœ„í—˜ ì ìˆ˜ë“¤ì˜ í‰ê· ì„ ê³„ì‚°í•©ë‹ˆë‹¤
- í‰ê·  80ì  ì´ìƒ: ìœ„í—˜(Critical)
- í‰ê·  60-79ì : ë†’ìŒ(High)
- í‰ê·  40-59ì : ë³´í†µ(Medium)
- í‰ê·  40ì  ë¯¸ë§Œ: ë‚®ìŒ(Low)

**ë§¤ì¥ ì„±ê³¼ ì ìˆ˜ (Store Performance Score) ê³„ì‚°:**
- CVI(Commercial Viability Index): ìƒì—…ì  ìƒì¡´ ê°€ëŠ¥ì„± ì§€ìˆ˜
- ASI(Accessibility Score Index): ì ‘ê·¼ì„± ì§€ìˆ˜
- SCI(Store Competitiveness Index): ë§¤ì¥ ê²½ìŸë ¥ ì§€ìˆ˜
- GMI(Growth & Market Index): ì„±ì¥ ë° ì‹œì¥ ì§€ìˆ˜
- ê° ì§€í‘œëŠ” 0-100ì  ë²”ìœ„ë¡œ ê³„ì‚°ë˜ë©°, ì „ì²´ ì ìˆ˜ëŠ” 4ê°œ ì§€í‘œì˜ í‰ê· ì…ë‹ˆë‹¤

**ë“±ê¸‰(Grade) ì‚°ì •:**
- 95ì  ì´ìƒ: A+
- 90-94ì : A
- 85-89ì : B+
- 80-84ì : B
- 75-79ì : C+
- 70-74ì : C
- 60-69ì : D
- 60ì  ë¯¸ë§Œ: F

## ğŸ—£ï¸ ë‹µë³€ ìŠ¤íƒ€ì¼
- ì¹œì ˆí•˜ì§€ë§Œ ì „ë¬¸ì 
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì 
- ì—¬ëŸ¬ ë°ì´í„°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í†µí•©
- ì‹¤í–‰ ê°€ëŠ¥í•œ ì•¡ì…˜ ì•„ì´í…œ ì œì‹œ
"""
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ êµ¬ì„±
        prompt_template = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            MessagesPlaceholder(variable_name="chat_history"),
            ("human", "{input}")
        ])
        
        # Chain ìƒì„± (ìµœì‹  Langchain ë°©ì‹)
        chain = prompt_template | llm
        
        print(f"[OK] Consultation chain created successfully")
        return chain, chat_history
        
    except Exception as e:
        print(f"[ERROR] Failed to create consultation chain: {e}")
        import traceback
        traceback.print_exc()
        return None, None


@observe()
def chat_with_consultant(chain, chat_history, user_message: str, store_data: dict = None, panorama_data: dict = None) -> str:
    """
    ìƒë‹´ ì²´ì¸ê³¼ ëŒ€í™” (Langfuse tracing í¬í•¨)
    
    Args:
        chain: Langchain Runnable (Prompt | LLM)
        chat_history: InMemoryChatMessageHistory ì¸ìŠ¤í„´ìŠ¤
        user_message: ì‚¬ìš©ì ë©”ì‹œì§€
        
    Returns:
        str: AI ì‘ë‹µ
    """
    try:
        print(f"[DEBUG] User: {user_message}")
        
        # ì „ë‹¨ì§€ ê´€ë ¨ ì§ˆë¬¸ì¸ì§€ í™•ì¸
        flyer_keywords = ["ì „ë‹¨ì§€", "ì˜¤í”„ë¼ì¸", "ë°°ë¶€", "ê´‘ê³ ", "ì „ë‹¨", "ë°°í¬", "í™ë³´"]
        is_flyer_question = any(keyword in user_message.lower() for keyword in flyer_keywords)
        
        # ì „ë‹¨ì§€ ê´€ë ¨ ì§ˆë¬¸ì´ ìˆê³  ë°ì´í„°ê°€ ìˆìœ¼ë©´ ë™ì  ë¶„ì„ ìˆ˜í–‰
        flyer_analysis = ""
        if is_flyer_question and store_data and panorama_data:
            print(f"[DEBUG] ì „ë‹¨ì§€ ê´€ë ¨ ì§ˆë¬¸ ê°ì§€ - ë™ì  ë¶„ì„ ì‹¤í–‰")
            flyer_recommendation = analyze_flyer_marketing_potential(store_data, panorama_data)
            
            if flyer_recommendation.get("recommended", False):
                persona = flyer_recommendation['persona_analysis']
                panorama_insights = flyer_recommendation['panorama_insights']
                
                flyer_analysis = f"""

### ğŸ“„ ì „ë‹¨ì§€ ê´‘ê³  ìœ„ì¹˜ ì¶”ì²œ (ê³ ë ¹ì¸µ íƒ€ê²Ÿ)
**ë§¤ì¥ í˜ë¥´ì†Œë‚˜:** ê³ ë ¹ì¸µ {persona['senior_ratio']:.1f}% + ì‹ ê·œê³ ê° {persona['new_customer_ratio']:.1f}% + {persona['commercial_area']}
**íŒŒë…¸ë¼ë§ˆ ë¶„ì„:** {panorama_insights['area_character'][:100]}...

**ì „ë‹¨ì§€ê°€ íš¨ê³¼ì ì¸ ì´ìœ :** {flyer_recommendation['why_flyer_effective']}

**ì¶”ì²œ ìœ„ì¹˜:**
"""
                for i, location in enumerate(flyer_recommendation['recommended_locations'], 1):
                    flyer_analysis += f"""
{i}. **{location['location']}**
   - ì„œ ìˆì„ ìœ„ì¹˜: {location['position']}
   - ì‹œê°„ëŒ€: {location['time_slot']}
   - íš¨ê³¼ì  ì´ìœ : {location['reason']}
   - ìŠ¤í¬ë¦½íŠ¸: "{location['script']}"
   - ì£¼ì˜ì‚¬í•­: {location['cautions']}
"""
            else:
                flyer_analysis = f"""

### ğŸ“„ ì „ë‹¨ì§€ ê´‘ê³  ì¶”ì²œ ê²°ê³¼
{flyer_recommendation.get('reason', 'ì „ë‹¨ì§€ ê´‘ê³ ê°€ ì í•©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')}
**ëŒ€ì•ˆ:** {flyer_recommendation.get('alternative', 'ì˜¨ë¼ì¸ ë§ˆì¼€íŒ…ì„ ì¶”ì²œí•©ë‹ˆë‹¤.')}
"""
        
        # ê¸°ì¡´ ëŒ€í™” ê¸°ë¡ ê°€ì ¸ì˜¤ê¸°
        history_messages = chat_history.messages
        
        # ì²´ì¸ ì‹¤í–‰ (chat_historyì™€ input ì „ë‹¬)
        # ì „ë‹¨ì§€ ë¶„ì„ ê²°ê³¼ê°€ ìˆìœ¼ë©´ ì‚¬ìš©ì ë©”ì‹œì§€ì— ì¶”ê°€
        enhanced_message = user_message
        if flyer_analysis:
            enhanced_message = f"{user_message}\n\n{flyer_analysis}"
        
        response = chain.invoke({
            "chat_history": history_messages,
            "input": enhanced_message
        })
        
        # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        chat_history.add_user_message(user_message)
        chat_history.add_ai_message(response.content)
        
        print(f"[DEBUG] AI: {response.content[:100]}...")
        
        return response.content
        
    except Exception as e:
        print(f"[ERROR] Chat failed: {e}")
        import traceback
        traceback.print_exc()
        return f"ì£„ì†¡í•©ë‹ˆë‹¤. ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
