"""
ì£¼ì†Œ ê¸°ë°˜ ì§€ì—­ ì¢…í•© ë¶„ì„ ëª¨ë“ˆ
- ì£¼ì†Œë¥¼ ì…ë ¥í•˜ë©´ ì¢Œí‘œë¡œ ë³€í™˜
- 300m ë²„í¼ ë‚´ì˜ ëª¨ë“  íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€ ìˆ˜ì§‘
- Gemini 2.5 Flashë¡œ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë¶„ì„ (OpenAI SDK í˜¸í™˜)
- ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± (ìƒê¶Œë¶„ìœ„ê¸°, ë„ë¡œë¶„ìœ„ê¸°, ì£¼ê±°/ìƒê°€, ì²­ê²°ë„ ë“±)
"""

import os
import pandas as pd
import geopandas as gpd
from shapely.geometry import Point, Polygon
import base64
from openai import OpenAI
import json
import re
from pathlib import Path
from dotenv import load_dotenv

# Langfuse tracing ì¶”ê°€ (ì˜¬ë°”ë¥¸ ë°©ì‹)
try:
    from langfuse import observe
    from langfuse.openai import openai as langfuse_openai
    LANGFUSE_AVAILABLE = True
    print("[OK] Langfuse initialized in PanoramaAnalysis")
except ImportError:
    print("[WARN] Langfuse not available in PanoramaAnalysis - tracing disabled")
    LANGFUSE_AVAILABLE = False
    langfuse_openai = None
from PIL import Image
import io
from datetime import datetime
import numpy as np
from typing import List, Dict, Optional
import folium
from folium import plugins
import shutil
import warnings
import time
warnings.filterwarnings('ignore')


def init_openai_client():
    """Gemini OpenAI í˜¸í™˜ API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”"""
    from pathlib import Path
    
    # í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ env íŒŒì¼ ì°¾ê¸°
    current_path = Path(__file__)
    root_path = current_path
    while root_path.parent != root_path:
        root_path = root_path.parent
        env_path = root_path / "env"
        if env_path.exists():
            load_dotenv(env_path, override=True)
            print(f"[Panorama] Loaded env from: {env_path}")
            break
    
    api_key = os.getenv('GEMINI_API_KEY')
    
    if not api_key:
        raise ValueError("GEMINI_API_KEYê°€ env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    print(f"[Panorama] Using API key: {api_key[:20]}...")
    
    # Gemini OpenAI í˜¸í™˜ API ì‚¬ìš©
    return OpenAI(
        api_key=api_key,
        base_url="https://generativelanguage.googleapis.com/v1beta/openai/"
    )


def address_to_coordinates(address: str) -> tuple:
    """
    ì£¼ì†Œë¥¼ ì¢Œí‘œë¡œ ë³€í™˜ (Google Maps / Kakao API ì‚¬ìš©)
    
    Parameters:
    -----------
    address : str
        í•œêµ­ ì£¼ì†Œ (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ì™•ì‹­ë¦¬ë¡œ 222")
        
    Returns:
    --------
    tuple : (longitude, latitude)
    """
    from geopy.geocoders import Nominatim
    import requests
    
    load_dotenv()
    
    # 1. Google Maps Geocoding API ì‹œë„ (ê°€ì¥ ì•ˆì •ì )
    google_key = os.getenv('GOOGLE_MAPS_API_KEY') or os.getenv('Google_Map_API_KEY')
    if google_key:
        url = 'https://maps.googleapis.com/maps/api/geocode/json'
        params = {
            'address': address,
            'key': google_key,
            'region': 'kr'  # í•œêµ­ ì§€ì—­ ìš°ì„ 
        }
        try:
            response = requests.get(url, params=params, timeout=(5, 15))
            if response.status_code == 200:
                result = response.json()
                if result.get('status') == 'OK' and result.get('results'):
                    location = result['results'][0]['geometry']['location']
                    lat = location['lat']
                    lon = location['lng']
                    print(f"[OK] Google Maps API: {address} -> ({lat:.6f}, {lon:.6f})")
                    return lon, lat
        except requests.RequestException as e:
            print(f"[WARN] Google Maps API ìš”ì²­ ì‹¤íŒ¨: {e}")
    
    # 2. Kakao API ì‹œë„
    kakao_key = os.getenv('KAKAO_REST_API_KEY')
    if kakao_key:
        url = 'https://dapi.kakao.com/v2/local/search/address.json'
        headers = {'Authorization': f'KakaoAK {kakao_key}'}
        params = {'query': address}
        try:
            # Add sane timeouts to avoid hanging on network issues
            response = requests.get(url, headers=headers, params=params, timeout=(5, 15))
            if response.status_code == 200:
                result = response.json()
                if result.get('documents'):
                    doc = result['documents'][0]
                    lon = float(doc['x'])
                    lat = float(doc['y'])
                    print(f"[OK] Kakao API: {address} -> ({lat:.6f}, {lon:.6f})")
                    return lon, lat
        except requests.RequestException as e:
            print(f"[WARN] Kakao API ìš”ì²­ ì‹¤íŒ¨: {e}")
    
    # 3. Fallback: Nominatim (ë¬´ë£Œ, ëŠë¦¼) - ëª¨ë“  í™˜ê²½ì—ì„œ ì‚¬ìš© ê°€ëŠ¥
    print("[INFO] API í‚¤ ì—†ìŒ - Nominatim ì‚¬ìš© (ëŠë¦´ ìˆ˜ ìˆìŒ)")
    try:
        geolocator = Nominatim(user_agent="street_analyzer")
        # Nominatim can be slow; provide a timeout
        location = geolocator.geocode(address, timeout=15)
        
        if location:
            print(f"[OK] Nominatim: {address} -> ({location.latitude:.6f}, {location.longitude:.6f})")
            return location.longitude, location.latitude
        else:
            raise ValueError(f"[ERROR] ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {address}")
    except Exception as e:
        print(f"[ERROR] Nominatim ì ‘ê·¼ ì‹¤íŒ¨: {e}")
        raise ValueError(f"[ERROR] ì£¼ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {address}")


def find_images_in_buffer(center_lon: float, 
                          center_lat: float, 
                          buffer_meters: float,
                          data_csv_path: str,
                          image_folder: str) -> List[Dict]:
    """
    ì¤‘ì‹¬ ì¢Œí‘œë¡œë¶€í„° ë²„í¼(ë°˜ê²½) ë‚´ì˜ ëª¨ë“  ì´ë¯¸ì§€ ì°¾ê¸°
    
    Parameters:
    -----------
    center_lon : float
        ì¤‘ì‹¬ì  ê²½ë„
    center_lat : float
        ì¤‘ì‹¬ì  ìœ„ë„
    buffer_meters : float
        ë²„í¼ ë°˜ê²½ (ë¯¸í„°)
    data_csv_path : str
        í¬ì¸íŠ¸ ë°ì´í„° CSV ê²½ë¡œ
    image_folder : str
        ì´ë¯¸ì§€ í´ë” ê²½ë¡œ
        
    Returns:
    --------
    List[Dict] : ë²„í¼ ë‚´ ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    """
    # CSV ë¡œë“œ (ê²½ë¡œ í™•ì¸)
    if not Path(data_csv_path).exists():
        # ìƒëŒ€ ê²½ë¡œë¡œ ë‹¤ì‹œ ì‹œë„
        current_dir = Path(__file__).parent
        data_csv_path = str(current_dir / "Step1_Result_final (1).csv")
    
    df = pd.read_csv(data_csv_path)
    
    # GeoDataFrame ìƒì„±
    geometry = [Point(xy) for xy in zip(df['pano_lon'], df['pano_lat'])]
    gdf = gpd.GeoDataFrame(df, geometry=geometry, crs='EPSG:4326')
    
    # UTMìœ¼ë¡œ íˆ¬ì˜ (ë¯¸í„° ë‹¨ìœ„ ê³„ì‚°ì„ ìœ„í•´)
    gdf_utm = gdf.to_crs('EPSG:5179')  # í•œêµ­ ì¤‘ë¶€ ì›ì  (ì„±ë™êµ¬ ì í•©)
    
    # ì¤‘ì‹¬ì  ìƒì„± ë° íˆ¬ì˜
    center_point = gpd.GeoDataFrame(
        [{'geometry': Point(center_lon, center_lat)}],
        crs='EPSG:4326'
    ).to_crs('EPSG:5179')
    
    # ë²„í¼ ìƒì„±
    buffer = center_point.geometry.buffer(buffer_meters)
    
    # ë²„í¼ ë‚´ ì ë“¤ í•„í„°ë§
    within_buffer_utm = gdf_utm[gdf_utm.geometry.within(buffer.iloc[0])].copy()
    
    # ì¤‘ì‹¬ì ìœ¼ë¡œë¶€í„°ì˜ ê±°ë¦¬ ê³„ì‚° (UTM ì¢Œí‘œê³„ì—ì„œ ë¯¸í„° ë‹¨ìœ„ë¡œ)
    within_buffer_utm['distance_m'] = within_buffer_utm.geometry.distance(
        center_point.geometry.iloc[0]
    )
    
    # ë‹¤ì‹œ WGS84ë¡œ ë³€í™˜ (ê±°ë¦¬ëŠ” ì´ë¯¸ ê³„ì‚°ë¨)
    within_buffer = within_buffer_utm.to_crs('EPSG:4326')
    
    # ì´ë¯¸ì§€ ì •ë³´ ìˆ˜ì§‘ (9ê°œ í´ë”ì—ì„œ ê²€ìƒ‰)
    images_info = []
    
    # 9ê°œ í´ë” ê²½ë¡œ ìƒì„±
    base_folder = Path(image_folder)
    image_folders = [
        base_folder,
        base_folder.parent / "downloaded_img_1",
        base_folder.parent / "downloaded_img_2", 
        base_folder.parent / "downloaded_img_3",
        base_folder.parent / "downloaded_img_4",
        base_folder.parent / "downloaded_img_5",
        base_folder.parent / "downloaded_img_6",
        base_folder.parent / "downloaded_img_7",
        base_folder.parent / "downloaded_img_8",
        base_folder.parent / "downloaded_img_9"
    ]
    
    for idx, row in within_buffer.iterrows():
        point_id = row['point_ID']
        pano_id = row['pano_id']
        
        # ì´ë¯¸ì§€ íŒŒì¼ëª…
        image_filename = f"point_{point_id}_pano_{pano_id}.jpg"
        
        # 9ê°œ í´ë”ì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸°
        image_path = None
        for folder in image_folders:
            potential_path = folder / image_filename
            if potential_path.exists():
                image_path = potential_path
                break
        
        if image_path:
            images_info.append({
                'point_id': int(point_id),
                'pano_id': pano_id,
                'lon': float(row['pano_lon']),
                'lat': float(row['pano_lat']),
                'distance_m': float(row['distance_m']),
                'image_path': str(image_path)
            })
    
    # ê±°ë¦¬ìˆœ ì •ë ¬
    images_info.sort(key=lambda x: x['distance_m'])
    
    return images_info


def extract_panorama_section(image_path: str, section: str = 'front') -> Image.Image:
    """
    íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€ì—ì„œ íŠ¹ì • ì„¹ì…˜ ì¶”ì¶œ
    
    Parameters:
    -----------
    image_path : str
        ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
    section : str
        ì¶”ì¶œí•  ì„¹ì…˜ ('front', 'back', 'left', 'right')
        
    Returns:
    --------
    PIL.Image : ì¶”ì¶œëœ ì´ë¯¸ì§€
    """
    img = Image.open(image_path)
    width, height = img.size
    
    # 1x6 íŒŒë…¸ë¼ë§ˆ ê°€ì •
    section_width = width // 6
    
    sections = {
        'left': (0, 0, section_width, height),
        'front': (section_width, 0, section_width * 2, height),
        'right': (section_width * 2, 0, section_width * 3, height),
        'back': (section_width * 3, 0, section_width * 4, height),
    }
    
    if section in sections:
        coords = sections[section]
        return img.crop(coords)
    else:
        return img.crop(sections['front'])

def _downscale_if_needed(pil_image: Image.Image, max_dim: int = 1024) -> Image.Image:
    """ê³¼ë„í•œ ì—…ë¡œë“œë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ì´ë¯¸ì§€ë¥¼ ì¶•ì†Œí•©ë‹ˆë‹¤."""
    if max(pil_image.size) <= max_dim:
        return pil_image
    img = pil_image.copy()
    img.thumbnail((max_dim, max_dim), Image.LANCZOS)
    return img


def encode_image_pil(pil_image: Image.Image, quality: int = 80, max_dim: int = 1024) -> str:
    """PIL ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”© (í¬ê¸° ì œí•œ ë° í’ˆì§ˆ ì¡°ì • í¬í•¨)"""
    img = _downscale_if_needed(pil_image, max_dim=max_dim)
    buffer = io.BytesIO()
    img.save(buffer, format='JPEG', quality=quality)
    return base64.b64encode(buffer.getvalue()).decode('utf-8')


def get_individual_analysis_prompt() -> str:
    """ê°œë³„ ì´ë¯¸ì§€ ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸"""
    return """ë‹¹ì‹ ì€ ìƒê¶Œ ì „ëµ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤. ì´ ê±°ë¦¬ ì´ë¯¸ì§€ë¥¼ ì„¸ë°€í•˜ê²Œ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.

[ë¶„ì„ ëª©ì ] 
ì´ ì§€ì ì˜ ìƒì—…ì  ê°€ì¹˜, ë³´í–‰ í™˜ê²½, ì²­ê²°ë„, ê±´ë¬¼ ìƒíƒœë¥¼ ì •ëŸ‰ì Â·ì •ì„±ì ìœ¼ë¡œ í‰ê°€í•©ë‹ˆë‹¤.

[ì¶œë ¥ í˜•ì‹]

{
  "report_metadata": {
    "analyst_persona": "ìƒê¶Œ ì „ëµ ì»¨ì„¤í„´íŠ¸",
    "analysis_type": "ì •ì„±ì  ì„œìˆ  ë° ì •ëŸ‰ì  ê°ì‚¬ë¥¼ ê²°í•©í•œ í•˜ì´ë¸Œë¦¬ë“œ ì‹œê° ë¶„ì„",
    "analysis_timestamp": "ìë™ìƒì„±"
  },
  
  "visit_summary": {
    "location_headline": "ì´ ì¥ì†Œì˜ ì²«ì¸ìƒì„ í•œ ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš” (ì˜ˆ: í™œê¸°ì°¬ ìƒì—…ì§€ì—­ì˜ ì¤‘ì‹¬ë¶€)",
    "overall_impression_prose": "ì´ ì¥ì†Œì— ëŒ€í•œ ì „ë°˜ì ì¸ ëŠë‚Œì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”. ê³µê°„ì˜ ë¶„ìœ„ê¸°, íŠ¹ì§•ì„ í¬í•¨í•˜ì„¸ìš”."
  },
  
  "virtual_walkthrough_notes": {
    "objective_sketch": {
      "space_and_buildings": "ëˆˆì— ë³´ì´ëŠ” ê³µê°„ê³¼ ê±´ë¬¼ì„ ë¬˜ì‚¬í•˜ì„¸ìš”. ê±´ë¬¼ ë†’ì´, í˜•íƒœ, ë°°ì¹˜, ìš©ë„ ë“±ì„ í¬í•¨í•˜ì„¸ìš”.",
      "street_details": "ë„ë¡œì™€ ë³´ë„ì˜ ìƒíƒœë¥¼ ë¬˜ì‚¬í•˜ì„¸ìš”. ë³´ë„ë¸”ëŸ­, ê°€ë¡œìˆ˜, ë²¤ì¹˜, ê°€ë¡œë“± ë“±ì„ í¬í•¨í•˜ì„¸ìš”."
    },
    "sensory_experience": {
      "dominant_colors_and_textures": "ì´ ê³µê°„ì„ ì§€ë°°í•˜ëŠ” ìƒ‰ê°ê³¼ ì¬ì§ˆê°ì„ ì„¤ëª…í•˜ì„¸ìš” (ë°ìŒ/ì–´ë‘ì›€, ê¹¨ë—í•¨/ë‚¡ìŒ ë“±)",
      "imagined_sounds": "ì´ê³³ì—ì„œ ë“¤ë¦´ ë²•í•œ ì†Œë¦¬ë¥¼ ìƒìƒí•˜ì—¬ ë¬˜ì‚¬í•˜ì„¸ìš” (ì°¨ëŸ‰ ì†Œë¦¬, ì‚¬ëŒë“¤ ëª©ì†Œë¦¬, ì¡°ìš©í•¨ ë“±)"
    }
  },
  
  "people_and_energy": {
    "observed_tribes_description": "ë³´ì´ëŠ” ì‚¬ëŒë“¤ì˜ ìœ í˜•ê³¼ íŠ¹ì§•ì„ ë¬˜ì‚¬í•˜ì„¸ìš”. ì‚¬ëŒì´ ì—†ë‹¤ë©´ 'ì‚¬ëŒ ì—†ìŒ'ì´ë¼ê³  ì“°ì„¸ìš”.",
    "street_energy_level": "ê±°ë¦¬ì˜ ì—ë„ˆì§€ ë ˆë²¨ì„ í‘œí˜„í•˜ì„¸ìš” (í™œê¸°ì°¸/ì°¨ë¶„í•¨/ì¡°ìš©í•¨/ì¹¨ì²´ë¨ ì¤‘ ì„ íƒ)"
  },
  
  "commercial_ecosystem_insight": {
    "dominant_store_types": "ì´ ê±°ë¦¬ì˜ ì£¼ìš” ê°€ê²Œ ì¢…ë¥˜ë¥¼ ë‚˜ì—´í•˜ì„¸ìš” (ìŒì‹ì , ì¹´í˜, í¸ì˜ì  ë“±). ì—†ìœ¼ë©´ 'ìƒì  ì—†ìŒ'",
    "signs_of_change_or_stability": "ìƒê¶Œì˜ ë³€í™”ë‚˜ ì•ˆì •ì„± ì‹ í˜¸ë¥¼ ì„¤ëª…í•˜ì„¸ìš” (ì‹ ê·œ ê°œì—…, íì—…, ë¦¬ëª¨ë¸ë§ í”ì  ë“±)",
    "opportunity_for_target_business": {
      "business_category": "ì´ ì§€ì—­ì— ì í•©í•´ ë³´ì´ëŠ” ì—…ì¢… (ì˜ˆ: ì¹´í˜, ìŒì‹ì , í¸ì˜ì  ë“±)",
      "narrative_insight": "ì´ ë¶„ìœ„ê¸°ì—ì„œ í•´ë‹¹ ì—…ì¢…ì´ ë“¤ì–´ì„ ë‹¤ë©´ ì–´ë–¤ ì—­í• ê³¼ ì»¨ì…‰ìœ¼ë¡œ ì ‘ê·¼í•´ì•¼ í• ì§€ 2-3ë¬¸ì¥ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”."
    }
  },
  
  "final_verdict_from_expert": {
    "recommendation_prose": "ì´ ì¥ì†Œì— ëŒ€í•œ ìµœì¢… ì „ë¬¸ê°€ ì˜ê²¬ì„ 3-4ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ì°½ì—…ìë‚˜ íˆ¬ììì—ê²Œ ì‹¤ì§ˆì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”."
  },
  
  "quantitative_audit": {
    "commercial_vitality": {
      "Storefront_Count": "ì‹œì•¼ì— ë³´ì´ëŠ” ìƒì  ì „ë©´ ê°œìˆ˜ (ì •ìˆ˜)",
      "Operational_Status": "ì˜ì—… ì¤‘ì¸ ìƒì  ìˆ˜ (ì •ìˆ˜, íŒë‹¨ ë¶ˆê°€ì‹œ N/A)",
      "Customer_Presence": "ê³ ê°ì´ ë³´ì´ëŠ” ìƒì  ìˆ˜ (ì •ìˆ˜)",
      "Promotional_Activity": "í™ë³´ë¬¼ì´ ìˆëŠ” ìƒì  ìˆ˜ (ì •ìˆ˜)"
    },
    "street_attractiveness": {
      "Facade_Condition": "ê±´ë¬¼ ì™¸ê´€ ìƒíƒœ: 2(ê¹¨ë—í•˜ê³  ê´€ë¦¬ë¨) | 1(ë³´í†µ) | 0(ë‚¡ê³  ë°©ì¹˜ë¨)",
      "Design_Diversity": "ë””ìì¸ ë‹¤ì–‘ì„±: 2(ë‹¤ì–‘í•˜ê³  ê°œì„±ìˆìŒ) | 1(ë³´í†µ) | 0(ë‹¨ì¡°ë¡œì›€)",
      "Amenity_Presence": "í¸ì˜ì‹œì„¤: 2(ë²¤ì¹˜/ê·¸ëŠ˜ ë“± ë§ìŒ) | 1(ì¼ë¶€ ìˆìŒ) | 0(ì—†ìŒ)",
      "Brand_Type": "ë¸Œëœë“œ ìœ í˜•: 2(í”„ëœì°¨ì´ì¦ˆ ë§ìŒ) | 1(í˜¼í•©) | 0(ë…ë¦½ ìƒì  ìœ„ì£¼)"
    },
    "pedestrian_experience": {
      "Sidewalk_Clutter": "ë³´ë„ ìƒíƒœ: 2(ê¹¨ë—í•˜ê³  ë„“ìŒ) | 1(ë³´í†µ) | 0(ì–´ì§€ëŸ½ê±°ë‚˜ ì¢ìŒ)",
      "Weather_Protection": "ë‚ ì”¨ ë³´í˜¸: 2(ìºë…¸í”¼/ì°¨ì–‘ ìˆìŒ) | 1(ì¼ë¶€) | 0(ì—†ìŒ)",
      "Lighting_Proxy": "ì¡°ëª… ìƒíƒœ: 2(ë°ê³  ì¶©ë¶„) | 1(ë³´í†µ) | 0(ì–´ë‘¡ê±°ë‚˜ ë¶€ì¡±)"
    }
  }
}

[ì ìˆ˜ ê¸°ì¤€]
- ì •ìˆ˜ ì¹´ìš´íŠ¸ (Storefront_Count ë“±): ì‹¤ì œë¡œ ë³´ì´ëŠ” ê°œìˆ˜ë¥¼ ì„¸ì–´ ê¸°ì…í•˜ì„¸ìš”
- 0-2 ì ìˆ˜: 2=ìš°ìˆ˜/ì¢‹ìŒ, 1=ë³´í†µ/í‰ê· , 0=ë‚˜ì¨/ì—´ì•…
- N/AëŠ” ì •ë§ íŒë‹¨ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš°ë§Œ ì‚¬ìš©í•˜ì„¸ìš”

[ì¤‘ìš”] 
ì˜¤ì§ JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ì„¸ìš”. ë§ˆí¬ë‹¤ìš´ì´ë‚˜ ì¶”ê°€ ì„¤ëª…ì„ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""


def get_synthesis_prompt(individual_results: List[Dict]) -> str:
    """ì¢…í•© ë¶„ì„ìš© í”„ë¡¬í”„íŠ¸"""
    summary = f"ì´ {len(individual_results)}ê°œ ì§€ì ì˜ ê°œë³„ ë¶„ì„ ê²°ê³¼:\n\n"
    
    for i, result in enumerate(individual_results[:10], 1):  # ìµœëŒ€ 10ê°œë§Œ í¬í•¨
        analysis = result.get('analysis', {})
        visit = analysis.get('visit_summary', {})
        commercial = analysis.get('commercial_ecosystem_insight', {})
        energy = analysis.get('people_and_energy', {})
        
        summary += f"ì§€ì  {i} (ì¤‘ì‹¬ì—ì„œ {result['distance_m']:.0f}m):\n"
        summary += f"   í—¤ë“œë¼ì¸: {visit.get('location_headline', 'N/A')}\n"
        summary += f"   ì£¼ìš” ìƒì : {commercial.get('dominant_store_types', 'N/A')}\n"
        summary += f"   ì—ë„ˆì§€: {energy.get('street_energy_level', 'N/A')}\n"
        
        # ì •ëŸ‰ ì§€í‘œë„ í¬í•¨
        quant = analysis.get('quantitative_audit', {})
        if quant:
            cv = quant.get('commercial_vitality', {})
            summary += f"   ìƒì ìˆ˜: {cv.get('Storefront_Count', 'N/A')}, "
            summary += f"ì˜ì—…ì¤‘: {cv.get('Operational_Status', 'N/A')}\n"
        summary += "\n"
    
    if len(individual_results) > 10:
        summary += f"... ì™¸ {len(individual_results) - 10}ê°œ ì§€ì  ë°ì´í„° ìƒëµ\n\n"
    
    prompt = f"""[ìƒê¶Œ ì „ëµ ì»¨ì„¤í„´íŠ¸ ì¢…í•© ë¶„ì„]

{summary}

[ë‹¹ì‹ ì˜ ì„ë¬´]
ìœ„ì˜ ê°œë³„ ì§€ì  ë¶„ì„ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬, ì´ ì§€ì—­ ì „ì²´ì˜ íŠ¹ì„±ì„ í‰ê°€í•˜ê³  ìƒì—…ì  ì ì¬ë ¥ì„ ì§„ë‹¨í•˜ì„¸ìš”.
ë‹¨ìˆœ í‰ê· ì´ ì•„ë‹Œ, ì „ì²´ì ì¸ íŒ¨í„´ê³¼ íë¦„ì„ íŒŒì•…í•˜ì—¬ í†µì°°ë ¥ ìˆëŠ” ì¢…í•© ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[ì¶œë ¥ í˜•ì‹]

{{
  "area_summary": {{
    "overall_character": "ì´ ì§€ì—­ì˜ ì „ë°˜ì ì¸ íŠ¹ì„±ì„ 2-3ë¬¸ì¥ìœ¼ë¡œ ì¢…í•© ì„œìˆ í•˜ì„¸ìš”. ìƒê¶Œ ì„±ê²©, ê³µê°„ íŠ¹ì„±, ë¶„ìœ„ê¸° ë“±ì„ í†µí•©ì ìœ¼ë¡œ ê¸°ìˆ í•˜ì„¸ìš”.",
    "dominant_zone_type": "ì£¼ê±°ì§€ì—­|ìƒì—…ì§€ì—­|í˜¼í•©ì§€ì—­|ê³µì—…ì§€ì—­|ê³µì›/ë…¹ì§€ ì¤‘ í•˜ë‚˜ ì„ íƒ",
    "primary_commercial_type": "ì´ ì§€ì—­ ìƒê¶Œì˜ ì£¼ìš” ìœ í˜•ì„ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ í•˜ì„¸ìš” (ì˜ˆ: ê·¼ë¦°í˜• ìƒí™œìƒê°€, ìœ í¥ ì¤‘ì‹¬ ìƒê¶Œ, ì¹´í˜ê±°ë¦¬ ë“±)"
  }},
  
  "comprehensive_scores": {{
    "commercial_atmosphere": "ìƒê¶Œ ë¶„ìœ„ê¸° ì ìˆ˜ (0-10): ìƒì—… í™œë™ì˜ í™œë°œí•¨, ë§¤ì¶œ ì ì¬ë ¥ ë“±ì„ ê³ ë ¤",
    "street_atmosphere": "ë„ë¡œ ë¶„ìœ„ê¸° ì ìˆ˜ (0-10): ê±°ë¦¬ì˜ ì¾Œì í•¨, ì‹œê°ì  ë§¤ë ¥ë„ ë“±ì„ ê³ ë ¤",
    "cleanliness": "ì²­ê²°ë„ ì ìˆ˜ (0-10): ê±°ë¦¬ ë° ê±´ë¬¼ì˜ ê¹¨ë—í•¨, ì“°ë ˆê¸° ê´€ë¦¬ ìƒíƒœ ë“±ì„ ê³ ë ¤",
    "maintenance": "ìœ ì§€ë³´ìˆ˜ ìƒíƒœ ì ìˆ˜ (0-10): ê±´ë¬¼, ë„ë¡œ, ì‹œì„¤ë¬¼ì˜ ê´€ë¦¬ ìƒíƒœ ë“±ì„ ê³ ë ¤",
    "walkability": "ë³´í–‰ í¸ì˜ì„± ì ìˆ˜ (0-10): ë³´í–‰ì ì¹œí™”ì„±, ì¸ë„ ìƒíƒœ, ì ‘ê·¼ì„± ë“±ì„ ê³ ë ¤",
    "safety_perception": "ì•ˆì „ ì¸ì‹ ì ìˆ˜ (0-10): ì¡°ëª…, ì‹œì•¼, ê´€ë¦¬ ìƒíƒœ ë“±ì—ì„œ ëŠê»´ì§€ëŠ” ì•ˆì „ê°ì„ ê³ ë ¤",
    "business_diversity": "ì—…ì¢… ë‹¤ì–‘ì„± ì ìˆ˜ (0-10): ë‹¤ì–‘í•œ ì—…ì¢…ì˜ í˜¼í•© ì •ë„, ì„ íƒì˜ í­ ë“±ì„ ê³ ë ¤",
    "residential_suitability": "ê±°ì£¼ ì í•©ë„ ì ìˆ˜ (0-10): ì£¼ê±°ì§€ë¡œì„œì˜ ì¾Œì ì„±ê³¼ í¸ì˜ì„±ì„ ê³ ë ¤",
    "commercial_suitability": "ìƒì—… ì í•©ë„ ì ìˆ˜ (0-10): ìƒì—… í™œë™ì„ ìœ„í•œ ì…ì§€ ë° í™˜ê²½ì˜ ì í•©ì„±ì„ ê³ ë ¤"
  }},
  
  "detailed_assessment": {{
    "strengths": [
      "ì´ ì§€ì—­ì˜ ì£¼ìš” ê°•ì  1 (êµ¬ì²´ì ì´ê³  ì‹¤ì§ˆì ìœ¼ë¡œ)",
      "ì´ ì§€ì—­ì˜ ì£¼ìš” ê°•ì  2",
      "ì´ ì§€ì—­ì˜ ì£¼ìš” ê°•ì  3"
    ],
    "weaknesses": [
      "ì´ ì§€ì—­ì˜ ì£¼ìš” ì•½ì  1 (ê°œì„ ì´ í•„ìš”í•œ ë¶€ë¶„)",
      "ì´ ì§€ì—­ì˜ ì£¼ìš” ì•½ì  2",
      "ì´ ì§€ì—­ì˜ ì£¼ìš” ì•½ì  3"
    ],
    "recommended_business_types": [
      "ì´ ì§€ì—­ì— ì í•©í•œ ì—…ì¢… 1 (êµ¬ì²´ì ì¸ ì—…ì¢…ëª…)",
      "ì´ ì§€ì—­ì— ì í•©í•œ ì—…ì¢… 2",
      "ì´ ì§€ì—­ì— ì í•©í•œ ì—…ì¢… 3"
    ],
    "foot_traffic_estimate": "ìƒ|ì¤‘|í•˜ ì¤‘ í•˜ë‚˜ ì„ íƒ (ê´€ì°°ëœ ì¸êµ¬ ë°€ë„ ë° ìƒê¶Œ í™œë ¥ë„ ê¸°ë°˜)",
    "competition_level": "ë†’ìŒ|ë³´í†µ|ë‚®ìŒ ì¤‘ í•˜ë‚˜ ì„ íƒ (ê¸°ì¡´ ìƒì  ë°€ë„ ë° ê²½ìŸ ê°•ë„ ê¸°ë°˜)"
  }},
  
  "final_recommendation": "ìƒê¶Œ ì „ëµ ì»¨ì„¤í„´íŠ¸ë¡œì„œ ì´ ì§€ì—­ì— ëŒ€í•œ ìµœì¢… ì¢…í•© ì˜ê²¬ì„ 7-10ë¬¸ì¥ìœ¼ë¡œ ë§¤ìš° ìì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ìŒ ë‚´ìš©ì„ ëª¨ë‘ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤: (1) ì´ ì§€ì—­ì˜ ì „ë°˜ì ì¸ í‰ê°€ì™€ íŠ¹ì§•, (2) ìƒê¶Œì˜ ê°•ì ê³¼ í™œìš© ë°©ì•ˆ, (3) ì£¼ì˜í•´ì•¼ í•  ì•½ì ì´ë‚˜ ë¦¬ìŠ¤í¬, (4) ì¶”ì²œí•˜ëŠ” ì—…ì¢…ê³¼ ê·¸ ì´ìœ , (5) ì„±ê³µì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì „ëµì´ë‚˜ ì ‘ê·¼ë²•, (6) ì˜ˆìƒ íˆ¬ì ê·œëª¨ë‚˜ ìˆ˜ìµì„±ì— ëŒ€í•œ ê²¬í•´, (7) ìµœì¢… ì¶”ì²œ ì—¬ë¶€ì™€ ê·¼ê±°. ì°½ì—…ìë‚˜ íˆ¬ììê°€ ì‹¤ì§ˆì ì¸ ì˜ì‚¬ê²°ì •ì„ í•  ìˆ˜ ìˆë„ë¡ êµ¬ì²´ì ì´ê³  ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."
}}

[ì ìˆ˜ ì‚°ì • ê°€ì´ë“œë¼ì¸]
- 0-3ì : ë§¤ìš° ë‚˜ì¨, í° ë¬¸ì œ ìˆìŒ, íšŒí”¼ ê¶Œì¥
- 4-5ì : í‰ê·  ì´í•˜, ê°œì„  í•„ìš”
- 6-7ì : ë³´í†µ ìˆ˜ì¤€, í‰ê· ì 
- 8-9ì : ì¢‹ìŒ, ê²½ìŸë ¥ ìˆìŒ
- 10ì : ë§¤ìš° ìš°ìˆ˜, ìµœìƒê¸‰

[ì¤‘ìš” ì§€ì¹¨]
1. ê°œë³„ ì§€ì ë“¤ì˜ ë‹¨ìˆœ í‰ê· ì´ ì•„ë‹ˆë¼, ì „ì²´ì ì¸ íŒ¨í„´ê³¼ ê²½í–¥ì„±ì„ íŒŒì•…í•˜ì„¸ìš”
2. ëª¨ë“  ì ìˆ˜ëŠ” ì •ìˆ˜(0-10)ë¡œ ê¸°ì…í•˜ì„¸ìš”
3. ê°•ì /ì•½ì /ì¶”ì²œì—…ì¢…ì€ ê°ê° ì •í™•íˆ 3ê°œì”© ì‘ì„±í•˜ì„¸ìš”
4. final_recommendationì€ ë°˜ë“œì‹œ 7-10ë¬¸ì¥ìœ¼ë¡œ ë§¤ìš° ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”
5. JSON í˜•ì‹ë§Œ ì¶œë ¥í•˜ê³ , ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”"""
    
    return prompt


def _chat_with_retry(client: OpenAI, *, messages, model: str = "gemini-2.5-flash", temperature: float = 0.3, timeout: float = None, max_retries: int = 2, backoff_base: float = 1.5):
    """Gemini Chat Completions í˜¸ì¶œì„ ì¬ì‹œë„/íƒ€ì„ì•„ì›ƒê³¼ í•¨ê»˜ ìˆ˜í–‰ (OpenAI SDK í˜¸í™˜)"""
    last_err = None
    for attempt in range(1, max_retries + 2):
        try:
            kwargs = {
                "model": model,
                "temperature": temperature,
                "messages": messages,
            }
            if timeout is not None:
                kwargs["timeout"] = timeout
            return client.chat.completions.create(**kwargs)
        except Exception as e:
            last_err = e
            wait = backoff_base ** attempt + (0.1 * attempt)
            print(f"      [WARN] Gemini API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt}): {e.__class__.__name__}: {e}")
            if attempt <= max_retries:
                print(f"      [INFO] {wait:.1f}s í›„ ì¬ì‹œë„")
                time.sleep(wait)
            else:
                break
    raise last_err


@observe()
def analyze_image_with_gpt(client: OpenAI, 
                           image_path: str, 
                           prompt: str) -> Dict:
    """Gemini 2.5 Flashë¡œ ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„"""
    # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (í…ŒìŠ¤íŠ¸/ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ë°©ì§€)
    if os.getenv("SIMULATE_OPENAI", "0") == "1":
        return {
            "report_metadata": {"analyst_persona": "ìƒê¶Œ ì „ëµ ì»¨ì„¤í„´íŠ¸", "analysis_type": "simulate", "analysis_timestamp": datetime.now().isoformat()},
            "visit_summary": {"location_headline": "ì‹œë®¬ë ˆì´ì…˜ ì‘ë‹µ", "overall_impression_prose": "í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì‘ë‹µ"},
        }

    # ì´ë¯¸ì§€ ì¶”ì¶œ ë° ì¸ì½”ë”©
    extracted_image = extract_panorama_section(image_path, 'front')
    base64_image = encode_image_pil(extracted_image, quality=80, max_dim=1024)

    # í™˜ê²½ì„¤ì • ê¸°ë°˜ íƒ€ì„ì•„ì›ƒê³¼ ì¬ì‹œë„ ì„¤ì • (ê¸°ë³¸: íƒ€ì„ì•„ì›ƒ ì—†ìŒ)
    load_dotenv()
    if os.getenv("OPENAI_NO_TIMEOUT", "0") == "1":
        timeout_s = None
    else:
        if os.getenv("OPENAI_TIMEOUT"):
            try:
                timeout_s = float(os.getenv("OPENAI_TIMEOUT"))
            except Exception:
                timeout_s = None
        else:
            timeout_s = None
    try:
        max_retries = int(os.getenv("OPENAI_MAX_RETRIES", "2"))
    except Exception:
        max_retries = 2

    print("      [INFO] Gemini API í˜¸ì¶œ ì‹œì‘ (ì´ë¯¸ì§€ ì—…ë¡œë“œ, ì œí•œëœ í¬ê¸°)")
    start_ts = time.time()
    response = _chat_with_retry(
        client,
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}},
                ],
            }
        ],
        model="gemini-2.5-flash",
        temperature=0.3,
        timeout=timeout_s,
        max_retries=max_retries,
    )
    elapsed = time.time() - start_ts
    print(f"      [OK] Gemini API ì‘ë‹µ ìˆ˜ì‹  ({elapsed:.1f}s ì†Œìš”)")

    result_text = response.choices[0].message.content
    
    # ì‘ë‹µ ì²´í¬
    if not result_text or result_text.strip() == "":
        print(f"[ERROR] Gemini ë¹ˆ ì‘ë‹µ ë°˜í™˜")
        return {
            "error": "Empty response from Gemini",
            "description": "ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨ (ë¹ˆ ì‘ë‹µ)"
        }
    
    # JSON íŒŒì‹±
    try:
        json_pattern = r'```json\s*(.*?)\s*```|(\{.*\})'
        matches = re.search(json_pattern, result_text, re.DOTALL)
        
        if matches:
            json_str = matches.group(1) if matches.group(1) else matches.group(2)
        else:
            json_str = result_text.strip()
        
        return json.loads(json_str)
    except Exception as e:
        print(f"[ERROR] JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"[DEBUG] ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì): {result_text[:200]}")
        return {
            "error": str(e),
            "raw_response": result_text,
            "description": "ì´ë¯¸ì§€ ë¶„ì„ ì‹¤íŒ¨ (JSON íŒŒì‹± ì˜¤ë¥˜)"
        }


def synthesize_analysis(client: OpenAI, individual_results: List[Dict]) -> Dict:
    """ê°œë³„ ë¶„ì„ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±"""
    # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
    if os.getenv("SIMULATE_OPENAI", "0") == "1":
        return {
            "area_summary": {"dominant_zone_type": "ì‹œë®¬ë ˆì´ì…˜"},
            "comprehensive_scores": {"commercial_atmosphere": 7, "street_atmosphere": 7, "cleanliness": 7, "walkability": 7, "business_diversity": 7},
            "detailed_assessment": {"strengths": ["ë”ë¯¸"], "weaknesses": ["ë”ë¯¸"], "recommended_business_types": ["ë”ë¯¸"]},
            "final_recommendation": "ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼",
        }

    prompt = get_synthesis_prompt(individual_results)

    load_dotenv()
    if os.getenv("OPENAI_NO_TIMEOUT", "0") == "1":
        timeout_s = None
    else:
        if os.getenv("OPENAI_TIMEOUT"):
            try:
                timeout_s = float(os.getenv("OPENAI_TIMEOUT"))
            except Exception:
                timeout_s = None
        else:
            timeout_s = None
    try:
        max_retries = int(os.getenv("OPENAI_MAX_RETRIES", "2"))
    except Exception:
        max_retries = 2

    print("      [INFO] Gemini ì¢…í•© ë¶„ì„ í˜¸ì¶œ ì‹œì‘")
    start_ts = time.time()
    response = _chat_with_retry(
        client,
        messages=[
            {"role": "user", "content": prompt}
        ],
        model="gemini-2.5-flash",
        temperature=0.3,
        timeout=timeout_s,
        max_retries=max_retries,
    )
    elapsed = time.time() - start_ts
    print(f"      [OK] ì¢…í•© ë¶„ì„ ì‘ë‹µ ìˆ˜ì‹  ({elapsed:.1f}s ì†Œìš”)")

    result_text = response.choices[0].message.content
    
    # ì‘ë‹µ ì²´í¬
    if not result_text or result_text.strip() == "":
        print(f"[ERROR] Gemini ë¹ˆ ì‘ë‹µ ë°˜í™˜ (ì¢…í•© ë¶„ì„)")
        return {
            "error": "Empty response from Gemini",
            "analysis_type": "synthesis"
        }
    
    # JSON íŒŒì‹±
    try:
        json_pattern = r'```json\s*(.*?)\s*```|(\{.*\})'
        matches = re.search(json_pattern, result_text, re.DOTALL)
        
        if matches:
            json_str = matches.group(1) if matches.group(1) else matches.group(2)
        else:
            json_str = result_text.strip()
        
        return json.loads(json_str)
    except Exception as e:
        print(f"[ERROR] ì¢…í•© ë¶„ì„ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        print(f"[DEBUG] ì¢…í•© ë¶„ì„ ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 200ì): {result_text[:200]}")
        return {
            "error": str(e),
            "raw_response": result_text,
            "analysis_type": "synthesis"
        }


def create_analysis_map(center_lon: float, 
                        center_lat: float, 
                        buffer_meters: float,
                        analyzed_images: List[Dict],
                        synthesis: Dict,
                        output_path: str = "analysis_map.html") -> str:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ ì§€ë„ë¡œ ì‹œê°í™”
    
    Parameters:
    -----------
    center_lon : float
        ì¤‘ì‹¬ì  ê²½ë„
    center_lat : float
        ì¤‘ì‹¬ì  ìœ„ë„
    buffer_meters : float
        ë²„í¼ ë°˜ê²½ (ë¯¸í„°)
    analyzed_images : List[Dict]
        ë¶„ì„ëœ ì´ë¯¸ì§€ ì •ë³´ ë¦¬ìŠ¤íŠ¸
    synthesis : Dict
        ì¢…í•© ë¶„ì„ ê²°ê³¼
    output_path : str
        ì €ì¥í•  HTML íŒŒì¼ ê²½ë¡œ
        
    Returns:
    --------
    str : ìƒì„±ëœ HTML íŒŒì¼ ê²½ë¡œ
    """
    # ì§€ë„ ìƒì„±
    m = folium.Map(
        location=[center_lat, center_lon],
        zoom_start=16,
        tiles='OpenStreetMap'
    )
    
    # ì¤‘ì‹¬ì  ë§ˆì»¤
    folium.Marker(
        [center_lat, center_lon],
        popup=f"<b>ë¶„ì„ ì¤‘ì‹¬ì </b><br>ìœ„ë„: {center_lat:.6f}<br>ê²½ë„: {center_lon:.6f}",
        tooltip="ë¶„ì„ ì¤‘ì‹¬ì ",
        icon=folium.Icon(color='red', icon='star', prefix='fa')
    ).add_to(m)
    
    # ë²„í¼ ì›
    folium.Circle(
        [center_lat, center_lon],
        radius=buffer_meters,
        color='blue',
        fill=True,
        fillColor='blue',
        fillOpacity=0.1,
        popup=f"<b>ë¶„ì„ ë²”ìœ„</b><br>ë°˜ê²½: {buffer_meters}m",
        tooltip=f"ë¶„ì„ ë²”ìœ„ ({buffer_meters}m)"
    ).add_to(m)
    
    # ë¶„ì„ëœ ì§€ì ë“¤ í‘œì‹œ
    for i, img_info in enumerate(analyzed_images, 1):
        lat = img_info['lat']
        lon = img_info['lon']
        distance = img_info['distance_m']
        
        # ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
        analysis = img_info.get('analysis', {})
        visit = analysis.get('visit_summary', {})
        commercial = analysis.get('commercial_ecosystem_insight', {})
        quant = analysis.get('quantitative_audit', {})
        
        # íŒì—… ë‚´ìš© êµ¬ì„±
        popup_html = f"""
        <div style='width:300px'>
            <h4>ì§€ì  {i}</h4>
            <hr>
            <b>ê±°ë¦¬:</b> {distance:.1f}m<br>
            <b>Point ID:</b> {img_info['point_id']}<br>
            <br>
            <b>ì²«ì¸ìƒ:</b><br>
            {visit.get('location_headline', 'N/A')}<br>
            <br>
            <b>ì£¼ìš” ìƒì :</b><br>
            {commercial.get('dominant_store_types', 'N/A')}<br>
            <br>
        """
        
        # ì •ëŸ‰ ì§€í‘œ ì¶”ê°€
        if quant:
            cv = quant.get('commercial_vitality', {})
            popup_html += f"""
            <b>ì •ëŸ‰ ì§€í‘œ:</b><br>
            - ìƒì  ìˆ˜: {cv.get('Storefront_Count', 'N/A')}<br>
            - ì˜ì—…ì¤‘: {cv.get('Operational_Status', 'N/A')}<br>
            """
        
        popup_html += "</div>"
        
        # ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒ (ê°€ê¹Œìš¸ìˆ˜ë¡ ì§„í•œ ë…¹ìƒ‰)
        if distance < buffer_meters * 0.3:
            color = 'darkgreen'
        elif distance < buffer_meters * 0.7:
            color = 'green'
        else:
            color = 'lightgreen'
        
        folium.CircleMarker(
            [lat, lon],
            radius=8,
            color=color,
            fill=True,
            fillColor=color,
            fillOpacity=0.7,
            popup=folium.Popup(popup_html, max_width=350),
            tooltip=f"ì§€ì  {i} ({distance:.0f}m)"
        ).add_to(m)
    
    # ì¢…í•© ë¶„ì„ ê²°ê³¼ë¥¼ ì§€ë„ì— ì¶”ê°€
    if synthesis and "area_summary" in synthesis:
        area_summary = synthesis['area_summary']
        scores = synthesis.get('comprehensive_scores', {})
        
        legend_html = f"""
        <div style='position: fixed; 
                    bottom: 50px; right: 50px; width: 350px; height: auto; 
                    background-color: white; z-index:9999; font-size:14px;
                    border:2px solid grey; border-radius: 5px; padding: 10px;
                    box-shadow: 2px 2px 6px rgba(0,0,0,0.3);'>
            <h4 style='margin-top:0'>ì¢…í•© ë¶„ì„ ê²°ê³¼</h4>
            <hr>
            <b>ì§€ì—­ ìœ í˜•:</b> {area_summary.get('dominant_zone_type', 'N/A')}<br>
            <b>ìƒê¶Œ ìœ í˜•:</b> {area_summary.get('primary_commercial_type', 'N/A')}<br>
            <br>
            <b>ì¢…í•© ì ìˆ˜:</b><br>
            <div style='margin-left: 10px'>
                ìƒê¶Œ ë¶„ìœ„ê¸°: {scores.get('commercial_atmosphere', 'N/A')}/10<br>
                ë„ë¡œ ë¶„ìœ„ê¸°: {scores.get('street_atmosphere', 'N/A')}/10<br>
                ì²­ê²°ë„: {scores.get('cleanliness', 'N/A')}/10<br>
                ë³´í–‰í™˜ê²½: {scores.get('walkability', 'N/A')}/10<br>
            </div>
        </div>
        """
        m.get_root().html.add_child(folium.Element(legend_html))
    
    # ì €ì¥
    m.save(output_path)
    print(f"[ì§€ë„] ì‹œê°í™” ì €ì¥: {output_path}")
    
    return output_path
def create_image_locations_map(center_lon: float, 
                                center_lat: float, 
                                buffer_meters: float,
                                analyzed_images: List[Dict],
                                output_path: str = "image_locations_map.html") -> str:
    """
    íŒŒë…¸ë¼ë§ˆ ì´ë¯¸ì§€ ìœ„ì¹˜ë§Œ í‘œì‹œí•˜ëŠ” ê°„ë‹¨í•œ ì§€ë„ ìƒì„±
    """
    # ì§€ë„ ìƒì„±
    m = folium.Map(
        location=[center_lat, center_lon],
        zoom_start=16,
        tiles='OpenStreetMap'
    )
    
    # ì¤‘ì‹¬ì  ë§ˆì»¤
    folium.Marker(
        [center_lat, center_lon],
        popup=f"<b>ë¶„ì„ ì¤‘ì‹¬ì </b><br>ì£¼ì†Œ: ë¶„ì„ ëŒ€ìƒ ì§€ì—­",
        tooltip="ë¶„ì„ ì¤‘ì‹¬ì ",
        icon=folium.Icon(color='red', icon='star', prefix='fa')
    ).add_to(m)
    
    # ë²„í¼ ì›
    folium.Circle(
        [center_lat, center_lon],
        radius=buffer_meters,
        color='blue',
        fill=True,
        fillColor='blue',
        fillOpacity=0.1,
        popup=f"<b>ë¶„ì„ ë²”ìœ„</b><br>ë°˜ê²½: {buffer_meters}m",
        tooltip=f"ë¶„ì„ ë²”ìœ„ ({buffer_meters}m)"
    ).add_to(m)
    
    # ë¶„ì„ëœ ì§€ì ë“¤ í‘œì‹œ
    for i, img_info in enumerate(analyzed_images, 1):
        lat = img_info['lat']
        lon = img_info['lon']
        distance = img_info['distance_m']
        
        popup_html = f"""
        <div style='width:200px'>
            <h4>ğŸ“ íŒŒë…¸ë¼ë§ˆ ìœ„ì¹˜ {i}</h4>
            <hr>
            <b>ê±°ë¦¬:</b> {distance:.1f}m<br>
            <b>Point ID:</b> {img_info['point_id']}<br>
        </div>
        """
        
        # ê±°ë¦¬ì— ë”°ë¥¸ ìƒ‰ìƒ
        if distance < buffer_meters * 0.3:
            color = 'darkgreen'
        elif distance < buffer_meters * 0.7:
            color = 'green'
        else:
            color = 'lightgreen'
        
        folium.CircleMarker(
            [lat, lon],
            radius=10,
            color=color,
            fill=True,
            fillColor=color,
            fillOpacity=0.8,
            popup=folium.Popup(popup_html, max_width=250),
            tooltip=f"ğŸ“ íŒŒë…¸ë¼ë§ˆ {i} ({distance:.0f}m)"
        ).add_to(m)
    
    # ë²”ë¡€ ì¶”ê°€
    legend_html = """
    <div style='position: fixed; 
                bottom: 50px; right: 50px; width: 200px; height: auto; 
                background-color: white; z-index:9999; font-size:12px;
                border:2px solid grey; border-radius: 5px; padding: 10px;
                box-shadow: 2px 2px 6px rgba(0,0,0,0.3);'>
        <h4 style='margin-top:0'>ğŸ“ íŒŒë…¸ë¼ë§ˆ ìœ„ì¹˜ ì§€ë„</h4>
        <hr>
        <b>ë¹¨ê°„ ë³„:</b> ë¶„ì„ ì¤‘ì‹¬ì <br>
        <b>íŒŒë€ ì›:</b> ë¶„ì„ ë²”ìœ„<br>
        <b>ë…¹ìƒ‰ ì :</b> íŒŒë…¸ë¼ë§ˆ ìœ„ì¹˜<br>
        <br>
        <small>ê²€ì€ ë…¹ìƒ‰: ê°€ê¹Œìš´ ìœ„ì¹˜<br>
        ì´ˆë¡ìƒ‰: ì¤‘ê°„ ê±°ë¦¬<br>
        ì—°ë‘ìƒ‰: ë¨¼ ìœ„ì¹˜</small>
    </div>
    """
    m.get_root().html.add_child(folium.Element(legend_html))
    
    # ì €ì¥
    m.save(output_path)
    print(f"[ì§€ë„] ì´ë¯¸ì§€ ìœ„ì¹˜ ì§€ë„ ì €ì¥: {output_path}")
    
    return output_path

@observe()
def analyze_area_by_address(address: str,
                            buffer_meters: float = 300,
                            data_csv_path: Optional[str] = None,
                            image_folder: Optional[str] = None,
                            max_images: int = 5,
                            output_json_path: Optional[str] = None,
                            create_map: bool = True,
                            map_output_path: Optional[str] = None) -> Dict:
    """
    ì£¼ì†Œë¥¼ ì…ë ¥ë°›ì•„ í•´ë‹¹ ì§€ì—­ì˜ ì¢…í•© ë¶„ì„ ìˆ˜í–‰
    
    Parameters:
    -----------
    address : str
        ë¶„ì„í•  ì£¼ì†Œ (ì˜ˆ: "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ì™•ì‹­ë¦¬ë¡œ 222")
    buffer_meters : float
        ë¶„ì„ ë°˜ê²½ (ë¯¸í„°), ê¸°ë³¸ê°’ 300m
    data_csv_path : str, optional
        í¬ì¸íŠ¸ ë°ì´í„° CSV ê²½ë¡œ (.envì—ì„œ ìë™ ë¡œë“œ)
    image_folder : str, optional
        ì´ë¯¸ì§€ í´ë” ê²½ë¡œ (.envì—ì„œ ìë™ ë¡œë“œ)
    max_images : int
        ìµœëŒ€ ë¶„ì„í•  ì´ë¯¸ì§€ ê°œìˆ˜ (ë¹„ìš© ì ˆê°ìš©), ê¸°ë³¸ê°’ 5ê°œ
    output_json_path : str, optional
        ê²°ê³¼ë¥¼ ì €ì¥í•  JSON íŒŒì¼ ê²½ë¡œ
    create_map : bool
        ì§€ë„ ì‹œê°í™” ìƒì„± ì—¬ë¶€, ê¸°ë³¸ê°’ True
    map_output_path : str, optional
        ì§€ë„ HTML íŒŒì¼ ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: ìë™ ìƒì„±)
        
    Returns:
    --------
    Dict : ì¢…í•© ë¶„ì„ ê²°ê³¼
    
    Example:
    --------
    >>> result = analyze_area_by_address("ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ì™•ì‹­ë¦¬ë¡œ 222", buffer_meters=300)
    >>> print(result['synthesis']['comprehensive_scores']['commercial_atmosphere'])
    >>> print(result['synthesis']['final_recommendation'])
    """
    
    print("=" * 80)
    print("ì£¼ì†Œ ê¸°ë°˜ ì§€ì—­ ì¢…í•© ë¶„ì„ ì‹œì‘")
    print("=" * 80)
    
    # .envì—ì„œ ê²½ë¡œ ë¡œë“œ
    load_dotenv()
    
    if data_csv_path is None:
        data_csv_path = os.getenv('PANOID_FILE')
        if not data_csv_path:
            # ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½ (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€)
            current_dir = Path(__file__).parent
            data_csv_path = str(current_dir / "Step1_Result_final (1).csv")
    
    if image_folder is None:
        image_folder = os.getenv('IMAGE_FOLDER')
        if not image_folder:
            # ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½ (í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ê¸°ì¤€)
            current_dir = Path(__file__).parent
            image_folder = str(current_dir / "downloaded_img_1")  # ì²« ë²ˆì§¸ í´ë”ë¥¼ ê¸°ë³¸ìœ¼ë¡œ
    
    # 1. ì£¼ì†Œ -> ì¢Œí‘œ ë³€í™˜
    print(f"\n[ì£¼ì†Œ] {address}")
    print(f"[ì§€ì˜¤ì½”ë”©] ì£¼ì†Œ ë³€í™˜ ì¤‘...")
    center_lon, center_lat = address_to_coordinates(address)
    print(f"[OK] ì¢Œí‘œ: ({center_lat:.6f}, {center_lon:.6f})")
    
    # 2. ë²„í¼ ë‚´ ì´ë¯¸ì§€ ì°¾ê¸°
    print(f"\n[ê²€ìƒ‰] ë°˜ê²½ {buffer_meters}m ë‚´ì˜ ì´ë¯¸ì§€ ê²€ìƒ‰ ì¤‘...")
    images_info = find_images_in_buffer(
        center_lon, center_lat, buffer_meters,
        data_csv_path, image_folder
    )
    
    print(f"[OK] ì´ {len(images_info)}ê°œ ì´ë¯¸ì§€ ë°œê²¬")
    
    if len(images_info) == 0:
        return {
            "error": "ë²„í¼ ë‚´ì— ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.",
            "center_coordinates": {"lon": center_lon, "lat": center_lat},
            "buffer_meters": buffer_meters
        }
    
    # 3. ì´ë¯¸ì§€ ê°œìˆ˜ ì œí•œ
    if len(images_info) > max_images:
        print(f"[INFO] ì´ë¯¸ì§€ê°€ {len(images_info)}ê°œë¡œ ë§ì•„ ê°€ì¥ ê°€ê¹Œìš´ {max_images}ê°œë§Œ ë¶„ì„í•©ë‹ˆë‹¤.")
        images_info = images_info[:max_images]
    
    # 4. Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    print(f"\n[API] Gemini API ì´ˆê¸°í™” ì¤‘...")
    client = init_openai_client()
    
    # 5. ê°œë³„ ì´ë¯¸ì§€ ë¶„ì„
    print(f"\n[ë¶„ì„] ê°œë³„ ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ (ì´ {len(images_info)}ê°œ)...")
    individual_results = []
    individual_prompt = get_individual_analysis_prompt()
    
    for i, img_info in enumerate(images_info, 1):
        print(f"  [{i}/{len(images_info)}] Point {img_info['point_id']} (ê±°ë¦¬: {img_info['distance_m']:.1f}m) ë¶„ì„ ì¤‘...")
        
        try:
            analysis = analyze_image_with_gpt(
                client, 
                img_info['image_path'], 
                individual_prompt
            )
            
            individual_results.append({
                **img_info,
                'analysis': analysis
            })
            
            # ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥
            vsum = analysis.get('visit_summary', {})
            print(f"      [OK] ì™„ë£Œ - {vsum.get('location_headline', 'N/A')[:40]}...")
            
        except Exception as e:
            print(f"      [ERROR] ì˜¤ë¥˜: {e}")
            individual_results.append({
                **img_info,
                'analysis': {"error": str(e)}
            })
    
    # 6. ì¢…í•© ë¶„ì„
    print(f"\n[ì¢…í•©] ì¢…í•© ë¶„ì„ ìƒì„± ì¤‘...")
    synthesis = synthesize_analysis(client, individual_results)
    print(f"[OK] ì¢…í•© ë¶„ì„ ì™„ë£Œ")
    
    # 7. ê²°ê³¼ êµ¬ì„±
    result = {
        "metadata": {
            "input_address": address,
            "center_coordinates": {
                "longitude": center_lon,
                "latitude": center_lat
            },
            "buffer_meters": buffer_meters,
            "total_images_found": len(images_info),
            "images_analyzed": len(individual_results),
            "analysis_timestamp": datetime.now().isoformat()
        },
        "individual_analyses": individual_results,
        "synthesis": synthesis
    }
    
    # 8. output í´ë” êµ¬ì¡° ìƒì„± ë° íŒŒì¼ ì €ì¥
    print(f"\n[ì €ì¥] ê²°ê³¼ íŒŒì¼ ì €ì¥ ì¤‘...")
    
    # output í´ë” ìƒì„± (ìƒëŒ€ ê²½ë¡œë¡œ ë³€ê²½)
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    output_folder = f"open_sdk/output/analysis_{timestamp}"
    os.makedirs(output_folder, exist_ok=True)
    os.makedirs(f"{output_folder}/images", exist_ok=True)
    
    # 8-1. ì „ì²´ ë¶„ì„ ê²°ê³¼ JSON ì €ì¥ (ì¢…í•© ë¶„ì„ í¬í•¨)
    full_json_path = f"{output_folder}/analysis_result.json"
    with open(full_json_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    print(f"  [OK] ì „ì²´ ë¶„ì„ ê²°ê³¼ (ì¢…í•© ë¶„ì„ í¬í•¨): {full_json_path}")
    
    # 8-3. ë¶„ì„ì— ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë³µì‚¬
    print(f"\n[ë³µì‚¬] ë¶„ì„ì— ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë³µì‚¬ ì¤‘...")
    for i, img_info in enumerate(individual_results, 1):
        src_path = img_info['image_path']
        filename = Path(src_path).name
        dst_path = f"{output_folder}/images/{filename}"
        shutil.copy2(src_path, dst_path)
        print(f"  [{i}/{len(individual_results)}] {filename}")
    print(f"  [OK] ì´ {len(individual_results)}ê°œ ì´ë¯¸ì§€ ë³µì‚¬ ì™„ë£Œ")
    
    # 9. ì§€ë„ ì‹œê°í™” ìƒì„±
    if create_map:
        map_output_path = f"{output_folder}/analysis_map.html"
        create_analysis_map(
            center_lon, center_lat, buffer_meters,
            individual_results, synthesis,
            map_output_path
        )
        # 2. ì´ë¯¸ì§€ ìœ„ì¹˜ ì§€ë„ (íŒŒë…¸ë¼ë§ˆ ìœ„ì¹˜ë§Œ)
        image_locations_map_path = f"{panorama_dir}/image_locations_map.html"
        create_image_locations_map(
            center_lon, center_lat, buffer_meters,
            individual_results,
            image_locations_map_path
        )    
    # output í´ë” ê²½ë¡œë¥¼ ê²°ê³¼ì— ì¶”ê°€
    result['output_folder'] = output_folder
    
    # 10. ìš”ì•½ ì¶œë ¥
    print("\n" + "=" * 80)
    print("[ê²°ê³¼] ë¶„ì„ ê²°ê³¼ ìš”ì•½")
    print("=" * 80)
    print(f"\n[í´ë”] ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {output_folder}")
    print(f"  - analysis_result.json (ì „ì²´ ë¶„ì„ + ì¢…í•© ë¶„ì„)")
    print(f"  - analysis_map.html (ì§€ë„)")
    print(f"  - images/ ({len(individual_results)}ê°œ ì´ë¯¸ì§€)")
    
    if "area_summary" in synthesis:
        print(f"\n[íŠ¹ì„±] ì§€ì—­ íŠ¹ì„±: {synthesis['area_summary']['dominant_zone_type']}")
        print(f"[ìƒê¶Œ] ìƒê¶Œ ìœ í˜•: {synthesis['area_summary'].get('primary_commercial_type', 'N/A')}")
        
        if "comprehensive_scores" in synthesis:
            scores = synthesis['comprehensive_scores']
            print(f"\n[ì ìˆ˜] ì¢…í•© ì ìˆ˜:")
            print(f"   - ìƒê¶Œ ë¶„ìœ„ê¸°: {scores.get('commercial_atmosphere', 0)}/10")
            print(f"   - ë„ë¡œ ë¶„ìœ„ê¸°: {scores.get('street_atmosphere', 0)}/10")
            print(f"   - ì²­ê²°ë„: {scores.get('cleanliness', 0)}/10")
            print(f"   - ë³´í–‰í™˜ê²½: {scores.get('walkability', 0)}/10")
            print(f"   - ì—…ì¢…ë‹¤ì–‘ì„±: {scores.get('business_diversity', 0)}/10")
        
        if "detailed_assessment" in synthesis:
            assess = synthesis['detailed_assessment']
            print(f"\n[ê°•ì ]")
            for strength in assess.get('strengths', [])[:3]:
                print(f"   - {strength}")
            
            print(f"\n[ì•½ì ]")
            for weakness in assess.get('weaknesses', [])[:3]:
                print(f"   - {weakness}")
            
            print(f"\n[ì—…ì¢…] ì¶”ì²œ ì—…ì¢…:")
            for biz in assess.get('recommended_business_types', [])[:3]:
                print(f"   - {biz}")
        
        if "final_recommendation" in synthesis:
            print(f"\n[ì˜ê²¬] ì „ë¬¸ê°€ ì¢…í•© ì˜ê²¬:")
            print(f"   {synthesis['final_recommendation']}")
    
    print("\n" + "=" * 80)
    
    return result


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì˜ˆì œ
    test_address = "ì„œìš¸íŠ¹ë³„ì‹œ ì„±ë™êµ¬ ì™•ì‹­ë¦¬ë¡œ 222"
    
    result = analyze_area_by_address(
        address=test_address,
        buffer_meters=300,
        max_images=10  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 10ê°œë§Œ
    )
    
    print(f"\n\nê²°ê³¼ í´ë”: {result['output_folder']}")
    
    # ì§€ë„ ìë™ ì—´ê¸°
    import webbrowser
    map_path = f"{result['output_folder']}/analysis_map.html"
    webbrowser.open(map_path)
