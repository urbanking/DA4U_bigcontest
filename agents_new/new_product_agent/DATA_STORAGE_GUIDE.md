# ì‹ ì œí’ˆ ì œì•ˆ Agent - ë°ì´í„° ì €ì¥ ë° ì‚¬ìš© ê°€ì´ë“œ

## ğŸ“Š ë°ì´í„° íë¦„ ê°œìš”

```
StoreAgent ë¦¬í¬íŠ¸
    â†“
NewProductAgent ì‹¤í–‰
    â†“
ë„¤ì´ë²„ ë°ì´í„°ë© í¬ë¡¤ë§ â†’ [ë©”ëª¨ë¦¬] â†’ LLM ìƒì„±
    â†“                        â†“
    â†“                    [ì„ íƒ: íŒŒì¼ ì €ì¥]
    â†“                        â†“
ìµœì¢… ê²°ê³¼ (JSON)     í¬ë¡¤ë§ ê²°ê³¼ (JSON)
```

---

## ğŸ”„ ì‚¬ìš© ë°©ì‹

### 1ï¸âƒ£ ê¸°ë³¸: ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš© (íŒŒì¼ ì €ì¥ ì•ˆí•¨)

```python
import asyncio
from agents_new.new_product_agent import NewProductAgent

async def main():
    # íŒŒì¼ ì €ì¥ ì•ˆí•¨ (ê¸°ë³¸ê°’)
    agent = NewProductAgent(headless=True)
    
    result = await agent.run(store_report)
    
    # í¬ë¡¤ë§ ê²°ê³¼ëŠ” resultì— í¬í•¨ë¨
    keywords = result['keywords_top']
    # [{"category": "ìŒë£Œ", "rank": 1, "keyword": "í”¼ìŠ¤íƒ€ì¹˜ì˜¤"}, ...]
    
    # LLM ì œì•ˆë„ í¬í•¨ë¨
    proposals = result['proposals']
    # [{"menu_name": "í”¼ìŠ¤íƒ€ì¹˜ì˜¤ ë¼ë–¼", ...}, ...]

asyncio.run(main())
```

**ì¥ì :**
- âœ… ë¹ ë¦„ (ë””ìŠ¤í¬ I/O ì—†ìŒ)
- âœ… ê°„ë‹¨í•¨
- âœ… ì„ì‹œ ë¶„ì„ì— ì í•©

**ë‹¨ì :**
- âŒ ì¬ì‚¬ìš© ë¶ˆê°€ (ë§¤ë²ˆ í¬ë¡¤ë§ í•„ìš”)
- âŒ ê²°ê³¼ ì¶”ì  ì–´ë ¤ì›€

---

### 2ï¸âƒ£ íŒŒì¼ë¡œ ì €ì¥ (ê¶Œì¥)

```python
import asyncio
from agents_new.new_product_agent import NewProductAgent

async def main():
    # íŒŒì¼ ì €ì¥ í™œì„±í™” (ê¸°ë³¸ ìœ„ì¹˜: open_sdk/output)
    agent = NewProductAgent(
        headless=True,
        save_outputs=True  # âœ… íŒŒì¼ ì €ì¥
    )
    
    result = await agent.run(store_report)
    
    # ìë™ìœ¼ë¡œ íŒŒì¼ ìƒì„±:
    # open_sdk/output/naver_datalab_{timestamp}/
    #   â”œâ”€â”€ {store_code}_keywords.json
    #   â””â”€â”€ {store_code}_new_product_result.json

asyncio.run(main())
```

**ì €ì¥ë˜ëŠ” íŒŒì¼:**

#### í´ë” êµ¬ì¡°
```
open_sdk/output/
â”œâ”€â”€ analysis_{store_code}_{timestamp}/    # ê¸°ì¡´: ë§¤ì¥ ë¶„ì„
â”œâ”€â”€ marketplace_{timestamp}/              # ê¸°ì¡´: ìƒê¶Œ ë¶„ì„
â”œâ”€â”€ mobility_{timestamp}/                 # ê¸°ì¡´: ì´ë™ ë¶„ì„
â””â”€â”€ naver_datalab_{timestamp}/            # âœ… NEW: ì‹ ì œí’ˆ ì œì•ˆ
    â”œâ”€â”€ {store_code}_keywords.json
    â””â”€â”€ {store_code}_new_product_result.json
```

#### 1) í¬ë¡¤ë§ ê²°ê³¼ (`{store_code}_keywords.json`)
```json
{
  "store_code": "TEST001",
  "crawled_at": "2025-10-23T15:30:45.123456",
  "metadata": {
    "industry": "ì¹´í˜",
    "commercial_area": "ì„±ë™êµ¬ ì„±ìˆ˜ë™",
    "target_gender": "ì—¬ì„±",
    "target_ages": ["10ëŒ€", "20ëŒ€", "30ëŒ€"],
    "categories": ["ë†ì‚°ë¬¼", "ìŒë£Œ", "ê³¼ì/ë² ì´ì»¤ë¦¬"]
  },
  "keywords": [
    {"category": "ìŒë£Œ", "rank": 1, "keyword": "í”¼ìŠ¤íƒ€ì¹˜ì˜¤"},
    {"category": "ìŒë£Œ", "rank": 2, "keyword": "ë”¸ê¸°ë¼ë–¼"},
    ...
  ],
  "total_count": 30
}
```

#### 2) ìµœì¢… ê²°ê³¼ (`{store_code}_new_product_result.json`)
```json
{
  "store_code": "TEST001",
  "activated": true,
  "audience_filters": {...},
  "used_categories": ["ë†ì‚°ë¬¼", "ìŒë£Œ", "ê³¼ì/ë² ì´ì»¤ë¦¬"],
  "keywords_top": [...],
  "insight": {...},
  "proposals": [...]
}
```

**ì¥ì :**
- âœ… ì¬ì‚¬ìš© ê°€ëŠ¥ (í¬ë¡¤ë§ ê²°ê³¼ ìºì‹±)
- âœ… ì¶”ì  ê°€ëŠ¥ (ì–¸ì œ, ì–´ë–¤ í‚¤ì›Œë“œê°€ ìˆ˜ì§‘ë˜ì—ˆëŠ”ì§€)
- âœ… ë¶„ì„ ê°€ëŠ¥ (ì‹œê°„ë³„ íŠ¸ë Œë“œ ë³€í™”)
- âœ… ë””ë²„ê¹… ìš©ì´

---

### 3ï¸âƒ£ ì €ì¥ëœ í¬ë¡¤ë§ ê²°ê³¼ ì¬ì‚¬ìš©

```python
from agents_new.new_product_agent.io import CrawlerOutputManager

# 1) ìµœì‹  í¬ë¡¤ë§ ê²°ê³¼ ë¡œë“œ
manager = CrawlerOutputManager()
data = manager.get_latest_keywords("TEST001")

if data:
    print(f"ë§¤ì¥: {data['store_code']}")
    print(f"í¬ë¡¤ë§ ì‹œê°: {data['crawled_at']}")
    print(f"í‚¤ì›Œë“œ: {data['keywords']}")

# 2) íŠ¹ì • íŒŒì¼ ë¡œë“œ
specific_data = manager.load_keywords(
    "agents_new/data outputs/naver_datalab/TEST001_keywords_20251023_153045.json"
)

# 3) í¬ë¡¤ë§ ì—†ì´ LLMë§Œ ì¬ì‹¤í–‰ ê°€ëŠ¥ (í–¥í›„ ê¸°ëŠ¥)
```

---

## ğŸ“ ì €ì¥ ìœ„ì¹˜

```
bigcontest_ai_agent/
â””â”€â”€ open_sdk/
    â””â”€â”€ output/
        â”œâ”€â”€ analysis_{store_code}_{timestamp}/         # ë§¤ì¥ ë¶„ì„ ê²°ê³¼
        â”œâ”€â”€ marketplace_{timestamp}/                   # ìƒê¶Œ ë¶„ì„ ê²°ê³¼
        â”œâ”€â”€ mobility_{timestamp}/                      # ì´ë™ ë¶„ì„ ê²°ê³¼
        â””â”€â”€ naver_datalab_{timestamp}/                 # âœ… ì‹ ì œí’ˆ ì œì•ˆ (NEW!)
            â”œâ”€â”€ {store_code}_keywords.json             # í¬ë¡¤ë§ í‚¤ì›Œë“œ
            â””â”€â”€ {store_code}_new_product_result.json   # ìµœì¢… ê²°ê³¼
```

**í†µí•© ì¶œë ¥ í´ë” ì‚¬ìš©ì˜ ì¥ì :**
- âœ… ëª¨ë“  ë¶„ì„ ê²°ê³¼ê°€ í•œ ê³³ì— ëª¨ì„
- âœ… íƒ€ì„ìŠ¤íƒ¬í”„ë³„ ì„¸ì…˜ ê´€ë¦¬ ìš©ì´
- âœ… ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ì™€ í•¨ê»˜ ê´€ë¦¬ ê°€ëŠ¥

---

## ğŸ¯ ì‹¤ì „ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì¼íšŒì„± ë¶„ì„
```python
# ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš© (ë¹ ë¦„)
agent = NewProductAgent(headless=True, save_outputs=False)
result = await agent.run(store_report)
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ì •ê¸° ë¶„ì„ (ì¼ë³„/ì£¼ë³„)
```python
# íŒŒì¼ ì €ì¥ (ì¶”ì  ê°€ëŠ¥)
agent = NewProductAgent(headless=True, save_outputs=True)
results = []
for store_code in store_codes:
    result = await agent.run(get_store_report(store_code))
    results.append(result)

# ë‚˜ì¤‘ì— ì €ì¥ëœ ê²°ê³¼ ë¹„êµ ë¶„ì„
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: í¬ë¡¤ë§ ìºì‹œ í™œìš©
```python
manager = CrawlerOutputManager()

# ì˜¤ëŠ˜ ì´ë¯¸ í¬ë¡¤ë§í–ˆëŠ”ì§€ í™•ì¸
latest = manager.get_latest_keywords("TEST001")
if latest and is_today(latest['crawled_at']):
    # ì €ì¥ëœ í‚¤ì›Œë“œ ì¬ì‚¬ìš©
    keywords = latest['keywords']
else:
    # ìƒˆë¡œ í¬ë¡¤ë§
    agent = NewProductAgent(save_outputs=True)
    result = await agent.run(store_report)
```

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### ë°©ë²• 1: ë©”ëª¨ë¦¬ë§Œ ì‚¬ìš©
```bash
python test_new_product_agent.py
```

### ë°©ë²• 2: íŒŒì¼ ì €ì¥ í¬í•¨
```bash
python examples_new_product_agent.py
# ì‹¤í–‰ í›„ ì„ íƒ: 2 (íŒŒì¼ë¡œ ì €ì¥)
```

### ë°©ë²• 3: ì €ì¥ëœ ë°ì´í„° í™•ì¸
```bash
python examples_new_product_agent.py
# ì‹¤í–‰ í›„ ì„ íƒ: 3 (ì €ì¥ëœ ê²°ê³¼ ë¡œë“œ)
```

---

## ğŸ’¡ íŒ

### 1. í¬ë¡¤ë§ ê²°ê³¼ ì¬ì‚¬ìš©ìœ¼ë¡œ ì†ë„ í–¥ìƒ
- ë™ì¼ ë§¤ì¥/ë‚ ì§œëŠ” í•œ ë²ˆë§Œ í¬ë¡¤ë§
- ì €ì¥ëœ í‚¤ì›Œë“œë¡œ ì—¬ëŸ¬ ë²ˆ LLM ì‹¤í—˜ ê°€ëŠ¥

### 2. ì‹œê°„ë³„ íŠ¸ë Œë“œ ë¶„ì„
```python
# ê°™ì€ ë§¤ì¥ì˜ ê³¼ê±° í¬ë¡¤ë§ ê²°ê³¼ ë¹„êµ
files = sorted(output_dir.glob("TEST001_keywords_*.json"))
for f in files:
    data = manager.load_keywords(str(f))
    print(f"{data['crawled_at']}: {data['keywords'][0]['keyword']}")
```

### 3. ë°°ì¹˜ ì²˜ë¦¬ ì‹œ íŒŒì¼ ì €ì¥ í•„ìˆ˜
```python
# 100ê°œ ë§¤ì¥ ì²˜ë¦¬ ì‹œ - ì¤‘ê°„ì— ì˜¤ë¥˜ë‚˜ë„ ì¬ì‹œì‘ ê°€ëŠ¥
agent = NewProductAgent(save_outputs=True)
for store in stores:
    try:
        await agent.run(store_report)
    except Exception as e:
        print(f"ì‹¤íŒ¨: {store['code']}")
        continue
```

---

## ğŸ“Š ì €ì¥ íŒŒì¼ í™œìš© ì˜ˆì‹œ

### Pythonìœ¼ë¡œ ë¶„ì„
```python
import json
from pathlib import Path

# ëª¨ë“  í¬ë¡¤ë§ ê²°ê³¼ ì½ê¸°
output_dir = Path("agents_new/data outputs/naver_datalab")
all_keywords = []

for file in output_dir.glob("*_keywords_*.json"):
    with open(file) as f:
        data = json.load(f)
        all_keywords.extend(data['keywords'])

# ê°€ì¥ ë§ì´ ë“±ì¥í•œ í‚¤ì›Œë“œ TOP 10
from collections import Counter
top_keywords = Counter(k['keyword'] for k in all_keywords).most_common(10)
print(top_keywords)
```

### Pandasë¡œ ë¶„ì„
```python
import pandas as pd

# í¬ë¡¤ë§ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ
df = pd.DataFrame(all_keywords)
print(df.groupby('keyword').size().sort_values(ascending=False).head(10))
```

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **ì €ì¥ ê³µê°„ ê´€ë¦¬**
   - ë§¤ì¥Ã—ë‚ ì§œë³„ë¡œ íŒŒì¼ ìƒì„±ë¨
   - ì£¼ê¸°ì ìœ¼ë¡œ ì˜¤ë˜ëœ íŒŒì¼ ì •ë¦¬ ê¶Œì¥

2. **í¬ë¡¤ë§ ì†ë„**
   - íŒŒì¼ ì €ì¥ ì—¬ë¶€ì™€ ë¬´ê´€í•˜ê²Œ í¬ë¡¤ë§ ì‹œê°„ ë™ì¼
   - ì €ì¥ì€ í¬ë¡¤ë§ í›„ ìˆ˜í–‰ë˜ë¯€ë¡œ ì†ë„ ì˜í–¥ ë¯¸ë¯¸

3. **ì¬ì‚¬ìš© ì‹œ ì£¼ì˜**
   - íŠ¸ë Œë“œëŠ” ì‹œì‹œê°ê° ë³€í•˜ë¯€ë¡œ ë„ˆë¬´ ì˜¤ë˜ëœ ë°ì´í„° ì¬ì‚¬ìš© ì§€ì–‘
   - ì¼ë°˜ì ìœ¼ë¡œ ë‹¹ì¼ ë°ì´í„°ë§Œ ì¬ì‚¬ìš© ê¶Œì¥

---

## ğŸ“ ë¬¸ì˜

íŒŒì¼ ì €ì¥/ë¡œë“œ ê´€ë ¨ ë¬¸ì œê°€ ìˆìœ¼ë©´ ì´ìŠˆë¥¼ ë“±ë¡í•´ì£¼ì„¸ìš”!
